[
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "title": "Horizon Plot",
    "section": "",
    "text": "Before getting start, make sure that ggHoriPlot has been included in the pacman::p_load(...) statement above.\n\n\nCode\npacman::p_load(ggHoriPlot, ggthemes, tidyverse)\n\n\n\n\nFor the purpose of this hands-on exercise, Average Retail Prices Of Selected Consumer Items will be used.\nUse the code chunk below to import the AVERP.csv file into R environment.\n\n\nCode\naverp &lt;- read_csv(\"../../data/AVERP.csv\") %&gt;%\n  mutate(`Date` = dmy(`Date`))\n\n\n\n\n\nNext, the code chunk below will be used to plot the horizon graph.\n\n\nCode\naverp %&gt;% \n  filter(Date &gt;= \"2018-01-01\") %&gt;%\n  ggplot() +\n  geom_horizon(aes(x = Date, y=Values), \n               origin = \"midpoint\", \n               horizonscale = 6)+\n  facet_grid(`Consumer Items`~.) +\n    theme_few() +\n  scale_fill_hcl(palette = 'RdBu') +\n  theme(panel.spacing.y=unit(0, \"lines\"), strip.text.y = element_text(\n    size = 5, angle = 0, hjust = 0),\n    legend.position = 'none',\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size=7),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()\n    ) +\n    scale_x_date(expand=c(0,0), date_breaks = \"3 month\", date_labels = \"%b%y\") +\n  ggtitle('Average Retail Prices of Selected Consumer Items (Jan 2018 to Dec 2022)')"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#getting-started",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#getting-started",
    "title": "Horizon Plot",
    "section": "",
    "text": "Before getting start, make sure that ggHoriPlot has been included in the pacman::p_load(...) statement above.\n\n\nCode\npacman::p_load(ggHoriPlot, ggthemes, tidyverse)\n\n\n\n\nFor the purpose of this hands-on exercise, Average Retail Prices Of Selected Consumer Items will be used.\nUse the code chunk below to import the AVERP.csv file into R environment.\n\n\nCode\naverp &lt;- read_csv(\"../../data/AVERP.csv\") %&gt;%\n  mutate(`Date` = dmy(`Date`))\n\n\n\n\n\nNext, the code chunk below will be used to plot the horizon graph.\n\n\nCode\naverp %&gt;% \n  filter(Date &gt;= \"2018-01-01\") %&gt;%\n  ggplot() +\n  geom_horizon(aes(x = Date, y=Values), \n               origin = \"midpoint\", \n               horizonscale = 6)+\n  facet_grid(`Consumer Items`~.) +\n    theme_few() +\n  scale_fill_hcl(palette = 'RdBu') +\n  theme(panel.spacing.y=unit(0, \"lines\"), strip.text.y = element_text(\n    size = 5, angle = 0, hjust = 0),\n    legend.position = 'none',\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size=7),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()\n    ) +\n    scale_x_date(expand=c(0,0), date_breaks = \"3 month\", date_labels = \"%b%y\") +\n  ggtitle('Average Retail Prices of Selected Consumer Items (Jan 2018 to Dec 2022)')"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "Tableau Public"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take-home Exercise 3",
    "section": "",
    "text": "According to an office report as shown in the infographic below:\n\nDaily mean temperature are projected to increase by 1.4 to 4.6, and\nThe contrast between the wet months (November to January) and dry month (February and June to September) is likely to be more pronounced.\n\n\nAs visual analytics greenhorns, we are keen to apply our newly acquired skills in visual interactivity and visualizing uncertainty methods to validate the claims presented above."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#installing-r-packages",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#installing-r-packages",
    "title": "Take-home Exercise 3",
    "section": "1.1 Installing R packages",
    "text": "1.1 Installing R packages\npacman::p_load() function from the pacman package is used in the following code chunk to install and call the libraries of multiple R packages:\n\n\nCode\npacman::p_load(\n  plotly,\n  dplyr,\n  readr,\n  readxl,\n  tidyr,\n  RColorBrewer,\n  ggplot2,\n  lubridate\n)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#importing-dataset",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#importing-dataset",
    "title": "Take-home Exercise 3",
    "section": "1.2 Importing Dataset",
    "text": "1.2 Importing Dataset\nHistorical daily temperature from Meteorological Service Singapore is provided for the task.\nThe following code segment utilizes the read_excel() function from the readxl package to load data from an Excel file into the R environment. This operation imports the dataset titled “Tengah_Jun_1983_2023.xlsx” into a dataframe.\n\n\nCode\n# Specify the path to the Excel file\nfile_path &lt;- (\"../../data/Tengah_Jun_1983_2023.xlsx\")\n\n# Import the data into a dataframe\ndf &lt;- read_excel(file_path)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "In this chapter, you will learn the basic principles and essential components of ggplot2. At the same time, you will gain hands-on experience on using these components to plot statistical graphics based on the principle of Layered Grammar of Graphics. By then end of this chapter you will be able to apply the essential graphical elements provided by ggplot2 to create elegant and yet functional statistical graphics."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#installing-and-loading-the-required-libraries",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#installing-and-loading-the-required-libraries",
    "title": "Hands-on Exercise 1",
    "section": "1.2.1 Installing and loading the required libraries",
    "text": "1.2.1 Installing and loading the required libraries\nThe code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-data",
    "title": "Hands-on Exercise 1",
    "section": "1.2.2 Importing data",
    "text": "1.2.2 Importing data\n\nexam_data &lt;- read_csv(\"../../data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#r-graphics-vs-ggplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#r-graphics-vs-ggplot",
    "title": "Hands-on Exercise 1",
    "section": "1.3.1 R Graphics VS ggplot",
    "text": "1.3.1 R Graphics VS ggplot\n\nR Graphics\n\nhist(exam_data$MATHS)\n\n\n\n\n\n\nggplot2\n\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"black\", \n                 fill=\"grey\") +\n  ggtitle(\"Distribution of Maths scores\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#a-layered-grammar-of-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#a-layered-grammar-of-graphics",
    "title": "Hands-on Exercise 1",
    "section": "1.4.1 A Layered Grammar of Graphics",
    "text": "1.4.1 A Layered Grammar of Graphics\nA short description of each building block are as follows:\n\nData: The dataset being plotted.\nAesthetics take attributes of the data and use them to influence visual characteristics, such as position, colours, size, shape, or transparency.\nGeometrics: The visual elements used for our data, such as point, bar or line.\nFacets split the data into subsets to create multiple variations of the same graph (paneling, multiple plots).\nStatistics, statiscal transformations that summarise data (e.g. mean, confidence intervals).\nCoordinate systems define the plane on which data are mapped on the graphic.\nThemes modify all non-data components of a plot, such as main title, sub-title, y-aixs title, or legend background."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_bar",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_bar",
    "title": "Hands-on Exercise 1",
    "section": "1.7.1 Geometric Objects: geom_bar",
    "text": "1.7.1 Geometric Objects: geom_bar\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_dotplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_dotplot",
    "title": "Hands-on Exercise 1",
    "section": "1.7.2 Geometric Objects: geom_dotplot",
    "text": "1.7.2 Geometric Objects: geom_dotplot\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)\n\nBin width defaults to 1/30 of the range of the data. Pick better value with\n`binwidth`.\n\n\n\n\n\nThe y scale is not very useful, in fact it is very misleading.\nThe code chunk below performs the following two steps:\n\nscale_y_continuous() is used to turn off the y-axis, and\nbinwidth argument is used to change the binwidth to 2.5.\n\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5,         \n               dotsize = 0.5) +      \n  scale_y_continuous(NULL,           \n                     breaks = NULL)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_histogram",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_histogram",
    "title": "Hands-on Exercise 1",
    "section": "1.7.3 Geometric Objects: geom_histogram()",
    "text": "1.7.3 Geometric Objects: geom_histogram()\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_histogram()       \n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#modifying-a-geometric-object-by-changing-geom",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#modifying-a-geometric-object-by-changing-geom",
    "title": "Hands-on Exercise 1",
    "section": "1.7.4 Modifying a geometric object by changing geom()",
    "text": "1.7.4 Modifying a geometric object by changing geom()\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20,            \n                 color=\"black\",      \n                 fill=\"light blue\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#modifying-a-geometric-object-by-changing-aes",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#modifying-a-geometric-object-by-changing-aes",
    "title": "Hands-on Exercise 1",
    "section": "1.7.5 Modifying a geometric object by changing aes()",
    "text": "1.7.5 Modifying a geometric object by changing aes()\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom-density",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom-density",
    "title": "Hands-on Exercise 1",
    "section": "1.7.6 Geometric Objects: geom-density()",
    "text": "1.7.6 Geometric Objects: geom-density()\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_density()           \n\n\n\n\nThe code chunk below plots two kernel density lines by using colour or fill arguments of aes()\n\nggplot(data=exam_data, \n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_boxplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_boxplot",
    "title": "Hands-on Exercise 1",
    "section": "1.7.7 Geometric Objects: geom_boxplot",
    "text": "1.7.7 Geometric Objects: geom_boxplot\n\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot()            \n\n\n\n\nNotches are used in box plots to help visually assess whether the medians of distributions differ. If the notches do not overlap, this is evidence that the medians are different.\nThe code chunk below plots the distribution of Maths scores by gender in notched plot instead of boxplot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(notch=TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_violin",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_violin",
    "title": "Hands-on Exercise 1",
    "section": "1.7.8 Geometric Objects: geom_violin",
    "text": "1.7.8 Geometric Objects: geom_violin\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_point",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_point",
    "title": "Hands-on Exercise 1",
    "section": "1.7.9 Geometric Objects: geom_point()",
    "text": "1.7.9 Geometric Objects: geom_point()\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geom-objects-can-be-combined",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geom-objects-can-be-combined",
    "title": "Hands-on Exercise 1",
    "section": "1.7.10 geom objects can be combined",
    "text": "1.7.10 geom objects can be combined\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot() +                    \n  geom_point(position=\"jitter\", \n             size = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat",
    "title": "Hands-on Exercise 1",
    "section": "1.8.1 Working with stat()",
    "text": "1.8.1 Working with stat()\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat---the-stat_summary-method",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat---the-stat_summary-method",
    "title": "Hands-on Exercise 1",
    "section": "1.8.2 Working with stat - the stat_summary() method",
    "text": "1.8.2 Working with stat - the stat_summary() method\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"red\",        \n               size=4)               \n\nWarning: The `fun.y` argument of `stat_summary()` is deprecated as of ggplot2 3.3.0.\nℹ Please use the `fun` argument instead."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat---the-geom-method",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat---the-geom-method",
    "title": "Hands-on Exercise 1",
    "section": "1.8.3 Working with stat - the geom() method",
    "text": "1.8.3 Working with stat - the geom() method\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",        \n             fun.y=\"mean\",           \n             colour =\"red\",          \n             size=4)          \n\nWarning in geom_point(stat = \"summary\", fun.y = \"mean\", colour = \"red\", :\nIgnoring unknown parameters: `fun.y`\n\n\nNo summary function supplied, defaulting to `mean_se()`"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#adding-a-best-fit-curve-on-a-scatterplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#adding-a-best-fit-curve-on-a-scatterplot",
    "title": "Hands-on Exercise 1",
    "section": "1.8.4 Adding a best fit curve on a scatterplot?",
    "text": "1.8.4 Adding a best fit curve on a scatterplot?\nIn the code chunk below, geom_smooth() is used to plot a best fit curve on the scatterplot.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(size=0.5)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nThe default smoothing method can be overridden as shown below.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-facet_wrap",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-facet_wrap",
    "title": "Hands-on Exercise 1",
    "section": "1.9.1 Working with facet_wrap()",
    "text": "1.9.1 Working with facet_wrap()\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#facet_grid-function",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#facet_grid-function",
    "title": "Hands-on Exercise 1",
    "section": "1.9.2 facet_grid() function",
    "text": "1.9.2 facet_grid() function\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-coordinate",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-coordinate",
    "title": "Hands-on Exercise 1",
    "section": "1.10.1 Working with Coordinate",
    "text": "1.10.1 Working with Coordinate\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\nThe code chunk below flips the horizontal bar chart into vertical bar chart by using coord_flip().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#changing-the-y--and-x-axis-range",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#changing-the-y--and-x-axis-range",
    "title": "Hands-on Exercise 1",
    "section": "1.10.2 Changing the y- and x-axis range",
    "text": "1.10.2 Changing the y- and x-axis range\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, size=0.5)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nThe code chunk below fixed both the y-axis and x-axis range from 0-100.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-theme",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-theme",
    "title": "Hands-on Exercise 1",
    "section": "1.11.1 Working with theme",
    "text": "1.11.1 Working with theme\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()\n\n\n\n\nA horizontal bar chart plotted using theme_classic().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "title": "Hands-on Exercise 8",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to model, analyse and visualise network data using R.\nBy the end of this hands-on exercise, you will be able to:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package.\n\n\n\n\n\n\nIn this hands-on exercise, four network data modelling and visualisation packages will be installed and launched. They are igraph, tidygraph, ggraph and visNetwork. Beside these four packages, tidyverse and lubridate, an R package specially designed to handle and wrangling time data will be installed and launched too.\nThe code chunk:\n\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)\n\n\n\n\n\nThe data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\n\n\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 55 employees.\n\n\n\n\n\n\nGAStech_email_nodes.csv which consist of the names, department and title of the 55 employees.\n\n\n\n\n\nIn this step, you will import GAStech_email_node.csv and GAStech_email_edges-v2.csv into RStudio environment by using read_csv() of readr package.\n\nGAStech_nodes &lt;- read_csv(\"../../data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"../../data/GAStech_email_edge-v2.csv\")\n\n\n\n\nNext, we will examine the structure of the data frame using glimpse() of dplyr.\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\n\nThe code chunk below will be used to perform the changes.\n\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\nThings to learn from the code chunk above\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges data frame.\n\n\n\n\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, we will aggregate the individual by date, senders, receivers, main subject and day of the week.\nThe code chunk:\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\nThings to learn from the code chunk above:\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated.\n\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges data frame.\n\n\n\n\n\nIn this section, you will learn how to create a graph data model by using tidygraph package. It provides a tidy API for graph/network manipulation. While network data itself is not tidy, it can be envisioned as two tidy tables, one for node data and one for edge data. tidygraph provides a way to switch between the two tables and provides dplyr verbs for manipulating them. Furthermore it provides access to a lot of graph algorithms with return values that facilitate their use in a tidy workflow.\nBefore getting started, you are advised to read these two articles:\n\nIntroducing tidygraph\ntidygraph 1.1 - A tidy hope\n\n\n\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network. Below are network data and objects supported by as_tbl_graph()\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor).\n\n\n\n\n\n\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n\n\n\nIn the above the .N() function is used to gain access to the node data while manipulating the edge data. Similarly .E() will give you the edge data and .G() will give you the tbl_graph object itself.\n\n\n\n\nIn this section, you will use tbl_graph() of tinygraph package to build an tidygraph’s network graph data.frame.\nBefore typing the codes, you are recommended to review to reference guide of tbl_graph()\n\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\n\n\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\n\n\n\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 4541 edges.\nThe command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time.\n\n\n\n\nThe nodes tibble data frame is activated by default, but you can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest “weight” first, we could use activate() and then arrange().\nFor example,\n\nGAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,372 × 4 (active)\n    from    to Weekday   Weight\n   &lt;int&gt; &lt;int&gt; &lt;ord&gt;      &lt;int&gt;\n 1    40    41 Saturday      13\n 2    41    43 Monday        11\n 3    35    31 Tuesday       10\n 4    40    41 Monday        10\n 5    40    43 Monday        10\n 6    36    32 Sunday         9\n 7    40    43 Saturday       9\n 8    41    40 Monday         9\n 9    19    15 Wednesday      8\n10    35    38 Tuesday        8\n# ℹ 1,362 more rows\n#\n# Node Data: 54 × 4\n     id label           Department     Title           \n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows\n\n\nVisit the reference guide of activate() to find out more about the function.\n\n\n\n\nggraph is an extension of ggplot2, making it easier to carry over basic ggplot skills to the design of network graphs.\nAs in all network graph, there are three main aspects to a ggraph’s network graph, they are:\n\nnodes,\nedges and\nlayouts.\n\nFor a comprehensive discussion of each of this aspect of graph, please refer to their respective vignettes provided.\n\n\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph. Before your get started, it is advisable to read their respective reference guide at least once.\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\nThings to learn from the code chunk above:\n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired. Both of the arguments for ggraph() are built around igraph. Therefore, ggraph() can use either an igraph object or a tbl_graph object.\n\n\n\n\nIn this section, you will use theme_graph() to remove the x and y axes. Before your get started, it is advisable to read it’s reference guide at least once.\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\nThings to learn from the code chunk above:\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids, and border, changes the font to Arial Narrow (this can be overridden).\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots.\n\n\n\n\nFurthermore, theme_graph() makes it easy to change the coloring of the plot.\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\n\nggraph support many layout for standard used, they are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl. Figures below and on the right show layouts supported by ggraph().\n\n\n\n\n\nThe code chunks below will be used to plot the network graph using Fruchterman and Reingold layout.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\nThing to learn from the code chunk above:\n\nlayout argument is used to define the layout to be used.\n\n\n\n\nIn this section, you will colour each node by referring to their respective departments.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_node_point is equivalent in functionality to geo_point of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes. In the codes chnuks above colour and size are used.\n\n\n\n\nIn the code chunk below, the thickness of the edges will be mapped with the Weight variable.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportional to the Weight attribute and argument alpha is used to introduce opacity on the line.\n\n\n\n\n\nAnother very useful feature of ggraph is faceting. In visualising network data, this technique can be used to reduce edge over-plotting in a very meaning way by spreading nodes and edges out based on their attributes. In this section, you will learn how to use faceting technique to visualise network data.\nThere are three functions in ggraph to implement faceting, they are:\n\nfacet_nodes() whereby edges are only draw in a panel if both terminal nodes are present here,\nfacet_edges() whereby nodes are always drawn in al panels even if the node data contains an attribute named the same as the one used for the edge facetting, and\nfacet_graph() faceting on two variables simultaneously.\n\n\n\nIn the code chunk below, facet_edges() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\nThe code chunk below uses theme() to change the position of the legend.\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\nThe code chunk below adds frame to each graph.\n\nset_graph_style() \n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\nIn the code chunkc below, facet_nodes() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\n\n\nCentrality measures are a collection of statistical indices use to describe the relative important of the actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measure here. Students are encouraged to refer to Chapter 7: Actor Prominence of A User’s Guide to Network Analysis in R to gain better understanding of theses network measures.\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\nThings to learn from the code chunk above:\n\nmutate() of dplyr is used to perform the computation.\nthe algorithm used, on the other hand, is the centrality_betweenness() of tidygraph.\n\n\n\n\nIt is important to note that from ggraph v2.0 onward tidygraph algorithms such as centrality measures can be accessed directly in ggraph calls. This means that it is no longer necessary to precompute and store derived node and edge centrality measures on the graph in order to use them in a plot.\n\ng &lt;- GAStech_graph %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()\n\n\n\n\n\n\n\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used.\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(community = as.factor(group_edge_betweenness(weights = Weight, directed = TRUE))) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = community))  \n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\nvisNetwork() is a R package for network visualization, using vis.js javascript library.\nvisNetwork() function uses a nodes list and edges list to create an interactive graph.\n\nThe nodes list must include an “id” column, and the edge list must have “from” and “to” columns.\nThe function also plots the labels for the nodes, using the names of the actors from the “label” column in the node list.\n\nThe resulting graph is fun to play around with.\n\nYou can move the nodes and the graph will use an algorithm to keep the nodes properly spaced.\nYou can also zoom in and out on the plot and move it around to re-center it.\n\n\n\n\nBefore we can plot the interactive network graph, we need to prepare the data model by using the code chunk below.\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %&gt;%\n  rename(to = id) %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(from, to) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(from!=to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\nThe code chunk below will be used to plot an interactive network graph by using the data prepared.\n\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)\n\n\n\n\n\n\n\n\nIn the code chunk below, Fruchterman and Reingold layout is used.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\nVisit Igraph to find out more about visIgraphLayout’s argument.\n\n\n\nvisNetwork() looks for a field called “group” in the nodes object and colour the nodes according to the values of the group field.\nThe code chunk below rename Department field to group.\n\nGAStech_nodes &lt;- GAStech_nodes %&gt;%\n  rename(group = Department) \n\nWhen we rerun the code chunk below, visNetwork shades the nodes by assigning unique colour to each category in the group field.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\nIn the code run below visEdges() is used to symbolise the edges.\n- The argument arrows is used to define where to place the arrow.\n- The smooth argument is used to plot the edges using a smooth curve.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\nVisit Option to find out more about visEdges’s argument.\n\n\n\nIn the code chunk below, visOptions() is used to incorporate interactivity features in the data visualisation.\n\nThe argument highlightNearest highlights nearest when clicking a node.\nThe argument nodesIdSelection adds an id node selection creating an HTML select element.\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\nVisit Option to find out more about visOption’s argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#overview",
    "title": "Hands-on Exercise 8",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to model, analyse and visualise network data using R.\nBy the end of this hands-on exercise, you will be able to:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#getting-started",
    "title": "Hands-on Exercise 8",
    "section": "",
    "text": "In this hands-on exercise, four network data modelling and visualisation packages will be installed and launched. They are igraph, tidygraph, ggraph and visNetwork. Beside these four packages, tidyverse and lubridate, an R package specially designed to handle and wrangling time data will be installed and launched too.\nThe code chunk:\n\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#the-data",
    "title": "Hands-on Exercise 8",
    "section": "",
    "text": "The data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\n\n\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 55 employees.\n\n\n\n\n\n\nGAStech_email_nodes.csv which consist of the names, department and title of the 55 employees.\n\n\n\n\n\nIn this step, you will import GAStech_email_node.csv and GAStech_email_edges-v2.csv into RStudio environment by using read_csv() of readr package.\n\nGAStech_nodes &lt;- read_csv(\"../../data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"../../data/GAStech_email_edge-v2.csv\")\n\n\n\n\nNext, we will examine the structure of the data frame using glimpse() of dplyr.\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\n\nThe code chunk below will be used to perform the changes.\n\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\nThings to learn from the code chunk above\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges data frame.\n\n\n\n\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, we will aggregate the individual by date, senders, receivers, main subject and day of the week.\nThe code chunk:\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\nThings to learn from the code chunk above:\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated.\n\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#creating-network-objects-using-tidygraph",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#creating-network-objects-using-tidygraph",
    "title": "Hands-on Exercise 8",
    "section": "",
    "text": "In this section, you will learn how to create a graph data model by using tidygraph package. It provides a tidy API for graph/network manipulation. While network data itself is not tidy, it can be envisioned as two tidy tables, one for node data and one for edge data. tidygraph provides a way to switch between the two tables and provides dplyr verbs for manipulating them. Furthermore it provides access to a lot of graph algorithms with return values that facilitate their use in a tidy workflow.\nBefore getting started, you are advised to read these two articles:\n\nIntroducing tidygraph\ntidygraph 1.1 - A tidy hope\n\n\n\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network. Below are network data and objects supported by as_tbl_graph()\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor).\n\n\n\n\n\n\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n\n\n\nIn the above the .N() function is used to gain access to the node data while manipulating the edge data. Similarly .E() will give you the edge data and .G() will give you the tbl_graph object itself.\n\n\n\n\nIn this section, you will use tbl_graph() of tinygraph package to build an tidygraph’s network graph data.frame.\nBefore typing the codes, you are recommended to review to reference guide of tbl_graph()\n\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\n\n\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\n\n\n\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 4541 edges.\nThe command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time.\n\n\n\n\nThe nodes tibble data frame is activated by default, but you can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest “weight” first, we could use activate() and then arrange().\nFor example,\n\nGAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,372 × 4 (active)\n    from    to Weekday   Weight\n   &lt;int&gt; &lt;int&gt; &lt;ord&gt;      &lt;int&gt;\n 1    40    41 Saturday      13\n 2    41    43 Monday        11\n 3    35    31 Tuesday       10\n 4    40    41 Monday        10\n 5    40    43 Monday        10\n 6    36    32 Sunday         9\n 7    40    43 Saturday       9\n 8    41    40 Monday         9\n 9    19    15 Wednesday      8\n10    35    38 Tuesday        8\n# ℹ 1,362 more rows\n#\n# Node Data: 54 × 4\n     id label           Department     Title           \n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows\n\n\nVisit the reference guide of activate() to find out more about the function."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#plotting-static-network-graphs-with-ggraph-package",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#plotting-static-network-graphs-with-ggraph-package",
    "title": "Hands-on Exercise 8",
    "section": "",
    "text": "ggraph is an extension of ggplot2, making it easier to carry over basic ggplot skills to the design of network graphs.\nAs in all network graph, there are three main aspects to a ggraph’s network graph, they are:\n\nnodes,\nedges and\nlayouts.\n\nFor a comprehensive discussion of each of this aspect of graph, please refer to their respective vignettes provided.\n\n\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph. Before your get started, it is advisable to read their respective reference guide at least once.\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\nThings to learn from the code chunk above:\n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired. Both of the arguments for ggraph() are built around igraph. Therefore, ggraph() can use either an igraph object or a tbl_graph object.\n\n\n\n\nIn this section, you will use theme_graph() to remove the x and y axes. Before your get started, it is advisable to read it’s reference guide at least once.\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\nThings to learn from the code chunk above:\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids, and border, changes the font to Arial Narrow (this can be overridden).\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots.\n\n\n\n\nFurthermore, theme_graph() makes it easy to change the coloring of the plot.\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\n\nggraph support many layout for standard used, they are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl. Figures below and on the right show layouts supported by ggraph().\n\n\n\n\n\nThe code chunks below will be used to plot the network graph using Fruchterman and Reingold layout.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\nThing to learn from the code chunk above:\n\nlayout argument is used to define the layout to be used.\n\n\n\n\nIn this section, you will colour each node by referring to their respective departments.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_node_point is equivalent in functionality to geo_point of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes. In the codes chnuks above colour and size are used.\n\n\n\n\nIn the code chunk below, the thickness of the edges will be mapped with the Weight variable.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportional to the Weight attribute and argument alpha is used to introduce opacity on the line."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#creating-facet-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#creating-facet-graphs",
    "title": "Hands-on Exercise 8",
    "section": "",
    "text": "Another very useful feature of ggraph is faceting. In visualising network data, this technique can be used to reduce edge over-plotting in a very meaning way by spreading nodes and edges out based on their attributes. In this section, you will learn how to use faceting technique to visualise network data.\nThere are three functions in ggraph to implement faceting, they are:\n\nfacet_nodes() whereby edges are only draw in a panel if both terminal nodes are present here,\nfacet_edges() whereby nodes are always drawn in al panels even if the node data contains an attribute named the same as the one used for the edge facetting, and\nfacet_graph() faceting on two variables simultaneously.\n\n\n\nIn the code chunk below, facet_edges() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\nThe code chunk below uses theme() to change the position of the legend.\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\nThe code chunk below adds frame to each graph.\n\nset_graph_style() \n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\nIn the code chunkc below, facet_nodes() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#network-metrics-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#network-metrics-analysis",
    "title": "Hands-on Exercise 8",
    "section": "",
    "text": "Centrality measures are a collection of statistical indices use to describe the relative important of the actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measure here. Students are encouraged to refer to Chapter 7: Actor Prominence of A User’s Guide to Network Analysis in R to gain better understanding of theses network measures.\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\nThings to learn from the code chunk above:\n\nmutate() of dplyr is used to perform the computation.\nthe algorithm used, on the other hand, is the centrality_betweenness() of tidygraph.\n\n\n\n\nIt is important to note that from ggraph v2.0 onward tidygraph algorithms such as centrality measures can be accessed directly in ggraph calls. This means that it is no longer necessary to precompute and store derived node and edge centrality measures on the graph in order to use them in a plot.\n\ng &lt;- GAStech_graph %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()\n\n\n\n\n\n\n\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used.\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(community = as.factor(group_edge_betweenness(weights = Weight, directed = TRUE))) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = community))  \n\ng + theme_graph()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#building-interactive-network-graph-with-visnetwork",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#building-interactive-network-graph-with-visnetwork",
    "title": "Hands-on Exercise 8",
    "section": "",
    "text": "visNetwork() is a R package for network visualization, using vis.js javascript library.\nvisNetwork() function uses a nodes list and edges list to create an interactive graph.\n\nThe nodes list must include an “id” column, and the edge list must have “from” and “to” columns.\nThe function also plots the labels for the nodes, using the names of the actors from the “label” column in the node list.\n\nThe resulting graph is fun to play around with.\n\nYou can move the nodes and the graph will use an algorithm to keep the nodes properly spaced.\nYou can also zoom in and out on the plot and move it around to re-center it.\n\n\n\n\nBefore we can plot the interactive network graph, we need to prepare the data model by using the code chunk below.\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %&gt;%\n  rename(to = id) %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(from, to) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(from!=to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\nThe code chunk below will be used to plot an interactive network graph by using the data prepared.\n\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)\n\n\n\n\n\n\n\n\nIn the code chunk below, Fruchterman and Reingold layout is used.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\nVisit Igraph to find out more about visIgraphLayout’s argument.\n\n\n\nvisNetwork() looks for a field called “group” in the nodes object and colour the nodes according to the values of the group field.\nThe code chunk below rename Department field to group.\n\nGAStech_nodes &lt;- GAStech_nodes %&gt;%\n  rename(group = Department) \n\nWhen we rerun the code chunk below, visNetwork shades the nodes by assigning unique colour to each category in the group field.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\nIn the code run below visEdges() is used to symbolise the edges.\n- The argument arrows is used to define where to place the arrow.\n- The smooth argument is used to plot the edges using a smooth curve.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\nVisit Option to find out more about visEdges’s argument.\n\n\n\nIn the code chunk below, visOptions() is used to incorporate interactivity features in the data visualisation.\n\nThe argument highlightNearest highlights nearest when clicking a node.\nThe argument nodesIdSelection adds an id node selection creating an HTML select element.\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\nVisit Option to find out more about visOption’s argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07C.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07C.html",
    "title": "Hands-on Exercise 7C",
    "section": "",
    "text": "In this in-class exercise, you will gain hands-on experience on using appropriate R methods to plot analytical maps.\n\n\n\nBy the end of this in-class exercise, you will be able to use appropriate functions of tmap and tidyverse to perform the following tasks:\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap\n\n\n\n\n\n\n\n\npacman::p_load(tmap, tidyverse, sf)\n\n\n\n\nFor the purpose of this hands-on exercise, a prepared data set called NGA_wp.rds will be used. The data set is a polygon feature data.frame providing information on water point of Nigeria at the LGA level. You can find the data set in the rds sub-direct of the hands-on data folder.\n\nNGA_wp &lt;- read_rds(\"../../data/rds/NGA_wp.rds\")\n\n\n\n\n\n\n\n\np1 &lt;- tm_shape(NGA_wp) +\n  tm_fill(\"wp_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of functional water point by LGAs\",\n            legend.outside = FALSE)\n\n\np2 &lt;- tm_shape(NGA_wp) +\n  tm_fill(\"total_wp\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of total  water point by LGAs\",\n            legend.outside = FALSE)\n\n\ntmap_arrange(p2, p1, nrow = 1)\n\n\n\n\n\n\n\n\nIn much of our readings we have now seen the importance to map rates rather than counts of things, and that is for the simple reason that water points are not equally distributed in space. That means that if we do not account for how many water points are somewhere, we end up mapping total water point size rather than our topic of interest.\n\n\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  mutate(pct_functional = wp_functional/total_wp) %&gt;%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\n\n\n\ntm_shape(NGA_wp) +\n  tm_fill(\"pct_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\",\n          legend.hist = TRUE) +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Rate map of functional water point by LGAs\",\n            legend.outside = TRUE)\n\n\n\n\n\n\n\n\nExtreme value maps are variations of common choropleth maps where the classification is designed to highlight extreme values at the lower and upper end of the scale, with the goal of identifying outliers. These maps were developed in the spirit of spatializing EDA, i.e., adding spatial features to commonly used approaches in non-spatial EDA (Anselin 1994).\n\n\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\n\n\nStep 1: Exclude records with NA by using the code chunk below.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  drop_na()\n\nStep 2: Creating customised classification and extracting values\n\npercent &lt;- c(0,.01,.1,.5,.9,.99,1)\nvar &lt;- NGA_wp[\"pct_functional\"] %&gt;%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\n\nWriting a function has three big advantages over using copy-and-paste:\n\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\n\nSource: Chapter 19: Functions of R for Data Science.\n\n\n\nFirstly, we will write an R function as shown below to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\nNext, we will write a percentile mapping function by using the code chunk below.\n\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\n\n\n\nTo run the function, type the code chunk as shown below.\n\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\nNote that this is just a bare bones implementation. Additional arguments such as the title, legend positioning just to name a few of them, could be passed to customise various features of the map.\n\n\n\n\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\n\nThe code chunk below is an R function that creating break points for a box map.\n\narguments:\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\nreturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\n\n\n\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\nLet’s test the newly created function.\n\nvar &lt;- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\n\nThe code chunk below is an R function to create a box map. - arguments: - vnam: variable name (as character, in quotes) - df: simple features polygon layer - legtitle: legend title - mtitle: map title - mult: multiplier for IQR - returns: - a tmap-element (plots a map).\n\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\n\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07C.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07C.html#overview",
    "title": "Hands-on Exercise 7C",
    "section": "",
    "text": "In this in-class exercise, you will gain hands-on experience on using appropriate R methods to plot analytical maps.\n\n\n\nBy the end of this in-class exercise, you will be able to use appropriate functions of tmap and tidyverse to perform the following tasks:\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07C.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07C.html#getting-started",
    "title": "Hands-on Exercise 7C",
    "section": "",
    "text": "pacman::p_load(tmap, tidyverse, sf)\n\n\n\n\nFor the purpose of this hands-on exercise, a prepared data set called NGA_wp.rds will be used. The data set is a polygon feature data.frame providing information on water point of Nigeria at the LGA level. You can find the data set in the rds sub-direct of the hands-on data folder.\n\nNGA_wp &lt;- read_rds(\"../../data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07C.html#basic-choropleth-mapping",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07C.html#basic-choropleth-mapping",
    "title": "Hands-on Exercise 7C",
    "section": "",
    "text": "p1 &lt;- tm_shape(NGA_wp) +\n  tm_fill(\"wp_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of functional water point by LGAs\",\n            legend.outside = FALSE)\n\n\np2 &lt;- tm_shape(NGA_wp) +\n  tm_fill(\"total_wp\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of total  water point by LGAs\",\n            legend.outside = FALSE)\n\n\ntmap_arrange(p2, p1, nrow = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07C.html#choropleth-map-for-rates",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07C.html#choropleth-map-for-rates",
    "title": "Hands-on Exercise 7C",
    "section": "",
    "text": "In much of our readings we have now seen the importance to map rates rather than counts of things, and that is for the simple reason that water points are not equally distributed in space. That means that if we do not account for how many water points are somewhere, we end up mapping total water point size rather than our topic of interest.\n\n\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  mutate(pct_functional = wp_functional/total_wp) %&gt;%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\n\n\n\ntm_shape(NGA_wp) +\n  tm_fill(\"pct_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\",\n          legend.hist = TRUE) +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Rate map of functional water point by LGAs\",\n            legend.outside = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07C.html#extreme-value-maps",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07C.html#extreme-value-maps",
    "title": "Hands-on Exercise 7C",
    "section": "",
    "text": "Extreme value maps are variations of common choropleth maps where the classification is designed to highlight extreme values at the lower and upper end of the scale, with the goal of identifying outliers. These maps were developed in the spirit of spatializing EDA, i.e., adding spatial features to commonly used approaches in non-spatial EDA (Anselin 1994).\n\n\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\n\n\nStep 1: Exclude records with NA by using the code chunk below.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  drop_na()\n\nStep 2: Creating customised classification and extracting values\n\npercent &lt;- c(0,.01,.1,.5,.9,.99,1)\nvar &lt;- NGA_wp[\"pct_functional\"] %&gt;%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\n\nWriting a function has three big advantages over using copy-and-paste:\n\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\n\nSource: Chapter 19: Functions of R for Data Science.\n\n\n\nFirstly, we will write an R function as shown below to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\nNext, we will write a percentile mapping function by using the code chunk below.\n\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\n\n\n\nTo run the function, type the code chunk as shown below.\n\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\nNote that this is just a bare bones implementation. Additional arguments such as the title, legend positioning just to name a few of them, could be passed to customise various features of the map.\n\n\n\n\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\n\nThe code chunk below is an R function that creating break points for a box map.\n\narguments:\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\nreturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\n\n\n\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\nLet’s test the newly created function.\n\nvar &lt;- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\n\nThe code chunk below is an R function to create a box map. - arguments: - vnam: variable name (as character, in quotes) - df: simple features polygon layer - legtitle: legend title - mtitle: map title - mult: multiplier for IQR - returns: - a tmap-element (plots a map).\n\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\n\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05C.html#importing-the-data-set",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05C.html#importing-the-data-set",
    "title": "Hands-on Exercise 5C",
    "section": "14.3.1 Importing the data set",
    "text": "14.3.1 Importing the data set\nIn the code chunk below, read_csv() of readr is used to import WHData-2018.csv into R and parsed it into tibble R data frame format.\n\nwh &lt;- read_csv(\"../../data/WHData-2018.csv\")\n\nThe output tibbled data frame is called wh."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05C.html#preparing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05C.html#preparing-the-data",
    "title": "Hands-on Exercise 5C",
    "section": "14.3.2 Preparing the data",
    "text": "14.3.2 Preparing the data\nNext, we need to change the rows by country name instead of row number by using the code chunk below.\n\nrow.names(wh) &lt;- wh$Country\n\nNotice that the row number has been replaced into the country name."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05C.html#transforming-the-data-frame-into-a-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05C.html#transforming-the-data-frame-into-a-matrix",
    "title": "Hands-on Exercise 5C",
    "section": "14.3.3 Transforming the data frame into a matrix",
    "text": "14.3.3 Transforming the data frame into a matrix\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform wh data frame into a data matrix.\n\nwh1 &lt;- dplyr::select(wh, c(3, 7:12))\nwh_matrix &lt;- data.matrix(wh)\n\nNotice that wh_matrix is in R matrix format."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05C.html#heatmap-of-r-stats",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05C.html#heatmap-of-r-stats",
    "title": "Hands-on Exercise 5C",
    "section": "14.4.1 heatmap() of R Stats",
    "text": "14.4.1 heatmap() of R Stats\nIn this sub-section, we will plot a heatmap by using heatmap() of Base Stats. The code chunk is given below.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      Rowv=NA, Colv=NA)\n\n\n\n\nNote:\n\nBy default, heatmap() plots a cluster heatmap. The arguments Rowv=NA and Colv=NA are used to switch off the option of plotting the row and column dendrograms.\n\nTo plot a cluster heatmap, we just have to use the default as shown in the code chunk below.\n\nwh_heatmap &lt;- heatmap(wh_matrix)\n\n\n\n\nNote:\n\nThe order of both rows and columns is different compare to the native wh_matrix. This is because heatmap do a reordering using clusterisation: it calculates the distance between each pair of rows and columns and try to order them by similarity. Moreover, the corresponding dendrogram are provided beside the heatmap.\n\nHere, red cells denotes small values, and red small ones. This heatmap is not really informative. Indeed, the Happiness Score variable have relatively higher values, what makes that the other variables with small values all look the same. Thus, we need to normalize this matrix. This is done using the scale argument. It can be applied to rows or to columns following your needs.\nThe code chunk below normalises the matrix column-wise.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\nNotice that the values are scaled now. Also note that margins argument is used to ensure that the entire x-axis labels are displayed completely and, cexRow and cexCol arguments are used to define the font size used for y-axis and x-axis labels respectively."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05C.html#working-with-heatmaply",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05C.html#working-with-heatmaply",
    "title": "Hands-on Exercise 5C",
    "section": "14.5.1 Working with heatmaply",
    "text": "14.5.1 Working with heatmaply\n\nheatmaply(mtcars)\n\n\n\n\n\nThe code chunk below shows the basic syntax needed to create n interactive heatmap by using heatmaply package.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\nNote that:\n\nDifferent from heatmap(), for heatmaply() the default horizontal dendrogram is placed on the left hand side of the heatmap.\nThe text label of each raw, on the other hand, is placed on the right hand side of the heat map.\nWhen the x-axis marker labels are too long, they will be rotated by 135 degree from the north."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05C.html#data-trasformation",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05C.html#data-trasformation",
    "title": "Hands-on Exercise 5C",
    "section": "14.5.2 Data trasformation",
    "text": "14.5.2 Data trasformation\nWhen analysing multivariate data set, it is very common that the variables in the data sets includes values that reflect different types of measurement. In general, these variables’ values have their own range. In order to ensure that all the variables have comparable values, data transformation are commonly used before clustering.\nThree main data transformation methods are supported by heatmaply(), namely: scale, normalise and percentilse."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05C.html#scaling-method",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05C.html#scaling-method",
    "title": "Hands-on Exercise 5C",
    "section": "14.5.2.1 Scaling method",
    "text": "14.5.2.1 Scaling method\n\nWhen all variables are came from or assumed to come from some normal distribution, then scaling (i.e.: subtract the mean and divide by the standard deviation) would bring them all close to the standard normal distribution.\nIn such a case, each value would reflect the distance from the mean in units of standard deviation.\nThe scale argument in heatmaply() supports column and row scaling.\n\nThe code chunk below is used to scale variable values columewise.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05C.html#normalising-method",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05C.html#normalising-method",
    "title": "Hands-on Exercise 5C",
    "section": "14.5.2.2 Normalising method",
    "text": "14.5.2.2 Normalising method\n\nWhen variables in the data comes from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\n\nDifferent from Scaling, the normalise method is performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n14.5.2.3 Percentising method\n\nThis is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank.\nThis is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile.\nThe benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\nSimilar to Normalize method, the Percentize method is also performed on the input data set i.e. wh_matrix as shown in the code chunk below."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05C.html#clustering-algorithm",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05C.html#clustering-algorithm",
    "title": "Hands-on Exercise 5C",
    "section": "14.5.3 Clustering algorithm",
    "text": "14.5.3 Clustering algorithm\nheatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:\n\ndistfun: function used to compute the distance (dissimilarity) between both rows and columns. Defaults to dist. The options “pearson”, “spearman” and “kendall” can be used to use correlation-based clustering, which uses as.dist(1 - cor(t(x))) as the distance metric (using the specified correlation method).\nhclustfun: function used to compute the hierarchical clustering when Rowv or Colv are not dendrograms. Defaults to hclust.\ndist_method default is NULL, which results in “euclidean” to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is “dist”” hence this can be one of “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski”.\nhclust_method default is NULL, which results in “complete” method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of “ward.D”, “ward.D2”, “single”, “complete”, “average” (= UPGMA), “mcquitty” (= WPGMA), “median” (= WPGMC) or “centroid” (= UPGMC).\n\nIn general, a clustering model can be calibrated either manually or statistically."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05C.html#manual-approach",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05C.html#manual-approach",
    "title": "Hands-on Exercise 5C",
    "section": "14.5.4 Manual approach",
    "text": "14.5.4 Manual approach\nIn the code chunk below, the heatmap is plotted by using hierachical clustering algorithm with “Euclidean distance” and “ward.D” method.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05C.html#statistical-approach",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05C.html#statistical-approach",
    "title": "Hands-on Exercise 5C",
    "section": "14.5.5 Statistical approach",
    "text": "14.5.5 Statistical approach\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\nwh_d &lt;- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nThe output table shows that “average” method should be used because it gave the high optimum value.\nNext, find_k() is used to determine the optimal number of cluster.\n\nwh_clust &lt;- hclust(wh_d, method = \"average\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\nFigure above shows that k=3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05C.html#seriation",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05C.html#seriation",
    "title": "Hands-on Exercise 5C",
    "section": "14.5.6 Seriation",
    "text": "14.5.6 Seriation\nOne of the problems with hierarchical clustering is that it doesn’t actually place the rows in a definite order, it merely constrains the space of possible orderings. Take three items A, B and C. If you ignore reflections, there are three possible orderings: ABC, ACB, BAC. If clustering them gives you ((A+B)+C) as a tree, you know that C can’t end up between A and B, but it doesn’t tell you which way to flip the A+B cluster. It doesn’t tell you if the ABC ordering will lead to a clearer-looking heatmap than the BAC ordering.\nheatmaply uses the seriation package to find an optimal ordering of rows and columns. Optimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\nHere we meet our first seriation algorithm: Optimal Leaf Ordering (OLO). This algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\nThe default options is “OLO” (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)). Another option is “GW” (Gruvaeus and Wainer) which aims for the same goal but uses a potentially faster heuristic.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\n\n\n\n\nThe option “mean” gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\n\n\n\n\nThe option “none” gives us the dendrograms without any rotation that is based on the data matrix.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05C.html#working-with-colour-palettes",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05C.html#working-with-colour-palettes",
    "title": "Hands-on Exercise 5C",
    "section": "14.5.7 Working with colour palettes",
    "text": "14.5.7 Working with colour palettes\nThe default colour palette uses by heatmaply is viridis. heatmaply users, however, can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.\nIn the code chunk below, the Blues colour palette of rColorBrewer is used.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\",\n          colors = Blues)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05C.html#the-finishing-touch",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05C.html#the-finishing-touch",
    "title": "Hands-on Exercise 5C",
    "section": "14.5.8 The finishing touch",
    "text": "14.5.8 The finishing touch\nBeside providing a wide collection of arguments for meeting the statistical analysis needs, heatmaply also provides many plotting features to ensure cartographic quality heatmap can be produced.\nIn the code chunk below the following arguments are used:\n\nk_row is used to produce 5 groups.\nmargins is used to change the top margin to 60 and row margin to 200.\nfontsizw_row and fontsize_col are used to change the font size for row and column labels to 4.\nmain is used to write the main title of the plot.\nxlab and ylab are used to write the x-axis and y-axis labels respectively.\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#the-data",
    "title": "Hands-on Exercise 5A",
    "section": "13.3.1 The data",
    "text": "13.3.1 The data\nFor the purpose of this hands-on exercise, the Singapore Residents by Planning AreaSubzone, Age Group, Sex and Type of Dwelling, June 2000-2018 data will be used. The data set has been downloaded and included in the data sub-folder of the hands-on exercise folder. It is called respopagsex2000to2018_tidy.csv and is in csv file format."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#importing-data",
    "title": "Hands-on Exercise 5A",
    "section": "13.3.2 Importing Data",
    "text": "13.3.2 Importing Data\nTo important respopagsex2000to2018_tidy.csv into R, read_csv() function of readr package will be used.\n\n#Reading the data into R environment\npop_data &lt;- read_csv(\"../../data/respopagsex2000to2018_tidy.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#preparing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#preparing-the-data",
    "title": "Hands-on Exercise 5A",
    "section": "13.3.3 Preparing the Data",
    "text": "13.3.3 Preparing the Data\nNext, use the mutate() function of dplyr package to derive three new measures, namely: young, active, and old.\n\n#Deriving the young, economy active and old measures\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year))%&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8]))%&gt;%\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018)%&gt;%\n  filter(TOTAL &gt; 0)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#plotting-a-static-ternary-diagram",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#plotting-a-static-ternary-diagram",
    "title": "Hands-on Exercise 5A",
    "section": "13.4.1 4.1 Plotting a static ternary diagram",
    "text": "13.4.1 4.1 Plotting a static ternary diagram\nUse ggtern() function of ggtern package to create a simple ternary plot.\n\n#Building the static ternary plot\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\n#Building the static ternary plot\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#plotting-an-interative-ternary-diagram",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#plotting-an-interative-ternary-diagram",
    "title": "Hands-on Exercise 5A",
    "section": "13.4.2 Plotting an interative ternary diagram",
    "text": "13.4.2 Plotting an interative ternary diagram\nThe code below create an interactive ternary plot using plot_ly() function of Plotly R.\n\n# reusable function for creating annotation object\nlabel &lt;- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05D.html#plotting-a-simple-parallel-coordinates",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05D.html#plotting-a-simple-parallel-coordinates",
    "title": "Hands-on Exercise 5D",
    "section": "15.4.1 Plotting a simple parallel coordinates",
    "text": "15.4.1 Plotting a simple parallel coordinates\nCode chunk below shows a typical syntax used to plot a basic static parallel coordinates plot by using ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12))\n\n\n\n\nNotice that only two argument namely data and columns is used. Data argument is used to map the data object (i.e. wh) and columns is used to select the columns for preparing the parallel coordinates plot."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05D.html#plotting-a-parallel-coordinates-with-boxplot",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05D.html#plotting-a-parallel-coordinates-with-boxplot",
    "title": "Hands-on Exercise 5D",
    "section": "15.4.2 Plotting a parallel coordinates with boxplot",
    "text": "15.4.2 Plotting a parallel coordinates with boxplot\nThe basic parallel coordinates failed to reveal any meaning understanding of the World Happiness measures. In this section, you will learn how to makeover the plot by using a collection of arguments provided by ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")\n\n\n\n\nThings to learn from the code chunk above.\n\ngroupColumn argument is used to group the observations (i.e. parallel lines) by using a single variable (i.e. Region) and colour the parallel coordinates lines by region name.\nscale argument is used to scale the variables in the parallel coordinate plot by using uniminmax method. The method univariately scale each variable so the minimum of the variable is zero and the maximum is one.\nalphaLines argument is used to reduce the intensity of the line colour to 0.2. The permissible value range is between 0 to 1.\nboxplot argument is used to turn on the boxplot by using logical TRUE. The default is FALSE.\ntitle argument is used to provide the parallel coordinates plot a title."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05D.html#parallel-coordinates-with-facet",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05D.html#parallel-coordinates-with-facet",
    "title": "Hands-on Exercise 5D",
    "section": "15.4.3 Parallel coordinates with facet",
    "text": "15.4.3 Parallel coordinates with facet\nSince ggparcoord() is developed by extending ggplot2 package, we can combination use some of the ggplot2 function when plotting a parallel coordinates plot.\nIn the code chunk below, facet_wrap() of ggplot2 is used to plot 10 small multiple parallel coordinates plots. Each plot represent one geographical region such as East Asia.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region)\n\n\n\n\nOne of the aesthetic defect of the current design is that some of the variable names overlap on x-axis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05D.html#rotating-x-axis-text-label",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05D.html#rotating-x-axis-text-label",
    "title": "Hands-on Exercise 5D",
    "section": "15.4.4 Rotating x-axis text label",
    "text": "15.4.4 Rotating x-axis text label\nTo make the x-axis text label easy to read, let us rotate the labels by 30 degrees. We can rotate axis text labels using theme() function in ggplot2 as shown in the code chunk below.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\nThing to learn from the code chunk above:\n\nTo rotate x-axis text labels, we use axis.text.x as argument to theme() function. And we specify element_text(angle = 30) to rotate the x-axis text by an angle 30 degree."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05D.html#adjusting-the-rotated-x-axis-text-label",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05D.html#adjusting-the-rotated-x-axis-text-label",
    "title": "Hands-on Exercise 5D",
    "section": "15.4.5 Adjusting the rotated x-axis text label",
    "text": "15.4.5 Adjusting the rotated x-axis text label\nRotating x-axis text labels to 30 degrees makes the label overlap with the plot and we can avoid this by adjusting the text location using hjust argument to theme’s text element with element_text(). We use axis.text.x as we want to change the look of x-axis text.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30, hjust=1))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05D.html#the-basic-plot",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05D.html#the-basic-plot",
    "title": "Hands-on Exercise 5D",
    "section": "15.5.1 The basic plot",
    "text": "15.5.1 The basic plot\nThe code chunk below plot an interactive parallel coordinates plot by using parallelPlot().\n\nwh &lt;- wh %&gt;%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250)\n\n\n\n\n\nNotice that some of the axis labels are too long. You will learn how to overcome this problem in the next step."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05D.html#rotate-axis-label",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05D.html#rotate-axis-label",
    "title": "Hands-on Exercise 5D",
    "section": "15.5.2 Rotate axis label",
    "text": "15.5.2 Rotate axis label\nIn the code chunk below, rotateTitle argument is used to avoid overlapping axis labels.\n\nparallelPlot(wh,\n             rotateTitle = TRUE)\n\n\n\n\n\nOne of the useful interactive feature of parallelPlot is we can click on a variable of interest, for example Happiness score, the monotonous blue colour (default) will change a blues with different intensity colour scheme will be used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05D.html#changing-the-colour-scheme",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05D.html#changing-the-colour-scheme",
    "title": "Hands-on Exercise 5D",
    "section": "15.5.3 Changing the colour scheme",
    "text": "15.5.3 Changing the colour scheme\nWe can change the default blue colour scheme by using continousCS argument as shown in the code chunl below.\n\nparallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05D.html#parallel-coordinates-plot-with-histogram",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05D.html#parallel-coordinates-plot-with-histogram",
    "title": "Hands-on Exercise 5D",
    "section": "15.5.4 Parallel coordinates plot with histogram",
    "text": "15.5.4 Parallel coordinates plot with histogram\nIn the code chunk below, histoVisibility argument is used to plot histogram along the axis of each variables.\n\nhistoVisibility &lt;- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#tooltip-effect-with-tooltip-aesthetic",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#tooltip-effect-with-tooltip-aesthetic",
    "title": "Hands-on Exercise 3",
    "section": "3.4.1 Tooltip effect with tooltip aesthetic",
    "text": "3.4.1 Tooltip effect with tooltip aesthetic\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts. First, an ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\nNotice that two steps are involved. First, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#displaying-multiple-information-on-tooltip",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#displaying-multiple-information-on-tooltip",
    "title": "Hands-on Exercise 3",
    "section": "3.5.1 Displaying multiple information on tooltip",
    "text": "3.5.1 Displaying multiple information on tooltip\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\nexam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#customising-tooltip-style",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#customising-tooltip-style",
    "title": "Hands-on Exercise 3",
    "section": "3.6.1 Customising Tooltip style",
    "text": "3.6.1 Customising Tooltip style\nCode chunk below uses opts_tooltip() of ggiraph to customize tooltip rendering by add css declarations.\n\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\n# Notice that the background colour of the tooltip is black and the font colour is white and bold.\n\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#displaying-statistics-on-tooltip",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#displaying-statistics-on-tooltip",
    "title": "Hands-on Exercise 3",
    "section": "3.6.2 Displaying statistics on tooltip",
    "text": "3.6.2 Displaying statistics on tooltip\nCode chunk below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#hover-effect-with-data_id-aesthetic",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#hover-effect-with-data_id-aesthetic",
    "title": "Hands-on Exercise 3",
    "section": "3.6.3 Hover effect with data_id aesthetic",
    "text": "3.6.3 Hover effect with data_id aesthetic\nCode chunk below shows the second interactive feature of ggiraph, namely data_id.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\n# Interactivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                        \n\n\n\n\n\nNote that the default value of the hover css is hover_css = “fill:orange;”."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#styling-hover-effect",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#styling-hover-effect",
    "title": "Hands-on Exercise 3",
    "section": "3.6.4 Styling hover effect",
    "text": "3.6.4 Styling hover effect\nIn the code chunk below, css codes are used to change the highlighting effect.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID, data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\n# Interactivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\nNote: Different from previous example, in this example the ccs customisation request are encoded directly."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#combining-tooltip-and-hover-effect",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#combining-tooltip-and-hover-effect",
    "title": "Hands-on Exercise 3",
    "section": "3.6.5 Combining tooltip and hover effect",
    "text": "3.6.5 Combining tooltip and hover effect\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\n# Interactivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#click-effect-with-onclick",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#click-effect-with-onclick",
    "title": "Hands-on Exercise 3",
    "section": "3.6.6 Click effect with onclick",
    "text": "3.6.6 Click effect with onclick\nonclick argument of ggiraph provides hotlink interactivity on the web.\nThe code chunk below shown an example of onclick.\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n# Interactivity: Web document link with a data object will be displayed on the web browser upon mouse click.\n\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#coordinated-multiple-views-with-ggiraph",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#coordinated-multiple-views-with-ggiraph",
    "title": "Hands-on Exercise 3",
    "section": "3.6.7 Coordinated Multiple Views with ggiraph",
    "text": "3.6.7 Coordinated Multiple Views with ggiraph\nCoordinated multiple views methods has been implemented in the data visualisation below.\n\n\n\n\n\n\nNotice that when a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\nIn order to build a coordinated multiple views as shown in the example above, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\n\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2), \n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\nThe data_id aesthetic is critical to link observations between plots and the tooltip aesthetic is optional but nice to have when mouse over a point."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-an-interactive-scatter-plot-plot_ly-method",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-an-interactive-scatter-plot-plot_ly-method",
    "title": "Hands-on Exercise 3",
    "section": "3.7.1 Creating an interactive scatter plot: plot_ly() method",
    "text": "3.7.1 Creating an interactive scatter plot: plot_ly() method\nThe tabset below shows an example a basic interactive plot created by using plot_ly().\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#working-with-visual-variable-plot_ly-method",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#working-with-visual-variable-plot_ly-method",
    "title": "Hands-on Exercise 3",
    "section": "3.7.2 Working with visual variable: plot_ly() method",
    "text": "3.7.2 Working with visual variable: plot_ly() method\nIn the code chunk below, color argument is mapped to a qualitative visual variable (i.e. RACE).\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-an-interactive-scatter-plot-ggplotly-method",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-an-interactive-scatter-plot-ggplotly-method",
    "title": "Hands-on Exercise 3",
    "section": "3.7.3 Creating an interactive scatter plot: ggplotly() method",
    "text": "3.7.3 Creating an interactive scatter plot: ggplotly() method\nThe code chunk below plots an interactive scatter plot by using ggplotly().\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#coordinated-multiple-views-with-plotly",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#coordinated-multiple-views-with-plotly",
    "title": "Hands-on Exercise 3",
    "section": "3.7.4 Coordinated Multiple Views with plotly",
    "text": "3.7.4 Coordinated Multiple Views with plotly\nThe creation of a coordinated linked plot by using plotly involves three steps:\n\nhighlight_key() of plotly package is used as shared data.\ntwo scatterplots will be created by using ggplot2 functions.\nlastly, subplot() of plotly package is used to place them next to each other side-by-side.\n\n\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\n\n\nThing to learn from the code chunk:\n\nhighlight_key() simply creates an object of class crosstalk::SharedData."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-table-dt-package",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-table-dt-package",
    "title": "Hands-on Exercise 3",
    "section": "3.8.1 Interactive Data Table: DT package",
    "text": "3.8.1 Interactive Data Table: DT package\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\nDT::datatable(exam_data, class= \"compact\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#linked-brushing-crosstalk-method",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#linked-brushing-crosstalk-method",
    "title": "Hands-on Exercise 3",
    "section": "3.8.2 Linked brushing: crosstalk method",
    "text": "3.8.2 Linked brushing: crosstalk method\nCode chunk below is used to implement the coordinated brushing shown below.\n\nd &lt;- highlight_key(exam_data) \np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)        \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk:\n\nhighlight() is a function of plotly package. It sets a variety of options for brushing (i.e., highlighting) multiple plots. These options are primarily designed for linking multiple plotly graphs, and may not behave as expected when linking plotly to another htmlwidget package via crosstalk. In some cases, other htmlwidgets will respect these options, such as persistent selection in leaflet.\nbscols() is a helper function of crosstalk package. It makes it easy to put HTML elements side by side. It can be called directly from the console but is especially designed to work in an R Markdown document. Warning: This will bring in all of Bootstrap!"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#ggiraph",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#ggiraph",
    "title": "Hands-on Exercise 3",
    "section": "3.9.1 ggiraph",
    "text": "3.9.1 ggiraph\nThis link provides online version of the reference guide and several useful articles. Use this link to download the pdf version of the reference guide.\n\nHow to Plot With Ggiraph\nInteractive map of France with ggiraph\nCustom interactive sunbursts with ggplot in R\nThis link provides code example on how ggiraph is used to interactive graphs for Swiss Olympians - the solo specialists."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#plotly-for-r",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#plotly-for-r",
    "title": "Hands-on Exercise 3",
    "section": "3.9.2 plotly for R",
    "text": "3.9.2 plotly for R\n\nGetting Started with Plotly in R\nA collection of plotly R graphs are available via this link.\nCarson Sievert (2020) Interactive web-based data visualization with R, plotly, and shiny, Chapman and Hall/CRC is the best resource to learn plotly for R. The online version is available via this link\nPlotly R Figure Reference provides a comprehensive discussion of each visual representations.\nPlotly R Library Fundamentals is a good place to learn the fundamental features of Plotly’s R API.\nGetting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#basic-concepts-of-animation",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#basic-concepts-of-animation",
    "title": "Hands-on Exercise 3",
    "section": "4.1.1 Basic concepts of animation",
    "text": "4.1.1 Basic concepts of animation\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#terminology",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#terminology",
    "title": "Hands-on Exercise 3",
    "section": "4.1.2 Terminology",
    "text": "4.1.2 Terminology\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#loading-the-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#loading-the-r-packages",
    "title": "Hands-on Exercise 3",
    "section": "4.2.1 Loading the R packages",
    "text": "4.2.1 Loading the R packages\nFirst, write a code chunk to check, install and load the following R packages:\n\nplotly, R library for plotting interactive statistical graphs.\ngganimate, an ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\n\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-the-data",
    "title": "Hands-on Exercise 3",
    "section": "4.2.2 Importing the data",
    "text": "4.2.2 Importing the data\nIn this hands-on exercise, the Data worksheet from GlobalPopulation Excel workbook will be used.\nWrite a code chunk to import Data worksheet from GlobalPopulation Excel workbook by using appropriate R package from tidyverse family.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"../../data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_each_(funs(factor(.)), col) %&gt;%\n  mutate(Year = as.integer(Year))\n\nUnfortunately, mutate_each_() was deprecated in dplyr 0.7.0. and funs() was deprecated in dplyr 0.8.0. In view of this, we will re-write the code by using mutate_at() as shown in the code chunk below.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"../../data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))\n\nInstead of using mutate_at(), across() can be used to derive the same outputs.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"../../data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate(across(col, as.factor)) %&gt;%\n  mutate(Year = as.integer(Year))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#building-a-static-population-bubble-plot",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#building-a-static-population-bubble-plot",
    "title": "Hands-on Exercise 3",
    "section": "4.3.1 Building a static population bubble plot",
    "text": "4.3.1 Building a static population bubble plot\nIn the code chunk below, the basic ggplot2 functions are used to create a static bubble plot.\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#building-the-animated-bubble-plot",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#building-the-animated-bubble-plot",
    "title": "Hands-on Exercise 3",
    "section": "4.3.2 Building the animated bubble plot",
    "text": "4.3.2 Building the animated bubble plot\nIn the code chunk below,\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year).\nease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\n# The animated bubble chart\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#building-an-animated-bubble-plot-ggplotly-method",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#building-an-animated-bubble-plot-ggplotly-method",
    "title": "Hands-on Exercise 3",
    "section": "4.4.1 Building an animated bubble plot: ggplotly() method",
    "text": "4.4.1 Building an animated bubble plot: ggplotly() method\nIn this sub-section, you will learn how to create an animated bubble plot by using ggplotly() method.\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young')\n\nggplotly(gg)\n\n\n\n\n\nNotice that although show.legend = FALSE argument was used, the legend still appears on the plot. To overcome this problem, theme(legend.position=‘none’) should be used as shown in the plot and code chunk below.\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') + \n  theme(legend.position='none')\n\nggplotly(gg)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#building-an-animated-bubble-plot-plot_ly-method",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#building-an-animated-bubble-plot-plot_ly-method",
    "title": "Hands-on Exercise 3",
    "section": "4.4.2 Building an animated bubble plot: plot_ly() method",
    "text": "4.4.2 Building an animated bubble plot: plot_ly() method\nIn this sub-section, you will learn how to create an animated bubble plot by using plot_ly() method.\n\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent,\n          sizes = c(2, 100),\n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %&gt;%\n  layout(showlegend = FALSE)\nbp"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#installing-and-loading-the-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#installing-and-loading-the-packages",
    "title": "Hands-on Exercise 4",
    "section": "9.2.1 Installing and loading the packages",
    "text": "9.2.1 Installing and loading the packages\nFor the purpose of this exercise, the following R packages will be used, they are:\n\ntidyverse, a family of R packages for data science process,\nggridges, a ggplot2 extension specially designed for plotting ridgeline plots, and\nggdist for visualising distribution and uncertainty.\n\n\npacman::p_load(ggdist, ggridges, ggthemes,\n               colorspace, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#data-import",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#data-import",
    "title": "Hands-on Exercise 4",
    "section": "9.2.2 Data import",
    "text": "9.2.2 Data import\nFor the purpose of this exercise, Exam_data.csv will be used.\n\nexam &lt;- read_csv(\"../../data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#varying-fill-colors-along-the-x-axis",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#varying-fill-colors-along-the-x-axis",
    "title": "Hands-on Exercise 4",
    "section": "9.3.2 Varying fill colors along the x axis",
    "text": "9.3.2 Varying fill colors along the x axis\nSometimes we would like to have the area under a ridgeline not filled with a single solid color but rather with colors that vary in some form along the x axis. This effect can be achieved by using either geom_ridgeline_gradient() or geom_density_ridges_gradient(). Both geoms work just like geom_ridgeline() and geom_density_ridges(), except that they allow for varying fill colors. However, they do not allow for alpha transparency in the fill. For technical reasons, we can have changing fill colors or transparency but not both.\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#mapping-the-probabilities-directly-onto-colour",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#mapping-the-probabilities-directly-onto-colour",
    "title": "Hands-on Exercise 4",
    "section": "9.3.3 Mapping the probabilities directly onto colour",
    "text": "9.3.3 Mapping the probabilities directly onto colour\nBeside providing additional geom objects to support the need to plot ridgeline plot, ggridges package also provides a stat function called stat_density_ridges() that replaces stat_density() of ggplot2.\nFigure below is plotted by mapping the probabilities calculated by using stat(ecdf) which represent the empirical cumulative density function for the distribution of English score.\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#ridgeline-plots-with-quantile-lines",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#ridgeline-plots-with-quantile-lines",
    "title": "Hands-on Exercise 4",
    "section": "9.3.4 Ridgeline plots with quantile lines",
    "text": "9.3.4 Ridgeline plots with quantile lines\nBy using geom_density_ridges_gradient(), we can colour the ridgeline plot by quantile, via the calculated stat(quantile) aesthetic as shown in the figure below.\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n\n\n\n\nInstead of using number to define the quantiles, we can also specify quantiles by cut points such as 2.5% and 97.5% tails to colour the ridgeline plot as shown in the figure below.\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#plotting-a-half-eye-graph",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#plotting-a-half-eye-graph",
    "title": "Hands-on Exercise 4",
    "section": "9.4.1 Plotting a Half Eye graph",
    "text": "9.4.1 Plotting a Half Eye graph\nFirst, we will plot a Half-Eye graph by using stat_halfeye() of ggdist package.\nThis produces a Half Eye visualization, which is contains a half-density and a slab-interval.\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#adding-the-boxplot-with-geom_boxplot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#adding-the-boxplot-with-geom_boxplot",
    "title": "Hands-on Exercise 4",
    "section": "9.4.2 Adding the boxplot with geom_boxplot()",
    "text": "9.4.2 Adding the boxplot with geom_boxplot()\nNext, we will add the second geometry layer using geom_boxplot() of ggplot2. This produces a narrow boxplot. We reduce the width and adjust the opacity.\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#adding-the-dot-plots-with-stat_dots",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#adding-the-dot-plots-with-stat_dots",
    "title": "Hands-on Exercise 4",
    "section": "9.4.3 Adding the Dot Plots with stat_dots()",
    "text": "9.4.3 Adding the Dot Plots with stat_dots()\nNext, we will add the third geometry layer using stat_dots() of ggdist package. This produces a half-dotplot, which is similar to a histogram that indicates the number of samples (number of dots) in each bin. We select side = “left” to indicate we want it on the left-hand side.\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#finishing-touch",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#finishing-touch",
    "title": "Hands-on Exercise 4",
    "section": "9.4.4 Finishing touch",
    "text": "9.4.4 Finishing touch\nLastly, coord_flip() of ggplot2 package will be used to flip the raincloud chart horizontally to give it the raincloud appearance. At the same time, theme_economist() of ggthemes package is used to give the raincloud chart a professional publishing standard look.\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 4",
    "section": "10.3.1 Installing and launching R packages",
    "text": "10.3.1 Installing and launching R packages\nIn this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#importing-data",
    "title": "Hands-on Exercise 4",
    "section": "10.3.2 Importing data",
    "text": "10.3.2 Importing data\n\nexam &lt;- read_csv(\"../../data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#one-sample-test-gghistostats-method",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#one-sample-test-gghistostats-method",
    "title": "Hands-on Exercise 4",
    "section": "10.3.3 One-sample test: gghistostats() method",
    "text": "10.3.3 One-sample test: gghistostats() method\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#unpacking-the-bayes-factor",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#unpacking-the-bayes-factor",
    "title": "Hands-on Exercise 4",
    "section": "10.3.4 Unpacking the Bayes Factor",
    "text": "10.3.4 Unpacking the Bayes Factor\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10.\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#how-to-interpret-bayes-factor",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#how-to-interpret-bayes-factor",
    "title": "Hands-on Exercise 4",
    "section": "10.3.5 How to interpret Bayes Factor",
    "text": "10.3.5 How to interpret Bayes Factor\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#two-sample-mean-test-ggbetweenstats",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#two-sample-mean-test-ggbetweenstats",
    "title": "Hands-on Exercise 4",
    "section": "10.3.6 Two-sample mean test: ggbetweenstats()",
    "text": "10.3.6 Two-sample mean test: ggbetweenstats()\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#oneway-anova-test-ggbetweenstats-method",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#oneway-anova-test-ggbetweenstats-method",
    "title": "Hands-on Exercise 4",
    "section": "10.3.7 Oneway ANOVA Test: ggbetweenstats() method",
    "text": "10.3.7 Oneway ANOVA Test: ggbetweenstats() method\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#significant-test-of-correlation-ggscatterstats",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#significant-test-of-correlation-ggscatterstats",
    "title": "Hands-on Exercise 4",
    "section": "10.3.8 Significant Test of Correlation: ggscatterstats()",
    "text": "10.3.8 Significant Test of Correlation: ggscatterstats()\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#significant-test-of-association-depedence-ggbarstats-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#significant-test-of-association-depedence-ggbarstats-methods",
    "title": "Hands-on Exercise 4",
    "section": "10.3.9 Significant Test of Association (Depedence) : ggbarstats() methods",
    "text": "10.3.9 Significant Test of Association (Depedence) : ggbarstats() methods\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association.\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#importing-excel-file-readxl-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#importing-excel-file-readxl-methods",
    "title": "Hands-on Exercise 4",
    "section": "10.6.1 Importing Excel file: readxl methods",
    "text": "10.6.1 Importing Excel file: readxl methods\nIn the code chunk below, read_xls() of readxl package is used to import the data worksheet of ToyotaCorolla.xls workbook into R.\n\ncar_resale &lt;- read_xls(\"../../data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …\n\n\nNotice that the output object car_resale is a tibble data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#multiple-regression-model-using-lm",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#multiple-regression-model-using-lm",
    "title": "Hands-on Exercise 4",
    "section": "10.6.2 Multiple Regression Model using lm()",
    "text": "10.6.2 Multiple Regression Model using lm()\nThe code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#model-diagnostic-checking-for-multicolinearity",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#model-diagnostic-checking-for-multicolinearity",
    "title": "Hands-on Exercise 4",
    "section": "10.6.3 Model Diagnostic: checking for multicolinearity:",
    "text": "10.6.3 Model Diagnostic: checking for multicolinearity:\nIn the code chunk, check_collinearity() of performance package.\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#model-diagnostic-checking-normality-assumption",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#model-diagnostic-checking-normality-assumption",
    "title": "Hands-on Exercise 4",
    "section": "10.6.4 Model Diagnostic: checking normality assumption",
    "text": "10.6.4 Model Diagnostic: checking normality assumption\nIn the code chunk, check_normality() of performance package.\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\n\ncheck_n &lt;- check_normality(model1)\n\n\nplot(check_n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#model-diagnostic-check-model-for-homogeneity-of-variances",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#model-diagnostic-check-model-for-homogeneity-of-variances",
    "title": "Hands-on Exercise 4",
    "section": "10.6.5 Model Diagnostic: Check model for homogeneity of variances",
    "text": "10.6.5 Model Diagnostic: Check model for homogeneity of variances\nIn the code chunk, check_heteroscedasticity() of performance package.\n\ncheck_h &lt;- check_heteroscedasticity(model1)\n\n\nplot(check_h)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#model-diagnostic-complete-check",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#model-diagnostic-complete-check",
    "title": "Hands-on Exercise 4",
    "section": "10.6.6 Model Diagnostic: Complete check",
    "text": "10.6.6 Model Diagnostic: Complete check\nWe can also perform the complete by using check_model().\n\ncheck_model(model1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-regression-parameters-see-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-regression-parameters-see-methods",
    "title": "Hands-on Exercise 4",
    "section": "10.6.7 Visualising Regression Parameters: see methods",
    "text": "10.6.7 Visualising Regression Parameters: see methods\nIn the code below, plot() of see package and parameters() of parameters package is used to visualise the parameters of a regression model.\n\nplot(parameters(model1))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-regression-parameters-ggcoefstats-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-regression-parameters-ggcoefstats-methods",
    "title": "Hands-on Exercise 4",
    "section": "10.6.8 Visualising Regression Parameters: ggcoefstats() methods",
    "text": "10.6.8 Visualising Regression Parameters: ggcoefstats() methods\nIn the code below, ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#installing-and-loading-the-packages-1",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#installing-and-loading-the-packages-1",
    "title": "Hands-on Exercise 4",
    "section": "11.2.1 Installing and loading the packages",
    "text": "11.2.1 Installing and loading the packages\nFor the purpose of this exercise, the following R packages will be used, they are:\n\ntidyverse, a family of R packages for data science process,\nplotly for creating interactive plot,\ngganimate for creating animation plot,\nDT for displaying interactive html table,\ncrosstalk for for implementing cross-widget interactions (currently, linked brushing and filtering), and\nggdist for visualising distribution and uncertainty.\n\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\n\npacman::p_load(ungeviz, plotly, crosstalk,\n               DT, ggdist, ggridges,\n               colorspace, gganimate, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#data-import-1",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#data-import-1",
    "title": "Hands-on Exercise 4",
    "section": "11.2.2 Data import",
    "text": "11.2.2 Data import\nFor the purpose of this exercise, Exam_data.csv will be used.\n\nexam &lt;- read_csv(\"../../data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#plotting-standard-error-bars-of-point-estimates",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#plotting-standard-error-bars-of-point-estimates",
    "title": "Hands-on Exercise 4",
    "section": "11.3.1 Plotting standard error bars of point estimates",
    "text": "11.3.1 Plotting standard error bars of point estimates\nNow we are ready to plot the standard error bars of mean maths score by race as shown below.\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by rac\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#plotting-confidence-interval-of-point-estimates",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#plotting-confidence-interval-of-point-estimates",
    "title": "Hands-on Exercise 4",
    "section": "11.3.2 Plotting confidence interval of point estimates",
    "text": "11.3.2 Plotting confidence interval of point estimates\nInstead of plotting the standard error bar of point estimates, we can also plot the confidence intervals of mean maths score by race.\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-the-uncertainty-of-point-estimates-with-interactive-error-bars",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-the-uncertainty-of-point-estimates-with-interactive-error-bars",
    "title": "Hands-on Exercise 4",
    "section": "11.3.3 Visualizing the uncertainty of point estimates with interactive error bars",
    "text": "11.3.3 Visualizing the uncertainty of point estimates with interactive error bars\nIn this section, you will learn how to plot interactive error bars for the 99% confidence interval of mean maths score by race as shown in the figure below.\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average /&lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-the-uncertainty-of-point-estimates-ggdist-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-the-uncertainty-of-point-estimates-ggdist-methods",
    "title": "Hands-on Exercise 4",
    "section": "11.4.1 Visualizing the uncertainty of point estimates: ggdist methods",
    "text": "11.4.1 Visualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\nThis function comes with many arguments. For example, in the code chunk below the following arguments are used:\n.width = 0.95 .point = median .interval = qi\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-the-uncertainty-of-point-estimates-ggdist-methods-1",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-the-uncertainty-of-point-estimates-ggdist-methods-1",
    "title": "Hands-on Exercise 4",
    "section": "11.4.2 Visualizing the uncertainty of point estimates: ggdist methods",
    "text": "11.4.2 Visualizing the uncertainty of point estimates: ggdist methods\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval(\n    show.legend = FALSE) +   \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-the-uncertainty-of-point-estimates-ggdist-methods-2",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-the-uncertainty-of-point-estimates-ggdist-methods-2",
    "title": "Hands-on Exercise 4",
    "section": "11.4.3 Visualizing the uncertainty of point estimates: ggdist methods",
    "text": "11.4.3 Visualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#funnelplotr-methods-makeover-1",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#funnelplotr-methods-makeover-1",
    "title": "Hands-on Exercise 4",
    "section": "12.4.2 FunnelPlotR methods: Makeover 1",
    "text": "12.4.2 FunnelPlotR methods: Makeover 1\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  numerator = covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",     #&lt;&lt;\n  xrange = c(0, 6500),  #&lt;&lt;\n  yrange = c(0, 0.05)   #&lt;&lt;\n)\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThings to learn from the code chunk above. + data_type argument is used to change from default “SR” to “PR” (i.e. proportions). + xrange and yrange are used to set the range of x-axis and y-axis"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#funnelplotr-methods-makeover-2",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#funnelplotr-methods-makeover-2",
    "title": "Hands-on Exercise 4",
    "section": "12.4.3 FunnelPlotR methods: Makeover 2",
    "text": "12.4.3 FunnelPlotR methods: Makeover 2\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  numerator = covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #&lt;&lt;           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"  #&lt;&lt;\n)\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThings to learn from the code chunk above.\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-the-basic-derived-fields",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-the-basic-derived-fields",
    "title": "Hands-on Exercise 4",
    "section": "12.5.1 Computing the basic derived fields",
    "text": "12.5.1 Computing the basic derived fields\nTo plot the funnel plot from scratch, we need to derive cumulative death rate and standard error of cumulative death rate.\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#calculate-lower-and-upper-limits-for-95-and-99.9-ci",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#calculate-lower-and-upper-limits-for-95-and-99.9-ci",
    "title": "Hands-on Exercise 4",
    "section": "12.5.2 Calculate lower and upper limits for 95% and 99.9% CI",
    "text": "12.5.2 Calculate lower and upper limits for 95% and 99.9% CI\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#plotting-a-static-funnel-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#plotting-a-static-funnel-plot",
    "title": "Hands-on Exercise 4",
    "section": "12.5.3 Plotting a static funnel plot",
    "text": "12.5.3 Plotting a static funnel plot\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#interactive-funnel-plot-plotly-ggplot2",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#interactive-funnel-plot-plotly-ggplot2",
    "title": "Hands-on Exercise 4",
    "section": "12.5.4 Interactive Funnel Plot: plotly + ggplot2",
    "text": "12.5.4 Interactive Funnel Plot: plotly + ggplot2\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "In this chapter, you will be introduced to several ggplot2 extensions for creating more elegant and effective statistical graphics. By the end of this exercise, you will be able to:\n\ncontrol the placement of annotation on a graph by using functions provided in ggrepel package,\ncreate professional publication quality figure by using functions provided in ggthemes and hrbrthemes packages,\nplot composite figure by combining ggplot2 graphs by using patchwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#installing-and-loading-the-required-libraries",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#installing-and-loading-the-required-libraries",
    "title": "Hands-on Exercise 2",
    "section": "2.2.1 Installing and loading the required libraries",
    "text": "2.2.1 Installing and loading the required libraries\nIn this exercise, beside tidyverse, four R packages will be used. They are:\n\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’.\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2.\npatchwork: an R package for preparing composite figure created using ggplot2.\n\nCode chunk below will be used to check if these packages have been installed and also will load them onto your working R environment.\n\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-data",
    "title": "Hands-on Exercise 2",
    "section": "2.2.2 Importing data",
    "text": "2.2.2 Importing data\n\nexam_data &lt;- read_csv(\"../../data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggrepel",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggrepel",
    "title": "Hands-on Exercise 2",
    "section": "2.3.1 Working with ggrepel",
    "text": "2.3.1 Working with ggrepel\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggtheme-package",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggtheme-package",
    "title": "Hands-on Exercise 2",
    "section": "2.4.1 Working with ggtheme package",
    "text": "2.4.1 Working with ggtheme package\nggthemes provides ‘ggplot2’ themes that replicate the look of plots by Edward Tufte, Stephen Few, Fivethirtyeight, The Economist, ‘Stata’, ‘Excel’, and The Wall Street Journal, among others.\nIn the example below, The Economist theme is used.\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-hrbthems-package",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-hrbthems-package",
    "title": "Hands-on Exercise 2",
    "section": "2.4.2 Working with hrbthems package",
    "text": "2.4.2 Working with hrbthems package\nhrbrthemes package provides a base theme that focuses on typographic elements, including where various labels are placed as well as the fonts that are used.\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\n\n\n\nThe second goal centers around productivity for a production workflow. In fact, this “production workflow” is the context for where the elements of hrbrthemes should be used.\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size = 18,\n              base_size = 15,\n              grid = \"Y\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-composite-graphics-pathwork-methods",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-composite-graphics-pathwork-methods",
    "title": "Hands-on Exercise 2",
    "section": "2.5.1 Creating Composite Graphics: pathwork methods",
    "text": "2.5.1 Creating Composite Graphics: pathwork methods\nThere are several ggplot2 extension’s functions support the needs to prepare composite figure by combining several graphs such as grid.arrange() of gridExtra package and plot_grid() of cowplot package. In this section, I am going to shared with you an ggplot2 extension called patchwork which is specially designed for combining separate ggplot2 graphs into a single figure.\nPatchwork package has a very simple syntax where we can create layouts super easily. Here’s the general syntax that combines:\n\nTwo-Column Layout using the Plus Sign +.\nParenthesis () to create a subplot group.\nTwo-Row Layout using the Division Sign /"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-two-ggplot2-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-two-ggplot2-graphs",
    "title": "Hands-on Exercise 2",
    "section": "2.5.2 Combining two ggplot2 graphs",
    "text": "2.5.2 Combining two ggplot2 graphs\nFigure in the tabset below shows a composite of two histograms created using patchwork. Note how simple the syntax used to create the plot!\n\np1 + p2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-three-ggplot2-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-three-ggplot2-graphs",
    "title": "Hands-on Exercise 2",
    "section": "2.5.3 Combining three ggplot2 graphs",
    "text": "2.5.3 Combining three ggplot2 graphs\nWe can plot more complex composite by using appropriate operators. For example, the composite figure below is plotted by using:\n\n“|” operator to stack two ggplot2 graphs,\n“/” operator to place the plots beside each other,\n“()” operator the define the sequence of the plotting.\n\n\n(p1 / p2) | p3"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-composite-figure-with-tag",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-composite-figure-with-tag",
    "title": "Hands-on Exercise 2",
    "section": "2.5.4 Creating a composite figure with tag",
    "text": "2.5.4 Creating a composite figure with tag\nIn order to identify subplots in text, patchwork also provides auto-tagging capabilities as shown in the figure below.\n\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = 'I')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-figure-with-insert",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-figure-with-insert",
    "title": "Hands-on Exercise 2",
    "section": "2.5.5 Creating figure with insert",
    "text": "2.5.5 Creating figure with insert\nBeside providing functions to place plots next to each other based on the provided layout. With inset_element() of patchwork, we can place one or several plots or graphic elements freely on top or below another plot.\n\np3 + inset_element(p2, \n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-composite-figure-by-using-patchwork-and-ggtheme",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-composite-figure-by-using-patchwork-and-ggtheme",
    "title": "Hands-on Exercise 2",
    "section": "2.5.6 Creating a composite figure by using patchwork and ggtheme",
    "text": "2.5.6 Creating a composite figure by using patchwork and ggtheme\nFigure below is created by combining patchwork and theme_economist() of ggthemes package discussed earlier.\n\npatchwork &lt;- (p1 / p2) | p3\npatchwork & theme_economist()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#importing-the-data-set",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#importing-the-data-set",
    "title": "Hands-on Exercise 5E",
    "section": "16.3.1 Importing the data set",
    "text": "16.3.1 Importing the data set\nIn the code chunk below, read_csv() of readr is used to import realis2018.csv into R and parsed it into tibble R data.frame format.\n\nrealis2018 &lt;- read_csv(\"../../data/realis2018.csv\")\n\nThe output tibble data.frame is called realis2018."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#data-wrangling-and-manipulation",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#data-wrangling-and-manipulation",
    "title": "Hands-on Exercise 5E",
    "section": "16.3.2 Data Wrangling and Manipulation",
    "text": "16.3.2 Data Wrangling and Manipulation\nThe data.frame realis2018 is in trasaction record form, which is highly disaggregated and not appropriate to be used to plot a treemap. In this section, we will perform the following steps to manipulate and prepare a data.frtame that is appropriate for treemap visualisation:\n\ngroup transaction records by Project Name, Planning Region, Planning Area, Property Type and Type of Sale, and\ncompute Total Unit Sold, Total Area, Median Unit Price and Median Transacted Price by applying appropriate summary statistics on No. of Units, Area (sqm), Unit Price ($ psm) and Transacted Price ($) respectively.\n\nTwo key verbs of dplyr package, namely: group_by() and summarize() will be used to perform these steps.\ngroup_by() breaks down a data.frame into specified groups of rows. When you then apply the verbs above on the resulting object they’ll be automatically applied “by group”.\nGrouping affects the verbs as follows:\n\ngrouped select() is the same as ungrouped select(), except that grouping variables are always retained.\ngrouped arrange() is the same as ungrouped; unless you set .by_group = TRUE, in which case it orders first by the grouping variables.\nmutate() and filter() are most useful in conjunction with window functions (like rank(), or min(x) == x). They are described in detail in vignette(“window-functions”).\nsample_n() and sample_frac() sample the specified number/fraction of rows in each group.\nsummarise() computes the summary for each group.\n\nIn our case, group_by() will used together with summarise() to derive the summarised data.frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#grouped-summaries-without-the-pipe",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#grouped-summaries-without-the-pipe",
    "title": "Hands-on Exercise 5E",
    "section": "16.3.3 Grouped summaries without the Pipe",
    "text": "16.3.3 Grouped summaries without the Pipe\nThe code chank below shows a typical two lines code approach to perform the steps.\n\nrealis2018_grouped &lt;- group_by(realis2018, `Project Name`,\n                               `Planning Region`, `Planning Area`, \n                               `Property Type`, `Type of Sale`)\nrealis2018_summarised &lt;- summarise(realis2018_grouped, \n                          `Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE),\n                          `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n                          `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE), \n                          `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\nNote\n\nAggregation functions such as sum() and meadian() obey the usual rule of missing values: if there’s any missing value in the input, the output will be a missing value. The argument na.rm = TRUE removes the missing values prior to computation.\n\nThe code chunk above is not very efficient because we have to give each intermediate data.frame a name, even though we don’t have to care about it."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#grouped-summaries-with-the-pipe",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#grouped-summaries-with-the-pipe",
    "title": "Hands-on Exercise 5E",
    "section": "16.3.4 Grouped summaries with the pipe",
    "text": "16.3.4 Grouped summaries with the pipe\nThe code chunk below shows a more efficient way to tackle the same processes by using the pipe, %&gt;%:\n\nrealis2018_summarised &lt;- realis2018 %&gt;% \n  group_by(`Project Name`,`Planning Region`, \n           `Planning Area`, `Property Type`, \n           `Type of Sale`) %&gt;%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#designing-a-static-treemap",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#designing-a-static-treemap",
    "title": "Hands-on Exercise 5E",
    "section": "16.4.1 Designing a static treemap",
    "text": "16.4.1 Designing a static treemap\nIn this section, treemap() of Treemap package is used to plot a treemap showing the distribution of median unit prices and total unit sold of resale condominium by geographic hierarchy in 2017.\nFirst, we will select records belongs to resale condominium property type from realis2018_selected data frame.\n\nrealis2018_selected &lt;- realis2018_summarised %&gt;%\n  filter(`Property Type` == \"Condominium\", `Type of Sale` == \"Resale\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#using-the-basic-arguments",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#using-the-basic-arguments",
    "title": "Hands-on Exercise 5E",
    "section": "16.4.2 Using the basic arguments",
    "text": "16.4.2 Using the basic arguments\nThe code chunk below designed a treemap by using three core arguments of treemap(), namely: index, vSize and vColor.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\nThings to learn from the three arguments used:\n\nindex\n\nThe index vector must consist of at least two column names or else no hierarchy treemap will be plotted.\nIf multiple column names are provided, such as the code chunk above, the first name is the highest aggregation level, the second name the second highest aggregation level, and so on.\n\nvSize\n\nThe column must not contain negative values. This is because it’s vaues will be used to map the sizes of the rectangles of the treemaps.\n\n\nWarning:\nThe treemap above was wrongly coloured. For a correctly designed treemap, the colours of the rectagles should be in different intensity showing, in our case, median unit prices.\nFor treemap(), vColor is used in combination with the argument type to determines the colours of the rectangles. Without defining type, like the code chunk above, treemap() assumes type = index, in our case, the hierarchy of planning areas."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#working-with-vcolor-and-type-arguments",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#working-with-vcolor-and-type-arguments",
    "title": "Hands-on Exercise 5E",
    "section": "16.4.3 Working with vColor and type arguments",
    "text": "16.4.3 Working with vColor and type arguments\nIn the code chunk below, type argument is define as value.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type = \"value\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\nThinking to learn from the conde chunk above.\n\nThe rectangles are coloured with different intensity of green, reflecting their respective median unit prices.\nThe legend reveals that the values are binned into ten bins, i.e. 0-5000, 5000-10000, etc. with an equal interval of 5000."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#colours-in-treemap-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#colours-in-treemap-package",
    "title": "Hands-on Exercise 5E",
    "section": "16.4.4 Colours in treemap package",
    "text": "16.4.4 Colours in treemap package\nThere are two arguments that determine the mapping to color palettes: mapping and palette. The only difference between “value” and “manual” is the default value for mapping. The “value” treemap considers palette to be a diverging color palette (say ColorBrewer’s “RdYlBu”), and maps it in such a way that 0 corresponds to the middle color (typically white or yellow), -max(abs(values)) to the left-end color, and max(abs(values)), to the right-end color. The “manual” treemap simply maps min(values) to the left-end color, max(values) to the right-end color, and mean(range(values)) to the middle color."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#the-value-type-treemap",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#the-value-type-treemap",
    "title": "Hands-on Exercise 5E",
    "section": "16.4.5 The “value” type treemap",
    "text": "16.4.5 The “value” type treemap\nThe code chunk below shows a value type treemap.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\nThing to learn from the code chunk above:\n\nalthough the colour palette used is RdYlBu but there are no red rectangles in the treemap above. This is because all the median unit prices are positive.\nThe reason why we see only 5000 to 45000 in the legend is because the range argument is by default c(min(values, max(values)) with some pretty rounding."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#the-manual-type-treemap",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#the-manual-type-treemap",
    "title": "Hands-on Exercise 5E",
    "section": "16.4.6 The “manual” type treemap",
    "text": "16.4.6 The “manual” type treemap\nThe “manual” type does not interpret the values as the “value” type does. Instead, the value range is mapped linearly to the colour palette.\nThe code chunk below shows a manual type treemap.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\nThings to learn from the code chunk above:\n\nThe colour scheme used is very copnfusing. This is because mapping = (min(values), mean(range(values)), max(values)). It is not wise to use diverging colour palette such as RdYlBu if the values are all positive or negative\n\nTo overcome this problem, a single colour palette such as Blues should be used.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#treemap-layout",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#treemap-layout",
    "title": "Hands-on Exercise 5E",
    "section": "16.4.7 Treemap Layout",
    "text": "16.4.7 Treemap Layout\ntreemap() supports two popular treemap layouts, namely: “squarified” and “pivotSize”. The default is “pivotSize”.\nThe squarified treemap algorithm (Bruls et al., 2000) produces good aspect ratios, but ignores the sorting order of the rectangles (sortID). The ordered treemap, pivot-by-size, algorithm (Bederson et al., 2002) takes the sorting order (sortID) into account while aspect ratios are still acceptable."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#working-with-algorithm-argument",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#working-with-algorithm-argument",
    "title": "Hands-on Exercise 5E",
    "section": "16.4.8 Working with algorithm argument",
    "text": "16.4.8 Working with algorithm argument\nThe code chunk below plots a squarified treemap by changing the algorithm argument.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"squarified\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#using-sortid",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#using-sortid",
    "title": "Hands-on Exercise 5E",
    "section": "16.4.9 Using sortID",
    "text": "16.4.9 Using sortID\nWhen “pivotSize” algorithm is used, sortID argument can be used to dertemine the order in which the rectangles are placed from top left to bottom right.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"pivotSize\",\n        sortID = \"Median Transacted Price\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#designing-a-basic-treemap",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#designing-a-basic-treemap",
    "title": "Hands-on Exercise 5E",
    "section": "16.5.1 Designing a basic treemap",
    "text": "16.5.1 Designing a basic treemap\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`),\n       layout = \"scol\",\n       start = \"bottomleft\") + \n  geom_treemap() +\n  scale_fill_gradient(low = \"light blue\", high = \"blue\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#defining-hierarchy",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#defining-hierarchy",
    "title": "Hands-on Exercise 5E",
    "section": "16.5.2 Defining hierarchy",
    "text": "16.5.2 Defining hierarchy\nGroup by Planning Region\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`),\n       start = \"topleft\") + \n  geom_treemap()\n\n\n\n\nGroup by Planning Area\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap()\n\n\n\n\nAdding boundary line\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap() +\n  geom_treemap_subgroup2_border(colour = \"gray40\",\n                                size = 2) +\n  geom_treemap_subgroup_border(colour = \"gray20\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#installing-d3treer-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#installing-d3treer-package",
    "title": "Hands-on Exercise 5E",
    "section": "16.6.1 Installing d3treeR package",
    "text": "16.6.1 Installing d3treeR package\nThis slide shows you how to install a R package which is not available in cran.\n\nIf this is the first time you install a package from github, you should install devtools package by using the code below or else you can skip this step.\n\n\ninstall.packages(\"devtools\")\n\n\nThe downloaded binary packages are in\n    /var/folders/96/x3nlspkx4kz_2c94gv1tq66m0000gq/T//RtmpxxCHqQ/downloaded_packages\n\n\n\nNext, you will load the devtools library and install the package found in github by using the codes below.\n\n\nlibrary(devtools)\ninstall_github(\"timelyportfolio/d3treeR\")\n\n\nNow you are ready to launch d3treeR package\n\n\nlibrary(d3treeR)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#designing-an-interactive-treemap",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05E.html#designing-an-interactive-treemap",
    "title": "Hands-on Exercise 5E",
    "section": "16.6.2 Designing An Interactive Treemap",
    "text": "16.6.2 Designing An Interactive Treemap\nThe codes below perform two processes.\n\ntreemap() is used to build a treemap by using selected variables in condominium data.frame. The treemap created is save as object called tm.\n\n\ntm &lt;- treemap(realis2018_summarised,\n        index=c(\"Planning Region\", \"Planning Area\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        title=\"Private Residential Property Sold, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\nThen d3tree() is used to build an interactive treemap.\n\n\nd3tree(tm,rootname = \"Singapore\" )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#importing-data",
    "title": "Hands-on Exercise 5B",
    "section": "6.3.1 Importing Data",
    "text": "6.3.1 Importing Data\nFirst, let us import the data into R by using read_csv() of readr package.\n\nwine &lt;- read_csv(\"../../data/wine_quality.csv\")\n\nNotice that beside quality and type, the rest of the variables are numerical and continuous data type."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#building-a-basic-correlation-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#building-a-basic-correlation-matrix",
    "title": "Hands-on Exercise 5B",
    "section": "6.4.1 Building a basic correlation matrix",
    "text": "6.4.1 Building a basic correlation matrix\nFigure below shows the scatter plot matrix of Wine Quality Data. It is a 11 by 11 matrix.\n\npairs(wine[,1:11])\n\n\n\n\nThe required input of pairs() can be a matrix or data frame. The code chunk used to create the scatterplot matrix is relatively simple. It uses the default pairs function. Columns 2 to 12 of wine dataframe is used to build the scatterplot matrix. The variables are: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates and alcohol.\n\npairs(wine[,2:12])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#drawing-the-lower-corner",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#drawing-the-lower-corner",
    "title": "Hands-on Exercise 5B",
    "section": "6.4.2 Drawing the lower corner",
    "text": "6.4.2 Drawing the lower corner\npairs function of R Graphics provided many customisation arguments. For example, it is a common practice to show either the upper half or lower half of the correlation matrix instead of both. This is because a correlation matrix is symmetric.\nTo show the lower half of the correlation matrix, the upper.panel argument will be used as shown in the code chunk below.\n\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\nSimilarly, you can display the upper half of the correlation matrix by using the code chun below.\n\npairs(wine[,2:12], lower.panel = NULL)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#including-with-correlation-coefficients",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#including-with-correlation-coefficients",
    "title": "Hands-on Exercise 5B",
    "section": "6.4.3 Including with correlation coefficients",
    "text": "6.4.3 Including with correlation coefficients\nTo show the correlation coefficient of each pair of variables instead of a scatter plot, panel.cor function will be used. This will also show higher correlations in a larger font.\nDon’t worry about the details for now-just type this code into your R session or script. Let’s have more fun way to display the correlation matrix.\n\npanel.cor &lt;- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\nusr &lt;- par(\"usr\")\non.exit(par(usr))\npar(usr = c(0, 1, 0, 1))\nr &lt;- abs(cor(x, y, use=\"complete.obs\"))\ntxt &lt;- format(c(r, 0.123456789), digits=digits)[1]\ntxt &lt;- paste(prefix, txt, sep=\"\")\nif(missing(cex.cor)) cex.cor &lt;- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12], \n      upper.panel = panel.cor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#the-basic-plot",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#the-basic-plot",
    "title": "Hands-on Exercise 5B",
    "section": "6.5.1 The basic plot",
    "text": "6.5.1 The basic plot\nOn of the advantage of using ggcorrmat() over many other methods to visualise a correlation matrix is it’s ability to provide a comprehensive and yet professional statistical report as shown in the figure below.\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11)\n\n\n\n\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are no significant at p &lt; 0.05\"\n)\n\n\n\n\nThings to learn from the code chunk above:\n\ncor.vars argument is used to compute the correlation matrix needed to build the corrgram.\nggcorrplot.args argument provide additional (mostly aesthetic) arguments that will be passed to ggcorrplot::ggcorrplot function. The list should avoid any of the following arguments since they are already internally being used: corr, method, p.mat, sig.level, ggtheme, colors, lab, pch, legend.title, digits.\n\nThe sample sub-code chunk can be used to control specific component of the plot such as the font size of the x-axis, y-axis, and the statistical report.\n\nggplot.component = list(\n    theme(text=element_text(size=5),\n      axis.text.x = element_text(size = 8),\n      axis.text.y = element_text(size = 8)))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#getting-started-with-corrplot",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#getting-started-with-corrplot",
    "title": "Hands-on Exercise 5B",
    "section": "6.7.1 Getting started with corrplot",
    "text": "6.7.1 Getting started with corrplot\nBefore we can plot a corrgram using corrplot(), we need to compute the correlation matrix of wine data frame.\nIn the code chunk below, cor() of R Stats is used to compute the correlation matrix of wine data frame.\n\nwine.cor &lt;- cor(wine[, 1:11])\n\nNext, corrplot() is used to plot the corrgram by using all the default setting as shown in the code chunk below.\n\ncorrplot(wine.cor)\n\n\n\n\nNotice that the default visual object used to plot the corrgram is circle. The default layout of the corrgram is a symmetric matrix. The default colour scheme is diverging blue-red. Blue colours are used to represent pair variables with positive correlation coefficients and red colours are used to represent pair variables with negative correlation coefficients. The intensity of the colour or also know as saturation is used to represent the strength of the correlation coefficient. Darker colours indicate relatively stronger linear relationship between the paired variables. On the other hand, lighter colours indicates relatively weaker linear relationship."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#working-with-visual-geometrics",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#working-with-visual-geometrics",
    "title": "Hands-on Exercise 5B",
    "section": "6.7.2 Working with visual geometrics",
    "text": "6.7.2 Working with visual geometrics\nIn corrplot package, there are seven visual geometrics (parameter method) can be used to encode the attribute values. They are: circle, square, ellipse, number, shade, color and pie. The default is circle. As shown in the previous section, the default visual geometric of corrplot matrix is circle. However, this default setting can be changed by using the method argument as shown in the code chunk below.\n\ncorrplot(wine.cor, \n         method = \"ellipse\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#working-with-layout",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#working-with-layout",
    "title": "Hands-on Exercise 5B",
    "section": "6.7.3 Working with layout",
    "text": "6.7.3 Working with layout\ncorrplor() supports three layout types, namely: “full”, “upper” or “lower”. The default is “full” which display full matrix. The default setting can be changed by using the type argument of corrplot().\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\")\n\n\n\n\nThe default layout of the corrgram can be further customised. For example, arguments diag and tl.col are used to turn off the diagonal cells and to change the axis text label colour to black colour respectively as shown in the code chunk and figure below.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\",\n         diag = FALSE,\n         tl.col = \"black\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#working-with-mixed-layout",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#working-with-mixed-layout",
    "title": "Hands-on Exercise 5B",
    "section": "6.7.4 Working with mixed layout",
    "text": "6.7.4 Working with mixed layout\nWith corrplot package, it is possible to design corrgram with mixed visual matrix of one half and numerical matrix on the other half. In order to create a coorgram with mixed layout, the corrplot.mixed(), a wrapped function for mixed visualisation style will be used.\nFigure below shows a mixed layout corrgram plotted using wine quality data.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\nThe code chunk used to plot the corrgram are shown below.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\nNotice that argument lower and upper are used to define the visualisation method used. In this case ellipse is used to map the lower half of the corrgram and numerical matrix (i.e. number) is used to map the upper half of the corrgram. The argument tl.pos, on the other, is used to specify the placement of the axis label. Lastly, the diag argument is used to specify the glyph on the principal diagonal of the corrgram."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#combining-corrgram-with-the-significant-test",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#combining-corrgram-with-the-significant-test",
    "title": "Hands-on Exercise 5B",
    "section": "6.7.5 Combining corrgram with the significant test",
    "text": "6.7.5 Combining corrgram with the significant test\nIn statistical analysis, we are also interested to know which pair of variables their correlation coefficients are statistically significant.\nFigure below shows a corrgram combined with the significant test. The corrgram reveals that not all correlation pairs are statistically significant. For example the correlation between total sulfur dioxide and free surfur dioxide is statistically significant at significant level of 0.1 but not the pair between total sulfur dioxide and citric acid.\nWith corrplot package, we can use the cor.mtest() to compute the p-values and confidence interval for each pair of variables.\n\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\n\nWe can then use the p.mat argument of corrplot function as shown in the code chunk below.\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#reorder-a-corrgram",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#reorder-a-corrgram",
    "title": "Hands-on Exercise 5B",
    "section": "6.7.6 Reorder a corrgram",
    "text": "6.7.6 Reorder a corrgram\nMatrix reorder is very important for mining the hiden structure and pattern in a corrgram. By default, the order of attributes of a corrgram is sorted according to the correlation matrix (i.e. “original”). The default setting can be over-write by using the order argument of corrplot(). Currently, corrplot package support four sorting methods, they are:\n\n“AOE” is for the angular order of the eigenvectors. See Michael Friendly (2002) for details.\n“FPC” for the first principal component order.\n“hclust” for hierarchical clustering order, and “hclust.method” for the agglomeration method to be used.\n\n“hclust.method” should be one of “ward”, “single”, “complete”, “average”, “mcquitty”, “median” or “centroid”.\n\n“alphabet” for alphabetical order.\n\n“AOE”, “FPC”, “hclust”, “alphabet”. More algorithms can be found in seriation package.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#reordering-a-correlation-matrix-using-hclust",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#reordering-a-correlation-matrix-using-hclust",
    "title": "Hands-on Exercise 5B",
    "section": "6.7.7 Reordering a correlation matrix using hclust",
    "text": "6.7.7 Reordering a correlation matrix using hclust\nIf using hclust, corrplot() can draw rectangles around the corrgram based on the results of hierarchical clustering.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#r-packages",
    "title": "Hands-on Exercise 5B",
    "section": "7.1 R packages",
    "text": "7.1 R packages\n\nggcormat() of ggstatsplot package\nggscatmat and ggpairs of GGally.\ncorrplot. A graphical display of a correlation matrix or general matrix. It also contains some algorithms to do matrix reordering. In addition, corrplot is good at details, including choosing color, text labels, color labels, layout, etc.\ncorrgram calculates correlation of variables and displays the results graphically. Included panel functions can display points, shading, ellipses, and correlation values with confidence intervals."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07A.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07A.html",
    "title": "Hands-on Exercise 7A",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nIn this chapter, you will learn how to plot functional and truthful choropleth maps by using an R package called tmap package.\n\n\n\nIn this hands-on exercise, the key R package use is tmap package in R. Beside tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\nThe code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n\n\n\nTwo data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\n\n\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz &lt;- st_read(dsn = \"../../data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/shannon/Desktop/ShannMinii/ISSS608-VAA/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nYou can examine the content of mpsz by using the code chunk below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nNotice that only the first ten records will be displayed. Do you know why?\n\n\n\nNext, we will import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popagsex.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\npopdata &lt;- read_csv(\"../../data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\n\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nThing to learn from the code chunk above:\n\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\n\nwrite_rds(mpsz_pop2020, \"../../data/rds/mpszpop2020.rds\")\n\n\n\n\n\n\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\nThings to learn from the code chunk above:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\n\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nIn the following sub-section, we will share with you tmap functions that used to plot these elements.\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\nThings to learn from tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. You will learn more about the color scheme in sub-section 4.4.\nBy default, Missing value will be shaded in grey.\n\n\n\n\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\n\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.\n\nWarning: Maps Lie!\n\n\nDIY: Using what you had learned, prepare choropleth maps by using different classification methods supported by tmap and compare their differences.\n\n\nDIY: Preparing choropleth maps by using similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20). Compare the output maps, what observation can you draw?\n\n\n\n\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nNotice that the choropleth map is shaded in green.\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nNotice that the colour scheme has been reversed.\n\n\n\n\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\ntmap_style(\"white\")\n\n\n\n\n\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments.\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=FALSE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07A.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07A.html#overview",
    "title": "Hands-on Exercise 7A",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nIn this chapter, you will learn how to plot functional and truthful choropleth maps by using an R package called tmap package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07A.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07A.html#getting-started",
    "title": "Hands-on Exercise 7A",
    "section": "",
    "text": "In this hands-on exercise, the key R package use is tmap package in R. Beside tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\nThe code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07A.html#importing-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07A.html#importing-data-into-r",
    "title": "Hands-on Exercise 7A",
    "section": "",
    "text": "Two data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\n\n\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz &lt;- st_read(dsn = \"../../data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/shannon/Desktop/ShannMinii/ISSS608-VAA/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nYou can examine the content of mpsz by using the code chunk below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nNotice that only the first ten records will be displayed. Do you know why?\n\n\n\nNext, we will import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popagsex.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\npopdata &lt;- read_csv(\"../../data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\n\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nThing to learn from the code chunk above:\n\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\n\nwrite_rds(mpsz_pop2020, \"../../data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07A.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07A.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 7A",
    "section": "",
    "text": "Two approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\nThings to learn from the code chunk above:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\n\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nIn the following sub-section, we will share with you tmap functions that used to plot these elements.\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\nThings to learn from tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. You will learn more about the color scheme in sub-section 4.4.\nBy default, Missing value will be shaded in grey.\n\n\n\n\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\n\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.\n\nWarning: Maps Lie!\n\n\nDIY: Using what you had learned, prepare choropleth maps by using different classification methods supported by tmap and compare their differences.\n\n\nDIY: Preparing choropleth maps by using similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20). Compare the output maps, what observation can you draw?\n\n\n\n\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nNotice that the choropleth map is shaded in green.\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nNotice that the colour scheme has been reversed.\n\n\n\n\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\ntmap_style(\"white\")\n\n\n\n\n\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments.\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=FALSE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07A.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07A.html#reference",
    "title": "Hands-on Exercise 7A",
    "section": "",
    "text": "tmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07B.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07B.html#learning-outcome",
    "title": "Hands-on Exercise 7B",
    "section": "23.1 Learning outcome",
    "text": "23.1 Learning outcome\nBy the end of this hands-on exercise, you will acquire the following skills by using appropriate R packages:\n\nTo import an aspatial data file into R.\nTo convert it into simple point feature data frame and at the same time, to assign an appropriate projection reference to the newly create simple point feature data frame.\nTo plot interactive proportional symbol maps."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07B.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07B.html#the-data",
    "title": "Hands-on Exercise 7B",
    "section": "25.1 The data",
    "text": "25.1 The data\nThe data set use for this hands-on exercise is called SGPools_svy21. The data is in csv file format.\nFigure below shows the first 15 records of SGPools_svy21.csv. It consists of seven columns. The XCOORD and YCOORD columns are the x-coordinates and y-coordinates of SingPools outlets and branches. They are in Singapore SVY21 Projected Coordinates System."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07B.html#data-import-and-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07B.html#data-import-and-preparation",
    "title": "Hands-on Exercise 7B",
    "section": "25.2 Data Import and Preparation",
    "text": "25.2 Data Import and Preparation\nThe code chunk below uses read_csv() function of readr package to import SGPools_svy21.csv into R as a tibble data frame called sgpools.\n\nsgpools &lt;- read_csv(\"../../data/aspatial/SGPools_svy21.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe code chunk below shows list() is used to do the job.\n\nlist(sgpools)\n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\n\nNotice that the sgpools data in tibble data frame and not the common R data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07B.html#creating-a-sf-data-frame-from-an-aspatial-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07B.html#creating-a-sf-data-frame-from-an-aspatial-data-frame",
    "title": "Hands-on Exercise 7B",
    "section": "25.3 Creating a sf data frame from an aspatial data frame",
    "text": "25.3 Creating a sf data frame from an aspatial data frame\nThe code chunk below converts sgpools data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\nsgpools_sf &lt;- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\nThings to learn from the arguments above:\n\nThe coords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\nThe crs argument required you to provide the coordinates system in epsg format. EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by refering to epsg.io.\n\nFigure below shows the data table of sgpools_sf. Notice that a new column called geometry has been added into the data frame.\n\nYou can display the basic information of the newly created sgpools_sf by using the code chunk below.\n\nlist(sgpools_sf)\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * &lt;chr&gt;                        &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;\n\n\nThe output shows that sgppols_sf is in point feature class. It’s epsg ID is 3414. The bbox provides information of the extend of the geospatial data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07B.html#it-all-started-with-an-interactive-point-symbol-map",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07B.html#it-all-started-with-an-interactive-point-symbol-map",
    "title": "Hands-on Exercise 7B",
    "section": "26.1 It all started with an interactive point symbol map",
    "text": "26.1 It all started with an interactive point symbol map\nThe code chunks below are used to create an interactive point symbol map.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = 1,\n           border.col = \"black\",\n           border.lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07B.html#lets-make-it-proportional",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07B.html#lets-make-it-proportional",
    "title": "Hands-on Exercise 7B",
    "section": "26.2 Lets make it proportional",
    "text": "26.2 Lets make it proportional\nTo draw a proportional symbol map, we need to assign a numerical variable to the size visual attribute. The code chunks below show that the variable Gp1Gp2Winnings is assigned to size visual attribute.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = \"Gp1Gp2 Winnings\",\n           border.col = \"black\",\n           border.lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07B.html#lets-give-it-a-different-colour",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07B.html#lets-give-it-a-different-colour",
    "title": "Hands-on Exercise 7B",
    "section": "26.3 Lets give it a different colour",
    "text": "26.3 Lets give it a different colour\nThe proportional symbol map can be further improved by using the colour visual attribute. In the code chunks below, OUTLET_TYPE variable is used as the colour attribute variable.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07B.html#i-have-a-twin-brothers",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07B.html#i-have-a-twin-brothers",
    "title": "Hands-on Exercise 7B",
    "section": "26.4 I have a twin brothers :)",
    "text": "26.4 I have a twin brothers :)\nAn impressive and little-know feature of tmap’s view mode is that it also works with faceted plots. The argument sync in tm_facets() can be used in this case to produce multiple maps with synchronised zoom and pan settings.\n\ntm_shape(sgpools_sf) +\n  tm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1) +\n  tm_facets(by= \"OUTLET TYPE\",\n            nrow = 1,\n            sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nBefore you end the session, it is wiser to switch tmap’s Viewer back to plot mode by using the code chunk below.\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07B.html#all-about-tmap-package",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07B.html#all-about-tmap-package",
    "title": "Hands-on Exercise 7B",
    "section": "27.1 All about tmap package",
    "text": "27.1 All about tmap package\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07B.html#geospatial-data-wrangling-1",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07B.html#geospatial-data-wrangling-1",
    "title": "Hands-on Exercise 7B",
    "section": "27.2 Geospatial data wrangling",
    "text": "27.2 Geospatial data wrangling\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07B.html#data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07B.html#data-wrangling",
    "title": "Hands-on Exercise 7B",
    "section": "27.3 Data wrangling",
    "text": "27.3 Data wrangling\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "By the end of this hands-on exercise you will be able create the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart\n\n\n\n\n\n\n\nWrite a code chunk to check, install and launch the following R packages: scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table and tidyverse.\n\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table, CGPfunctions, ggHoriPlot, tidyverse)\n\n\n\n\nIn this section, you will learn how to plot a calender heatmap programmatically by using ggplot2 package.\n\nBy the end of this section, you will be able to:\n\nplot a calender heatmap by using ggplot2 functions and extension,\nto write function using R programming,\nto derive specific date and time related field by using base R and lubridate packages\nto perform data preparation task by using tidyr and dplyr packages.\n\n\n\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\n\nFirst, you will use the code chunk below to import eventlog.csv file into R environment and called the data frame as attacks.\n\nattacks &lt;- read_csv(\"../../data/eventlog.csv\")\n\n\n\n\nIt is always a good practice to examine the imported data frame before further analysis is performed.\nFor example, kable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\ntz field stores time zone of the source IP address.\n\n\n\n\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\nThings to learn from the code chunk\n\na tibble data table called grouped is derived by aggregating the attack by wkday and hour fields.\na new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data.\n\n\n\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\n\n\n\n\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, you are required to do the followings:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nIn this step, you are required to extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\n\n\n\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\nIn this section, you will learn how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\n\n\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair &lt;- read_excel(\"../../data/arrivals_by_air.xlsx\")\n\n\n\n\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))\n\n\n\n\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))\n\n\n\n\nNext, the code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)\n\n\n\n\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n\nThe code chunk below is used to plot the cycle plot as shown in Slide 12/23.\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\")\n\n\n\n\n\n\n\n\nIn this section you will learn how to plot a slopegraph by using R.\nBefore getting start, make sure that CGPfunctions has been installed and loaded onto R environment. Then, refer to Using newggslopegraph to learn more about the function. Lastly, read more about newggslopegraph() and its arguments by referring to this link.\n\n\nImport the rice data set into R environment by using the code chunk below.\n\nrice &lt;- read_csv(\"../../data/rice.csv\")\n\n\n\n\nNext, code chunk below will be used to plot a basic slopegraph as shown below.\n\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Dr. Kam Tin Seong\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#learning-outcome",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "By the end of this hands-on exercise you will be able create the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#do-it-yourself",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#do-it-yourself",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "Write a code chunk to check, install and launch the following R packages: scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table and tidyverse.\n\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table, CGPfunctions, ggHoriPlot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-calendar-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-calendar-heatmap",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "In this section, you will learn how to plot a calender heatmap programmatically by using ggplot2 package.\n\nBy the end of this section, you will be able to:\n\nplot a calender heatmap by using ggplot2 functions and extension,\nto write function using R programming,\nto derive specific date and time related field by using base R and lubridate packages\nto perform data preparation task by using tidyr and dplyr packages.\n\n\n\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\n\nFirst, you will use the code chunk below to import eventlog.csv file into R environment and called the data frame as attacks.\n\nattacks &lt;- read_csv(\"../../data/eventlog.csv\")\n\n\n\n\nIt is always a good practice to examine the imported data frame before further analysis is performed.\nFor example, kable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\ntz field stores time zone of the source IP address.\n\n\n\n\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\nThings to learn from the code chunk\n\na tibble data table called grouped is derived by aggregating the attack by wkday and hour fields.\na new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data.\n\n\n\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\n\n\n\n\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, you are required to do the followings:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nIn this step, you are required to extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\n\n\n\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-cycle-plot",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-cycle-plot",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "In this section, you will learn how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\n\n\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair &lt;- read_excel(\"../../data/arrivals_by_air.xlsx\")\n\n\n\n\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))\n\n\n\n\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))\n\n\n\n\nNext, the code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)\n\n\n\n\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n\nThe code chunk below is used to plot the cycle plot as shown in Slide 12/23.\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-slopegraph",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-slopegraph",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "In this section you will learn how to plot a slopegraph by using R.\nBefore getting start, make sure that CGPfunctions has been installed and loaded onto R environment. Then, refer to Using newggslopegraph to learn more about the function. Lastly, read more about newggslopegraph() and its arguments by referring to this link.\n\n\nImport the rice data set into R environment by using the code chunk below.\n\nrice &lt;- read_csv(\"../../data/rice.csv\")\n\n\n\n\nNext, code chunk below will be used to plot a basic slopegraph as shown below.\n\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Dr. Kam Tin Seong\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "Completing Hands-on Exercises Completing In-class Exercise Completing Take-home Exercise Completing Group Project"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "OECD education director Andreas Schleicher shared in a BBC article that “Singapore managed to achieve excellence without wide differences between children from wealthy and disadvantaged families.” (2016) Furthermore, several Singapore’s Minister for Education also started an “every school a good school” slogan.\nThe general public, however, strongly belief that there are still disparities that exist, especially between the elite schools and neighborhood school, between students from families with higher socioeconomic status and those with relatively lower socioeconomic status and immigration and non-immigration families."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#installing-r-packages",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#installing-r-packages",
    "title": "Take-home Exercise 1",
    "section": "1.1 Installing R packages",
    "text": "1.1 Installing R packages\npacman::p_load() function from the pacman package is used in the following code chunk to install and call the libraries of multiple R packages:\n\npacman::p_load(tidyverse, haven, ggrepel, patchwork, \n               ggthemes, hrbrthemes)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-dataset",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-dataset",
    "title": "Take-home Exercise 1",
    "section": "1.2 Importing Dataset",
    "text": "1.2 Importing Dataset\n“Student questionnaire data file” from the PISA 2022 database is provided for the task.\nThe code chunk below uses read_sas() of haven to import PISA data into R environment.\n\nstu_qqq &lt;- read_sas(\"../../data/STU_QQQ_SAS/cy08msp_stu_qqq.sas7bdat\")\n\n\nstu_qqq_SG &lt;- stu_qqq %&gt;%\n  filter(CNT == \"SGP\")\n\n\nwrite_rds(stu_qqq_SG,\n          \"../../data/STU_QQQ_SAS/stu_qqq_SG.rds\")\n\nWe upload the file as stu_qqq_Sg.\n\nstu_qqq_Sg &lt;-\n  read_rds(\"../../data/STU_QQQ_SAS/stu_qqq_SG.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#summary-statistics",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#summary-statistics",
    "title": "Take-home Exercise 1",
    "section": "1.3 Summary Statistics",
    "text": "1.3 Summary Statistics\nWe first display first 5 rows using head().\n\nhead(stu_qqq_Sg, 5)\n\n# A tibble: 5 × 1,279\n  CNT   CNTRYID CNTSCHID CNTSTUID CYC   NatCen STRATUM SUBNATIO REGION  OECD\n  &lt;chr&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 SGP       702 70200052 70200001 08MS  070200 SGP01   7020000   70200     0\n2 SGP       702 70200134 70200002 08MS  070200 SGP01   7020000   70200     0\n3 SGP       702 70200112 70200003 08MS  070200 SGP01   7020000   70200     0\n4 SGP       702 70200004 70200004 08MS  070200 SGP01   7020000   70200     0\n5 SGP       702 70200152 70200005 08MS  070200 SGP01   7020000   70200     0\n# ℹ 1,269 more variables: ADMINMODE &lt;dbl&gt;, LANGTEST_QQQ &lt;dbl&gt;,\n#   LANGTEST_COG &lt;dbl&gt;, LANGTEST_PAQ &lt;dbl&gt;, Option_CT &lt;dbl&gt;, Option_FL &lt;dbl&gt;,\n#   Option_ICTQ &lt;dbl&gt;, Option_WBQ &lt;dbl&gt;, Option_PQ &lt;dbl&gt;, Option_TQ &lt;dbl&gt;,\n#   Option_UH &lt;dbl&gt;, BOOKID &lt;dbl&gt;, ST001D01T &lt;dbl&gt;, ST003D02T &lt;dbl&gt;,\n#   ST003D03T &lt;dbl&gt;, ST004D01T &lt;dbl&gt;, ST250Q01JA &lt;dbl&gt;, ST250Q02JA &lt;dbl&gt;,\n#   ST250Q03JA &lt;dbl&gt;, ST250Q04JA &lt;dbl&gt;, ST250Q05JA &lt;dbl&gt;, ST250D06JA &lt;chr&gt;,\n#   ST250D07JA &lt;chr&gt;, ST251Q01JA &lt;dbl&gt;, ST251Q02JA &lt;dbl&gt;, ST251Q03JA &lt;dbl&gt;, …\n\n\nThen, we check the structure of stu_qqq_Sg.\n\nstr(stu_qqq_Sg)\n\ntibble [6,606 × 1,279] (S3: tbl_df/tbl/data.frame)\n $ CNT         : chr [1:6606] \"SGP\" \"SGP\" \"SGP\" \"SGP\" ...\n  ..- attr(*, \"label\")= chr \"Country code 3-character\"\n $ CNTRYID     : num [1:6606] 702 702 702 702 702 702 702 702 702 702 ...\n  ..- attr(*, \"label\")= chr \"Country Identifier\"\n $ CNTSCHID    : num [1:6606] 70200052 70200134 70200112 70200004 70200152 ...\n  ..- attr(*, \"label\")= chr \"Intl. School ID\"\n $ CNTSTUID    : num [1:6606] 70200001 70200002 70200003 70200004 70200005 ...\n  ..- attr(*, \"label\")= chr \"Intl. Student ID\"\n $ CYC         : chr [1:6606] \"08MS\" \"08MS\" \"08MS\" \"08MS\" ...\n  ..- attr(*, \"label\")= chr \"PISA Assessment Cycle (2 digits + 2 character Assessment type - MS/FT)\"\n $ NatCen      : chr [1:6606] \"070200\" \"070200\" \"070200\" \"070200\" ...\n  ..- attr(*, \"label\")= chr \"National Centre 6-digit Code\"\n $ STRATUM     : chr [1:6606] \"SGP01\" \"SGP01\" \"SGP01\" \"SGP01\" ...\n  ..- attr(*, \"label\")= chr \"Stratum ID 5-character (cnt + original stratum ID)\"\n $ SUBNATIO    : chr [1:6606] \"7020000\" \"7020000\" \"7020000\" \"7020000\" ...\n  ..- attr(*, \"label\")= chr \"Adjudicated sub-region code 7-digit code (3-digit country code + region ID + stratum ID)\"\n $ REGION      : num [1:6606] 70200 70200 70200 70200 70200 70200 70200 70200 70200 70200 ...\n  ..- attr(*, \"label\")= chr \"REGION\"\n $ OECD        : num [1:6606] 0 0 0 0 0 0 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"OECD country\"\n $ ADMINMODE   : num [1:6606] 2 2 2 2 2 2 2 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"Mode of Respondent\"\n $ LANGTEST_QQQ: num [1:6606] 313 313 313 313 313 313 313 313 313 313 ...\n  ..- attr(*, \"label\")= chr \"Language of Questionnaire\"\n $ LANGTEST_COG: num [1:6606] 313 313 313 313 313 313 313 313 313 313 ...\n  ..- attr(*, \"label\")= chr \"Language of Assessment\"\n $ LANGTEST_PAQ: num [1:6606] NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"label\")= chr \"Language of Parent Questionnaire\"\n $ Option_CT   : num [1:6606] NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"label\")= chr \"Creative Thinking Option\"\n $ Option_FL   : num [1:6606] NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"label\")= chr \"Financial Literacy Option\"\n $ Option_ICTQ : num [1:6606] 1 1 1 1 1 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"ICT Questionnaire Option\"\n $ Option_WBQ  : num [1:6606] 0 0 0 0 0 0 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"Well-Being Questionnaire Option\"\n $ Option_PQ   : num [1:6606] 0 0 0 0 0 0 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"Parent Questionnaire Option\"\n $ Option_TQ   : num [1:6606] 0 0 0 0 0 0 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"Teacher Questionnaire Option\"\n $ Option_UH   : num [1:6606] 0 0 0 0 0 0 0 0 0 0 ...\n  ..- attr(*, \"label\")= chr \"Une Heure Option\"\n $ BOOKID      : num [1:6606] 4 45 8 40 42 15 13 39 14 7 ...\n  ..- attr(*, \"label\")= chr \"Form Identifier\"\n $ ST001D01T   : num [1:6606] 10 10 10 10 10 10 10 10 10 10 ...\n  ..- attr(*, \"label\")= chr \"Student International Grade (Derived)\"\n $ ST003D02T   : num [1:6606] 10 6 7 2 9 9 3 4 8 6 ...\n  ..- attr(*, \"label\")= chr \"Student (Standardized) Birth - Month\"\n $ ST003D03T   : num [1:6606] 2006 2006 2006 2006 2006 ...\n  ..- attr(*, \"label\")= chr \"Student (Standardized) Birth -Year\"\n $ ST004D01T   : num [1:6606] 1 2 2 2 1 1 2 2 1 2 ...\n  ..- attr(*, \"label\")= chr \"Student (Standardized) Gender\"\n $ ST250Q01JA  : num [1:6606] 2 1 1 2 2 2 1 1 2 2 ...\n  ..- attr(*, \"label\")= chr \"Which of the following are in your [home]: A room of your own\"\n $ ST250Q02JA  : num [1:6606] 1 1 1 1 1 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Which of the following are in your [home]: A computer (laptop, desktop, or tablet) that you can use for school work\"\n $ ST250Q03JA  : num [1:6606] 1 1 2 1 1 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Which of the following are in your [home]: Educational Software or Apps\"\n $ ST250Q04JA  : num [1:6606] 1 1 1 1 1 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Which of the following are in your [home]: Your own [cell phone] with Internet access (e.g. smartphone)\"\n $ ST250Q05JA  : num [1:6606] 1 1 1 1 1 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Which of the following are in your [home]: Internet access (e.g. Wi-fi) (excluding through smartphones)\"\n $ ST250D06JA  : chr [1:6606] \"7020002\" \"7020001\" \"7020001\" \"7020002\" ...\n  ..- attr(*, \"label\")= chr \"Which of the following are in your home? &lt;Country-specific item 1&gt;\"\n $ ST250D07JA  : chr [1:6606] \"7020002\" \"7020001\" \"7020002\" \"7020002\" ...\n  ..- attr(*, \"label\")= chr \"Which of the following are in your home? &lt;Country-specific item 2&gt;\"\n $ ST251Q01JA  : num [1:6606] 2 1 2 1 2 2 2 1 3 3 ...\n  ..- attr(*, \"label\")= chr \"How many of these items are there at your [home]: Cars, vans, or trucks\"\n $ ST251Q02JA  : num [1:6606] 1 4 1 2 2 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"How many of these items are there at your [home]: Mopeds or motorcycles\"\n $ ST251Q03JA  : num [1:6606] 3 3 3 3 2 2 3 3 4 3 ...\n  ..- attr(*, \"label\")= chr \"How many of these items are there at your [home]: Rooms with a bath or shower\"\n $ ST251Q04JA  : num [1:6606] 3 3 3 3 2 3 3 3 4 3 ...\n  ..- attr(*, \"label\")= chr \"How many of these items are there at your [home]: Rooms with a [flush toilet]\"\n $ ST251Q06JA  : num [1:6606] 3 4 2 2 1 2 2 3 4 1 ...\n  ..- attr(*, \"label\")= chr \"How many of these items are there at your [home]: Musical instruments (e.g. guitar, piano, [country-specific example])\"\n $ ST251Q07JA  : num [1:6606] 3 2 1 1 4 1 4 1 4 3 ...\n  ..- attr(*, \"label\")= chr \"How many of these items are there at your [home]: Works of art (e.g. paintings, sculptures, [country-specific example])\"\n $ ST251D08JA  : chr [1:6606] \"9999997\" \"9999997\" \"9999997\" \"9999997\" ...\n  ..- attr(*, \"label\")= chr \"How many of these items are there at your home? &lt;Country-specific item 1&gt;\"\n $ ST251D09JA  : chr [1:6606] \"9999997\" \"9999997\" \"9999997\" \"9999997\" ...\n  ..- attr(*, \"label\")= chr \"How many of these items are there at your home? &lt;Country-specific item 2&gt;\"\n $ ST253Q01JA  : num [1:6606] 7 8 7 6 7 7 8 8 8 7 ...\n  ..- attr(*, \"label\")= chr \"How many [digital devices] with screens are there in your [home]?\"\n $ ST254Q01JA  : num [1:6606] 2 3 2 2 2 2 2 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"How many of the following [digital devices] are in your [home]: Televisions\"\n $ ST254Q02JA  : num [1:6606] 1 2 2 1 3 2 2 5 2 2 ...\n  ..- attr(*, \"label\")= chr \"How many of the following [digital devices] are in your [home]: Desktop computers\"\n $ ST254Q03JA  : num [1:6606] 3 2 2 2 2 2 3 3 3 4 ...\n  ..- attr(*, \"label\")= chr \"How many of the following [digital devices] are in your [home]: Laptop computers or notebooks\"\n $ ST254Q04JA  : num [1:6606] 2 3 2 1 1 2 2 3 3 2 ...\n  ..- attr(*, \"label\")= chr \"How many of the following [digital devices] are in your [home]: Tablets (e.g. [iPad®], [BlackBerry® Playbook™])\"\n $ ST254Q05JA  : num [1:6606] 1 5 1 1 NA 1 1 5 2 2 ...\n  ..- attr(*, \"label\")= chr \"How many of the following [digital devices] are in your [home]: E-book readers (e.g. [Kindle™], [Kobo], [Bookeen])\"\n $ ST254Q06JA  : num [1:6606] 3 2 3 3 4 2 4 3 4 4 ...\n  ..- attr(*, \"label\")= chr \"How many of the following [digital devices] are in your [home]: [Cell phones] with Internet access (i.e. smartphones)\"\n $ ST255Q01JA  : num [1:6606] 7 4 4 3 2 2 4 5 7 4 ...\n  ..- attr(*, \"label\")= chr \"How many books are there in your [home]?\"\n $ ST256Q01JA  : num [1:6606] 2 4 5 2 4 1 1 3 4 4 ...\n  ..- attr(*, \"label\")= chr \"How many of these books at [home]: Religious books (e.g. [Bible], [Example 2])\"\n $ ST256Q02JA  : num [1:6606] 2 5 2 1 1 2 1 5 4 2 ...\n  ..- attr(*, \"label\")= chr \"How many of these books at [home]: Classical literature (e.g. [Shakespeare], [Example 2])\"\n $ ST256Q03JA  : num [1:6606] 4 5 2 1 1 2 2 5 5 1 ...\n  ..- attr(*, \"label\")= chr \"How many of these books at [home]: Contemporary literature\"\n $ ST256Q06JA  : num [1:6606] 4 3 3 2 2 5 2 4 4 1 ...\n  ..- attr(*, \"label\")= chr \"How many of these books at [home]: Books on science\"\n $ ST256Q07JA  : num [1:6606] 3 5 5 2 2 5 1 4 3 1 ...\n  ..- attr(*, \"label\")= chr \"How many of these books at [home]: Books on art, music, or design\"\n $ ST256Q08JA  : num [1:6606] 3 3 3 1 1 5 1 5 5 2 ...\n  ..- attr(*, \"label\")= chr \"How many of these books at [home]: [Technical reference books]\"\n $ ST256Q09JA  : num [1:6606] 2 2 4 2 2 2 2 2 2 3 ...\n  ..- attr(*, \"label\")= chr \"How many of these books at [home]: Dictionaries\"\n $ ST256Q10JA  : num [1:6606] 4 4 5 2 4 1 4 4 4 3 ...\n  ..- attr(*, \"label\")= chr \"How many of these books at [home]: Books to help with your school work\"\n $ ST230Q01JA  : num [1:6606] 4 4 2 4 4 3 2 2 3 4 ...\n  ..- attr(*, \"label\")= chr \"How many siblings (including brothers, sisters, step-brothers, and step-sisters) do you have?\"\n $ ST005Q01JA  : num [1:6606] 2 2 2 2 2 2 2 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"What is the [highest level of schooling] completed by your mother?\"\n $ ST006Q01JA  : num [1:6606] 2 2 2 2 2 2 2 NA 2 2 ...\n  ..- attr(*, \"label\")= chr \"Does your mother have any of the following qualifications: [ISCED level 8]\"\n $ ST006Q02JA  : num [1:6606] 2 2 2 2 2 2 2 1 2 2 ...\n  ..- attr(*, \"label\")= chr \"Does your mother have any of the following qualifications: [ISCED level 7]\"\n $ ST006Q03JA  : num [1:6606] 1 2 2 2 2 2 2 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Does your mother have any of the following qualifications: [ISCED level 6]\"\n $ ST006Q04JA  : num [1:6606] 2 1 2 2 1 1 2 1 1 2 ...\n  ..- attr(*, \"label\")= chr \"Does your mother have any of the following qualifications: [ISCED level 5]\"\n $ ST006Q05JA  : num [1:6606] 1 1 2 1 2 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Does your mother have any of the following qualifications: [ISCED level 4]\"\n $ ST007Q01JA  : num [1:6606] 2 2 2 4 2 2 4 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"What is the [highest level of schooling] completed by your father?\"\n $ ST008Q01JA  : num [1:6606] 2 2 2 NA 2 2 2 NA 2 2 ...\n  ..- attr(*, \"label\")= chr \"Does your father have any of the following qualifications: [ISCED level 8]\"\n $ ST008Q02JA  : num [1:6606] 2 2 2 NA 2 1 2 NA 2 2 ...\n  ..- attr(*, \"label\")= chr \"Does your father have any of the following qualifications: [ISCED level 7]\"\n $ ST008Q03JA  : num [1:6606] 2 2 2 NA 2 1 2 1 1 2 ...\n  ..- attr(*, \"label\")= chr \"Does your father have any of the following qualifications: [ISCED level 6]\"\n $ ST008Q04JA  : num [1:6606] 1 1 2 NA 1 1 2 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Does your father have any of the following qualifications: [ISCED level 5]\"\n $ ST008Q05JA  : num [1:6606] 2 1 2 1 2 1 2 1 1 2 ...\n  ..- attr(*, \"label\")= chr \"Does your father have any of the following qualifications: [ISCED level 4]\"\n $ ST258Q01JA  : num [1:6606] 1 1 1 5 1 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"In the past 30 days, how often did you not eat because there was not enough money to buy food?\"\n $ ST259Q01JA  : num [1:6606] NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"label\")= chr \"Now think about where you would place your family on this scale. Where would you say your family stands at this time?\"\n $ ST259Q02JA  : num [1:6606] NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"label\")= chr \"Now think about where you would place your family on this scale. Where do you think you will stand when you are 30?\"\n $ ST019AQ01T  : num [1:6606] 1 1 1 1 1 2 1 2 1 1 ...\n  ..- attr(*, \"label\")= chr \"In what country were you and your parents born? You\"\n $ ST019BQ01T  : num [1:6606] 1 1 2 1 1 2 1 2 1 1 ...\n  ..- attr(*, \"label\")= chr \"In what country were you and your parents born? Mother\"\n $ ST019CQ01T  : num [1:6606] 1 1 1 1 1 2 1 2 1 1 ...\n  ..- attr(*, \"label\")= chr \"In what country were you and your parents born? Father\"\n $ ST021Q01TA  : num [1:6606] NA NA NA NA NA 1 NA 1 NA NA ...\n  ..- attr(*, \"label\")= chr \"How old were you when you arrived in [country of test]?\"\n $ ST022Q01TA  : num [1:6606] 1 1 2 2 1 2 1 2 1 2 ...\n  ..- attr(*, \"label\")= chr \"What language do you speak at home most of the time?\"\n $ ST226Q01JA  : num [1:6606] 1 1 1 1 1 1 1 4 1 1 ...\n  ..- attr(*, \"label\")= chr \"How long have you been enrolled at this school?\"\n $ ST125Q01NA  : num [1:6606] 3 5 8 4 8 3 4 8 8 4 ...\n  ..- attr(*, \"label\")= chr \"How old were you when you started [ISCED 0]: Years\"\n $ ST126Q01TA  : num [1:6606] 4 5 5 5 5 5 5 5 4 5 ...\n  ..- attr(*, \"label\")= chr \"How old were you when you started [ISCED 1]: Years\"\n $ ST127Q01TA  : num [1:6606] 1 1 1 1 1 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Have you ever repeated a [grade]: At [ISCED 1]\"\n $ ST127Q02TA  : num [1:6606] 1 1 1 1 1 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Have you ever repeated a [grade]: At [ISCED 2]\"\n $ ST127Q03TA  : num [1:6606] 1 1 1 1 1 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Have you ever repeated a [grade]: At [ISCED 3]\"\n $ ST260Q01JA  : num [1:6606] 1 1 1 1 1 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Have you ever missed school for more than three months in a row: At [ISCED 1]\"\n $ ST260Q02JA  : num [1:6606] 1 1 1 1 1 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Have you ever missed school for more than three months in a row: At [ISCED 2]\"\n $ ST260Q03JA  : num [1:6606] 1 1 1 1 1 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Have you ever missed school for more than three months in a row: At [ISCED 3]\"\n $ ST261Q01JA  : num [1:6606] NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"label\")= chr \"Why miss school for 3+ months: I was bored.\"\n $ ST261Q02JA  : num [1:6606] NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"label\")= chr \"Why miss school for 3+ months: I was suspended for something (e.g. violence, aggression, use of drugs, drug dealing).\"\n $ ST261Q03JA  : num [1:6606] NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"label\")= chr \"Why miss school for 3+ months: I was pregnant.\"\n $ ST261Q04JA  : num [1:6606] NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"label\")= chr \"Why miss school for 3+ months: I could not reach school because of transportation problems.\"\n $ ST261Q05JA  : num [1:6606] NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"label\")= chr \"Why miss school for 3+ months: I had to take care of a family member.\"\n $ ST261Q06JA  : num [1:6606] NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"label\")= chr \"Why miss school for 3+ months: I had to help with work at home, the family business, or on the family land.\"\n $ ST261Q07JA  : num [1:6606] NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"label\")= chr \"Why miss school for 3+ months: I had to get work to bring money home.\"\n $ ST261Q08JA  : num [1:6606] NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"label\")= chr \"Why miss school for 3+ months: I was sick.\"\n $ ST261Q09JA  : num [1:6606] NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"label\")= chr \"Why miss school for 3+ months: I did not feel safe at school.\"\n $ ST261Q10JA  : num [1:6606] NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"label\")= chr \"Why miss school for 3+ months: I could not pay [school fees].\"\n $ ST261Q11JA  : num [1:6606] NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"label\")= chr \"Why miss school for 3+ months: School was closed because of a natural disaster (e.g. flood, earthquake).\"\n $ ST062Q01TA  : num [1:6606] 1 1 1 1 2 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"In the last two full weeks of school, how often: I [skipped] a whole school day\"\n  [list output truncated]\n\n\nThe dataset contains the Intl. School ID (CNTSCHID), Intl. Student ID (CNTSTUID), and Student (Standardized) Gender (ST004D01T) variables, which are currently kept as numeric data types. We will convert these to categorical data types due to the following reasons:\n\nThe International School ID is a numerical designation used to uniquely identify various schools. The numbers lack inherent mathematical significance; they serve solely as designations.\nComparable to school IDs, The International Student ID is a distinct identity assigned to each student, it should be regarded as a label.\n“Student (Standardized) Gender” represents gender and is characterized by discrete categories such as male or female rather than a numerical scale.\n\n\nstu_qqq_Sg$CNTSCHID &lt;- as.factor(stu_qqq_Sg$CNTSCHID)\nstu_qqq_Sg$CNTSTUID &lt;- as.factor(stu_qqq_Sg$CNTSTUID)\nstu_qqq_Sg$ST004D01T &lt;- as.factor(stu_qqq_Sg$ST004D01T)\n\nWe proceed to check for duplicates.\n\nduplicate_rows &lt;- stu_qqq_Sg[duplicated(stu_qqq_Sg),]\nprint(head(duplicate_rows))\n\n# A tibble: 0 × 1,279\n# ℹ 1,279 variables: CNT &lt;chr&gt;, CNTRYID &lt;dbl&gt;, CNTSCHID &lt;fct&gt;, CNTSTUID &lt;fct&gt;,\n#   CYC &lt;chr&gt;, NatCen &lt;chr&gt;, STRATUM &lt;chr&gt;, SUBNATIO &lt;chr&gt;, REGION &lt;dbl&gt;,\n#   OECD &lt;dbl&gt;, ADMINMODE &lt;dbl&gt;, LANGTEST_QQQ &lt;dbl&gt;, LANGTEST_COG &lt;dbl&gt;,\n#   LANGTEST_PAQ &lt;dbl&gt;, Option_CT &lt;dbl&gt;, Option_FL &lt;dbl&gt;, Option_ICTQ &lt;dbl&gt;,\n#   Option_WBQ &lt;dbl&gt;, Option_PQ &lt;dbl&gt;, Option_TQ &lt;dbl&gt;, Option_UH &lt;dbl&gt;,\n#   BOOKID &lt;dbl&gt;, ST001D01T &lt;dbl&gt;, ST003D02T &lt;dbl&gt;, ST003D03T &lt;dbl&gt;,\n#   ST004D01T &lt;fct&gt;, ST250Q01JA &lt;dbl&gt;, ST250Q02JA &lt;dbl&gt;, ST250Q03JA &lt;dbl&gt;, …\n\n\nThe output # A tibble: 0 × 1,279 indicates that there are zero rows in the resulting tibble. This means that no duplicate rows were found in dataset stu_qqq_Sg across all 1,279 variables.\nNext, we proceed to check for missing values.\n\n# Count the total number of missing values in the dataset\ntotal_na &lt;- sum(is.na(stu_qqq_Sg))\nprint(total_na)\n\n[1] 4168500\n\n\nWhile there are numerous missing values in the dataset, our focus is primarily on specific columns. We’re interested in the columns labeled:\n\nCNTSCHID (International School ID)\nCNTSTUID (International Student ID)\nST004D01T (Student Standardized Gender)\nHISEI (Highest parental occupational status based on 4-digit human coded ISCO)\nESCS (Index of economic, social and cultural status)\n\nand a series of columns related to plausible values in different subjects. These subjects include:\n\nMathematics (PV1MATH to PV10MATH)\nReading (PV1READ to PV10READ)\nScience (PV1SCIE to PV10SCIE)\n\nWe’ll examine these columns for missing data, as they are relevant to our analysis.\nWe can use the select function from the dplyr package to extract the specific columns.\n\nlibrary(dplyr)\n\n# Selecting specific columns explicitly\nselected_columns &lt;- stu_qqq_Sg %&gt;%\n  select(CNTSCHID, CNTSTUID, ST004D01T,\n         HISEI, ESCS,\n         PV1MATH, PV2MATH, PV3MATH, PV4MATH, PV5MATH, PV6MATH, PV7MATH, PV8MATH, PV9MATH, PV10MATH,\n         PV1READ, PV2READ, PV3READ, PV4READ, PV5READ, PV6READ, PV7READ, PV8READ, PV9READ, PV10READ,\n         PV1SCIE, PV2SCIE, PV3SCIE, PV4SCIE, PV5SCIE, PV6SCIE, PV7SCIE, PV8SCIE, PV9SCIE, PV10SCIE)\n\n# Count the number of missing values per selected column\nna_per_selected_column &lt;- colSums(is.na(selected_columns))\n\n# Printing the number of missing values per selected column\nprint(na_per_selected_column)\n\n CNTSCHID  CNTSTUID ST004D01T     HISEI      ESCS   PV1MATH   PV2MATH   PV3MATH \n        0         0         0       310        47         0         0         0 \n  PV4MATH   PV5MATH   PV6MATH   PV7MATH   PV8MATH   PV9MATH  PV10MATH   PV1READ \n        0         0         0         0         0         0         0         0 \n  PV2READ   PV3READ   PV4READ   PV5READ   PV6READ   PV7READ   PV8READ   PV9READ \n        0         0         0         0         0         0         0         0 \n PV10READ   PV1SCIE   PV2SCIE   PV3SCIE   PV4SCIE   PV5SCIE   PV6SCIE   PV7SCIE \n        0         0         0         0         0         0         0         0 \n  PV8SCIE   PV9SCIE  PV10SCIE \n        0         0         0 \n\n\nThe counts of missing values for the variables in question are as follows:\n\nHighest Parental Occupational Status (HISEI): 310 missing values\nIndex of economic, social and cultural status (ESCS): 47 missing values\n\nTo ensure our analysis is accurate, we’re going to remove these incomplete rows from our dataset."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#calculate-average-plausible-values-for-each-student",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#calculate-average-plausible-values-for-each-student",
    "title": "Take-home Exercise 1",
    "section": "2.1 Calculate average plausible values for each student",
    "text": "2.1 Calculate average plausible values for each student\nWe calculate each student’s average plausible values for each subject, condensing multiple data points into one representative score per subject. This simplification aids in analyzing the distribution of performances across different subjects in Singapore.\n\nlibrary(dplyr)\n\n# Calculate the mean PV scores for each student in each subject\nstudent_avg_scores &lt;- stu_qqq_Sg %&gt;%\n  mutate(\n    AvgMathPV = rowMeans(select(., starts_with(\"PV1MATH\"):starts_with(\"PV10MATH\")), na.rm = TRUE),\n    AvgReadPV = rowMeans(select(., starts_with(\"PV1READ\"):starts_with(\"PV10READ\")), na.rm = TRUE),\n    AvgSciePV = rowMeans(select(., starts_with(\"PV1SCIE\"):starts_with(\"PV10SCIE\")), na.rm = TRUE)\n  )\n\n# View the student level averages\nprint(student_avg_scores)\n\n# A tibble: 6,606 × 1,282\n   CNT   CNTRYID CNTSCHID CNTSTUID CYC   NatCen STRATUM SUBNATIO REGION  OECD\n   &lt;chr&gt;   &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt;    &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;\n 1 SGP       702 70200052 70200001 08MS  070200 SGP01   7020000   70200     0\n 2 SGP       702 70200134 70200002 08MS  070200 SGP01   7020000   70200     0\n 3 SGP       702 70200112 70200003 08MS  070200 SGP01   7020000   70200     0\n 4 SGP       702 70200004 70200004 08MS  070200 SGP01   7020000   70200     0\n 5 SGP       702 70200152 70200005 08MS  070200 SGP01   7020000   70200     0\n 6 SGP       702 70200043 70200006 08MS  070200 SGP01   7020000   70200     0\n 7 SGP       702 70200049 70200007 08MS  070200 SGP01   7020000   70200     0\n 8 SGP       702 70200107 70200008 08MS  070200 SGP01   7020000   70200     0\n 9 SGP       702 70200012 70200009 08MS  070200 SGP01   7020000   70200     0\n10 SGP       702 70200061 70200010 08MS  070200 SGP01   7020000   70200     0\n# ℹ 6,596 more rows\n# ℹ 1,272 more variables: ADMINMODE &lt;dbl&gt;, LANGTEST_QQQ &lt;dbl&gt;,\n#   LANGTEST_COG &lt;dbl&gt;, LANGTEST_PAQ &lt;dbl&gt;, Option_CT &lt;dbl&gt;, Option_FL &lt;dbl&gt;,\n#   Option_ICTQ &lt;dbl&gt;, Option_WBQ &lt;dbl&gt;, Option_PQ &lt;dbl&gt;, Option_TQ &lt;dbl&gt;,\n#   Option_UH &lt;dbl&gt;, BOOKID &lt;dbl&gt;, ST001D01T &lt;dbl&gt;, ST003D02T &lt;dbl&gt;,\n#   ST003D03T &lt;dbl&gt;, ST004D01T &lt;fct&gt;, ST250Q01JA &lt;dbl&gt;, ST250Q02JA &lt;dbl&gt;,\n#   ST250Q03JA &lt;dbl&gt;, ST250Q04JA &lt;dbl&gt;, ST250Q05JA &lt;dbl&gt;, ST250D06JA &lt;chr&gt;, …"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#consolidate-individual-student-performance-data-into-school-wide-metrics",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#consolidate-individual-student-performance-data-into-school-wide-metrics",
    "title": "Take-home Exercise 1",
    "section": "2.2 Consolidate individual student performance data into school-wide metrics",
    "text": "2.2 Consolidate individual student performance data into school-wide metrics\nWe compute the average of plausible value (PV) scores for each subject at the school level. The steps to accomplish this in R include:\n\nAggregation of PV Scores per Subject\n\nStart by determining the average PV scores for every student by taking the mean across the ten plausible values for Mathematics, Reading, and Science respectively.\n\nConsolidation by School\n\nOrganize the dataset around the International School ID (CNTSCHID) to group students according to their school.\n\nSchool-Level Averages\n\nFor each group representing a school, compute the mean of these individual averages. This results in a single average score that represents the collective performance of students in each subject for that school.\n\n\n\nlibrary(dplyr)\n\n# Calculate the mean PV scores for each student in each subject\nstu_qqq_Sg &lt;- stu_qqq_Sg %&gt;%\n  mutate(AvgMathPV = rowMeans(select(., starts_with(\"PV1MATH\"):starts_with(\"PV10MATH\")), na.rm = TRUE),\n         AvgReadPV = rowMeans(select(., starts_with(\"PV1READ\"):starts_with(\"PV10READ\")), na.rm = TRUE),\n         AvgSciePV = rowMeans(select(., starts_with(\"PV1SCIE\"):starts_with(\"PV10SCIE\")), na.rm = TRUE))\n\n# Group by school ID and calculate the mean of the student averages for each school\nschool_avg_scores &lt;- stu_qqq_Sg %&gt;%\n  group_by(CNTSCHID) %&gt;%\n  summarise(AvgMathScore = mean(AvgMathPV, na.rm = TRUE),\n            AvgReadScore = mean(AvgReadPV, na.rm = TRUE),\n            AvgScieScore = mean(AvgSciePV, na.rm = TRUE))\n\n# View the school level averages\nprint(school_avg_scores)\n\n# A tibble: 164 × 4\n   CNTSCHID AvgMathScore AvgReadScore AvgScieScore\n   &lt;fct&gt;           &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n 1 70200001         725.         653.         698.\n 2 70200002         535.         507.         534.\n 3 70200003         740.         665.         714.\n 4 70200004         510.         480.         494.\n 5 70200005         547.         516.         529.\n 6 70200006         487.         468.         477.\n 7 70200007         580.         540.         579.\n 8 70200008         567.         522.         540.\n 9 70200009         560.         536.         552.\n10 70200010         531.         503.         540.\n# ℹ 154 more rows"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#gender-labeling",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#gender-labeling",
    "title": "Take-home Exercise 1",
    "section": "2.3 Gender Labeling",
    "text": "2.3 Gender Labeling\nHere, we label genders and calculate average PV Scores per subject for each student.\n\nlibrary(dplyr)\n\n# Assuming 'stu_qqq_Sg' is your data frame, 'CNTSTUID' is the column with International Student IDs,\n# and 'ST004D01T' is the column with Student Standardized Gender (1 for female; 0 for male)\n\n# Calculate the mean PV scores for each student in each subject and map gender numeric values to labels\ngender_avg_scores &lt;- stu_qqq_Sg %&gt;%\n  mutate(\n    Gender = ifelse(ST004D01T == 1, \"Female\", \"Male\"),\n    AvgMathPV = rowMeans(select(., starts_with(\"PV1MATH\"):starts_with(\"PV10MATH\")), na.rm = TRUE),\n    AvgReadPV = rowMeans(select(., starts_with(\"PV1READ\"):starts_with(\"PV10READ\")), na.rm = TRUE),\n    AvgSciePV = rowMeans(select(., starts_with(\"PV1SCIE\"):starts_with(\"PV10SCIE\")), na.rm = TRUE)\n  )\n\n# Now, 'gender_avg_scores' contains the individual student's data with their gender and average scores\nprint(gender_avg_scores)\n\n# A tibble: 6,606 × 1,283\n   CNT   CNTRYID CNTSCHID CNTSTUID CYC   NatCen STRATUM SUBNATIO REGION  OECD\n   &lt;chr&gt;   &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt;    &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;\n 1 SGP       702 70200052 70200001 08MS  070200 SGP01   7020000   70200     0\n 2 SGP       702 70200134 70200002 08MS  070200 SGP01   7020000   70200     0\n 3 SGP       702 70200112 70200003 08MS  070200 SGP01   7020000   70200     0\n 4 SGP       702 70200004 70200004 08MS  070200 SGP01   7020000   70200     0\n 5 SGP       702 70200152 70200005 08MS  070200 SGP01   7020000   70200     0\n 6 SGP       702 70200043 70200006 08MS  070200 SGP01   7020000   70200     0\n 7 SGP       702 70200049 70200007 08MS  070200 SGP01   7020000   70200     0\n 8 SGP       702 70200107 70200008 08MS  070200 SGP01   7020000   70200     0\n 9 SGP       702 70200012 70200009 08MS  070200 SGP01   7020000   70200     0\n10 SGP       702 70200061 70200010 08MS  070200 SGP01   7020000   70200     0\n# ℹ 6,596 more rows\n# ℹ 1,273 more variables: ADMINMODE &lt;dbl&gt;, LANGTEST_QQQ &lt;dbl&gt;,\n#   LANGTEST_COG &lt;dbl&gt;, LANGTEST_PAQ &lt;dbl&gt;, Option_CT &lt;dbl&gt;, Option_FL &lt;dbl&gt;,\n#   Option_ICTQ &lt;dbl&gt;, Option_WBQ &lt;dbl&gt;, Option_PQ &lt;dbl&gt;, Option_TQ &lt;dbl&gt;,\n#   Option_UH &lt;dbl&gt;, BOOKID &lt;dbl&gt;, ST001D01T &lt;dbl&gt;, ST003D02T &lt;dbl&gt;,\n#   ST003D03T &lt;dbl&gt;, ST004D01T &lt;fct&gt;, ST250Q01JA &lt;dbl&gt;, ST250Q02JA &lt;dbl&gt;,\n#   ST250Q03JA &lt;dbl&gt;, ST250Q04JA &lt;dbl&gt;, ST250Q05JA &lt;dbl&gt;, ST250D06JA &lt;chr&gt;, …"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#create-clean-hisei-and-escs-dataframes",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#create-clean-hisei-and-escs-dataframes",
    "title": "Take-home Exercise 1",
    "section": "2.4 Create clean HISEI and ESCS dataframes",
    "text": "2.4 Create clean HISEI and ESCS dataframes\nAs mentioned earlier, we’ll create a new dataframe for HISEI where any row with a missing HISEI value is removed. This will reduce our dataset by 310 rows.\n\n# Assuming 'stu_qqq_Sg' is your original data frame\n\n# Creating a data frame for HISEI\ndf_hisei &lt;- stu_qqq_Sg %&gt;%\n  filter(!is.na(HISEI)) %&gt;%\n  mutate(\n    AvgMathPV = rowMeans(select(., starts_with(\"PV1MATH\"), starts_with(\"PV10MATH\")), na.rm = TRUE),\n    AvgReadPV = rowMeans(select(., starts_with(\"PV1READ\"), starts_with(\"PV10READ\")), na.rm = TRUE),\n    AvgSciePV = rowMeans(select(., starts_with(\"PV1SCIE\"), starts_with(\"PV10SCIE\")), na.rm = TRUE)\n  )\n\nprint(df_hisei)\n\n# A tibble: 6,296 × 1,282\n   CNT   CNTRYID CNTSCHID CNTSTUID CYC   NatCen STRATUM SUBNATIO REGION  OECD\n   &lt;chr&gt;   &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt;    &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;\n 1 SGP       702 70200052 70200001 08MS  070200 SGP01   7020000   70200     0\n 2 SGP       702 70200134 70200002 08MS  070200 SGP01   7020000   70200     0\n 3 SGP       702 70200112 70200003 08MS  070200 SGP01   7020000   70200     0\n 4 SGP       702 70200004 70200004 08MS  070200 SGP01   7020000   70200     0\n 5 SGP       702 70200152 70200005 08MS  070200 SGP01   7020000   70200     0\n 6 SGP       702 70200043 70200006 08MS  070200 SGP01   7020000   70200     0\n 7 SGP       702 70200049 70200007 08MS  070200 SGP01   7020000   70200     0\n 8 SGP       702 70200107 70200008 08MS  070200 SGP01   7020000   70200     0\n 9 SGP       702 70200012 70200009 08MS  070200 SGP01   7020000   70200     0\n10 SGP       702 70200061 70200010 08MS  070200 SGP01   7020000   70200     0\n# ℹ 6,286 more rows\n# ℹ 1,272 more variables: ADMINMODE &lt;dbl&gt;, LANGTEST_QQQ &lt;dbl&gt;,\n#   LANGTEST_COG &lt;dbl&gt;, LANGTEST_PAQ &lt;dbl&gt;, Option_CT &lt;dbl&gt;, Option_FL &lt;dbl&gt;,\n#   Option_ICTQ &lt;dbl&gt;, Option_WBQ &lt;dbl&gt;, Option_PQ &lt;dbl&gt;, Option_TQ &lt;dbl&gt;,\n#   Option_UH &lt;dbl&gt;, BOOKID &lt;dbl&gt;, ST001D01T &lt;dbl&gt;, ST003D02T &lt;dbl&gt;,\n#   ST003D03T &lt;dbl&gt;, ST004D01T &lt;fct&gt;, ST250Q01JA &lt;dbl&gt;, ST250Q02JA &lt;dbl&gt;,\n#   ST250Q03JA &lt;dbl&gt;, ST250Q04JA &lt;dbl&gt;, ST250Q05JA &lt;dbl&gt;, ST250D06JA &lt;chr&gt;, …\n\n\nFor ESCS, We’ll make another dataframe where we remove rows missing ESCS values. This will decrease the dataset by 47 rows.\n\nlibrary(dplyr)\n\n# Assuming 'stu_qqq_Sg' is your original data frame\n\n# Creating a data frame for ESCS\ndf_escs &lt;- stu_qqq_Sg %&gt;%\n  filter(!is.na(ESCS)) %&gt;%\n  mutate(\n    AvgMathPV = rowMeans(select(., starts_with(\"PV1MATH\"), starts_with(\"PV10MATH\")), na.rm = TRUE),\n    AvgReadPV = rowMeans(select(., starts_with(\"PV1READ\"), starts_with(\"PV10READ\")), na.rm = TRUE),\n    AvgSciePV = rowMeans(select(., starts_with(\"PV1SCIE\"), starts_with(\"PV10SCIE\")), na.rm = TRUE)\n  )\n\nprint(df_escs) \n\n# A tibble: 6,559 × 1,282\n   CNT   CNTRYID CNTSCHID CNTSTUID CYC   NatCen STRATUM SUBNATIO REGION  OECD\n   &lt;chr&gt;   &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt;    &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;\n 1 SGP       702 70200052 70200001 08MS  070200 SGP01   7020000   70200     0\n 2 SGP       702 70200134 70200002 08MS  070200 SGP01   7020000   70200     0\n 3 SGP       702 70200112 70200003 08MS  070200 SGP01   7020000   70200     0\n 4 SGP       702 70200004 70200004 08MS  070200 SGP01   7020000   70200     0\n 5 SGP       702 70200152 70200005 08MS  070200 SGP01   7020000   70200     0\n 6 SGP       702 70200043 70200006 08MS  070200 SGP01   7020000   70200     0\n 7 SGP       702 70200049 70200007 08MS  070200 SGP01   7020000   70200     0\n 8 SGP       702 70200107 70200008 08MS  070200 SGP01   7020000   70200     0\n 9 SGP       702 70200012 70200009 08MS  070200 SGP01   7020000   70200     0\n10 SGP       702 70200061 70200010 08MS  070200 SGP01   7020000   70200     0\n# ℹ 6,549 more rows\n# ℹ 1,272 more variables: ADMINMODE &lt;dbl&gt;, LANGTEST_QQQ &lt;dbl&gt;,\n#   LANGTEST_COG &lt;dbl&gt;, LANGTEST_PAQ &lt;dbl&gt;, Option_CT &lt;dbl&gt;, Option_FL &lt;dbl&gt;,\n#   Option_ICTQ &lt;dbl&gt;, Option_WBQ &lt;dbl&gt;, Option_PQ &lt;dbl&gt;, Option_TQ &lt;dbl&gt;,\n#   Option_UH &lt;dbl&gt;, BOOKID &lt;dbl&gt;, ST001D01T &lt;dbl&gt;, ST003D02T &lt;dbl&gt;,\n#   ST003D03T &lt;dbl&gt;, ST004D01T &lt;fct&gt;, ST250Q01JA &lt;dbl&gt;, ST250Q02JA &lt;dbl&gt;,\n#   ST250Q03JA &lt;dbl&gt;, ST250Q04JA &lt;dbl&gt;, ST250Q05JA &lt;dbl&gt;, ST250D06JA &lt;chr&gt;, …"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#distribution-of-average-plausible-values-by-students-in-singapore",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#distribution-of-average-plausible-values-by-students-in-singapore",
    "title": "Take-home Exercise 1",
    "section": "3.1 Distribution of Average Plausible Values by Students in Singapore",
    "text": "3.1 Distribution of Average Plausible Values by Students in Singapore\n\nlibrary(tidyverse)\nlibrary(hrbrthemes)\nlibrary(viridis)\nlibrary(forcats)\n\n# Reshape the data to long format\nstudent_avg_long &lt;- student_avg_scores %&gt;%\n  pivot_longer(\n    cols = c(AvgMathPV, AvgReadPV, AvgSciePV),\n    names_to = \"subject\",\n    values_to = \"value\"\n  )\n\n# Replace the subject names with more readable names if necessary\nstudent_avg_long$subject &lt;- recode(student_avg_long$subject,\n                                   AvgMathPV = \"Mathematics\",\n                                   AvgReadPV = \"Reading\",\n                                   AvgSciePV = \"Science\")\n\n# Create the ggplot object with larger axis title texts\np &lt;- student_avg_long %&gt;%\n  ggplot(aes(x = value, fill = subject)) +\n  geom_histogram(binwidth = 10, alpha = 1) +  # Full opacity\n  scale_fill_manual(values = c(\"Mathematics\" = \"darkblue\", \"Reading\" = \"orange\", \"Science\" = \"darkgreen\")) +\n  facet_wrap(~subject, scales = \"free_x\", ncol = 3) +\n  labs(\n    title = 'Distribution of Average Plausible Values for Each Subject',\n    x = 'Average Plausible Values',\n    y = 'Count of Students'\n  ) +\n  theme_ipsum(base_size = 16) +  # Increase base font size\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 20),  # Center and increase plot title size\n    axis.title.x = element_text(hjust = 0.5, size = 14),  # Center and increase x-axis title size\n    axis.title.y = element_text(hjust = 0.5, size = 14),  # Center and increase y-axis title size\n    strip.text = element_text(hjust = 0.5),  # Center the facet labels\n    legend.position = \"none\",\n    panel.spacing = unit(0.1, \"lines\"),\n    axis.text.x = element_text(size = 14),   # Increase x-axis tick label size\n    axis.text.y = element_text(size = 14),   # Increase y-axis tick label size\n    axis.ticks.y = element_line(color = \"black\"),\n    panel.grid.major.y = element_line(colour = \"grey90\"),  # Specify color for horizontal grid lines\n    panel.grid.major.x = element_blank(),  # Remove vertical grid lines\n    panel.grid.minor.x = element_blank(),  # Remove minor vertical grid lines\n    # Ensure the axis text and ticks for the non-leftmost panels are removed\n    axis.text.y.right = element_blank(),\n    axis.ticks.y.right = element_blank()\n  )\n\n# Print the plot\np\n\n\n\n\nFor each subject represented in the histograms, the scores predominantly converge around a central peak, indicative of the mode — the score range that most students fall into. The distribution patterns reveal a diminished number of students attaining scores at both extremities of the spectrum, either very high or very low. This results in a bell-shaped curve, reflecting a typical distribution where scores are most densely populated near the central value."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#distribution-of-average-plausible-values-by-school",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#distribution-of-average-plausible-values-by-school",
    "title": "Take-home Exercise 1",
    "section": "3.2 Distribution of Average Plausible Values by School",
    "text": "3.2 Distribution of Average Plausible Values by School\n\nlibrary(tidyverse)\nlibrary(hrbrthemes)\nlibrary(viridis)\nlibrary(forcats)\n\n# Rank schools by AvgMathScore, AvgReadScore, and AvgScieScore and add labels for top and bottom schools\nschool_avg_scores &lt;- school_avg_scores %&gt;%\n  mutate(\n    RankMath = rank(-AvgMathScore),\n    RankRead = rank(-AvgReadScore),\n    RankScie = rank(-AvgScieScore),\n    LabelMath = ifelse(RankMath == 1 | RankMath == n(), as.character(CNTSCHID), NA),\n    LabelRead = ifelse(RankRead == 1 | RankRead == n(), as.character(CNTSCHID), NA),\n    LabelScie = ifelse(RankScie == 1 | RankScie == n(), as.character(CNTSCHID), NA)\n  )\n\n# Find the maximum score to set the limits of the y-axis\nmax_score &lt;- max(school_avg_scores$AvgMathScore, school_avg_scores$AvgReadScore, school_avg_scores$AvgScieScore)\nmax_rank &lt;- max(school_avg_scores$RankMath, school_avg_scores$RankRead, school_avg_scores$RankScie, na.rm = TRUE) + 10\np &lt;- ggplot(school_avg_scores) +\n  geom_point(aes(x = RankMath, y = AvgMathScore, color = \"Mathematics\"), size = 0.5) +\n  geom_point(aes(x = RankRead, y = AvgReadScore, color = \"Reading\"), size = 0.5) +\n  geom_point(aes(x = RankScie, y = AvgScieScore, color = \"Science\"), size = 0.5) +\n  geom_text(data = subset(school_avg_scores, !is.na(LabelMath)), \n            aes(x = ifelse(RankMath == 1, RankMath + 30, RankMath + 1), y = AvgMathScore, \n                label = ifelse(RankMath == 1, paste(\"Maths/Science =\", LabelMath), \"\")), size = 2.5) +\n  geom_text(data = subset(school_avg_scores, !is.na(LabelRead)), \n            aes(x = ifelse(RankRead == 1, RankRead + 35, RankRead + 1), y = AvgReadScore, \n                label = ifelse(RankRead == 1, paste(\"Reading =\", LabelRead), \"\")), size = 2.5) +\n  geom_text(data = subset(school_avg_scores, !is.na(LabelMath) & RankMath != 1), \n            aes(x = RankMath - 0.2, y = AvgMathScore - 120, \n                label = paste(\"Maths/Reading =\", LabelMath)), size = 2.5) +\n  geom_text(data = subset(school_avg_scores, !is.na(LabelScie) & RankScie != 1), \n            aes(x = RankScie - 0.2, y = AvgScieScore - 160, \n                label = paste(\"Science =\", LabelScie)), size = 2.5) +\n  scale_color_viridis_d() +\n   scale_color_manual(values = c(\"Mathematics\" = \"darkblue\", \"Reading\" = \"orange\", \"Science\" = \"darkgreen\")) +\n  theme_ipsum() +\n  labs(title = 'Distribution of Average Plausible Values by School',\n       color = \"\") +  # Remove the word \"Subject\" from the legend\n  theme(\n    legend.position = \"top\",  # Move the legend to the top\n    legend.justification = c(1, 1),  # Align the legend to the top-right corner\n    legend.text = element_text(size = 11),  # Decrease legend text size to 11\n    axis.title.x = element_text(size = 14, hjust = 0.5),  # Increase x-axis title size and center\n    axis.title.y = element_text(size = 14, hjust = 0.5),  # Increase y-axis title size and center\n    plot.title = element_text(size = 20, hjust = 0.5),  # Center the title\n    plot.subtitle = element_text(size = 14),\n    axis.text.x = element_blank(),  # Remove x-axis labels\n    panel.grid.major.x = element_blank(),  # Remove vertical gridlines\n    panel.grid.minor.x = element_blank()  # Remove vertical gridlines\n  ) +\n  xlab('International School ID') +\n  ylab('Average Plausible Values') +\n  coord_cartesian(xlim = c(0, max_rank + 2), ylim = c(0, max_score * 1.1))  # Adjusted coordinate limits\n\n# Print the plot\nprint(p)\n\n\n\n\nThe data points create a descending trajectory from left to right, indicating that schools positioned at the left end of the spectrum generally exhibit higher average scores compared to those towards the right. This gradient suggests performance disparities across schools, with some institutions outperforming others.\nThe data presents noteworthy insights, particularly the exemplary performance in Mathematics and Science by the school labeled with ID 70200003. In contrast, the school assigned ID 70200149 is distinguished by its underachievement in both Mathematics and Reading."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#distribution-of-average-plausible-values-by-gender",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#distribution-of-average-plausible-values-by-gender",
    "title": "Take-home Exercise 1",
    "section": "3.3 Distribution of Average Plausible Values by Gender",
    "text": "3.3 Distribution of Average Plausible Values by Gender\n\nlibrary(dplyr)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(hrbrthemes)  # Load hrbrthemes for theme_ipsum\n\n# Assuming 'stu_qqq_Sg' is your data frame\n\n# Prepare the data with gender and average scores\ngender_scores &lt;- stu_qqq_Sg %&gt;%\n  mutate(\n    Gender = ifelse(ST004D01T == 1, \"Female\", \"Male\"),\n    AvgMathPV = rowMeans(select(., starts_with(\"PV1MATH\"):starts_with(\"PV10MATH\")), na.rm = TRUE),\n    AvgReadPV = rowMeans(select(., starts_with(\"PV1READ\"):starts_with(\"PV10READ\")), na.rm = TRUE),\n    AvgSciePV = rowMeans(select(., starts_with(\"PV1SCIE\"):starts_with(\"PV10SCIE\")), na.rm = TRUE)\n  )\n\n# Reshape the data to long format\nlong_format &lt;- gender_scores %&gt;%\n  select(CNTSTUID, Gender, AvgMathPV, AvgReadPV, AvgSciePV) %&gt;%\n  pivot_longer(\n    cols = c(AvgMathPV, AvgReadPV, AvgSciePV),\n    names_to = \"Subject\",\n    values_to = \"Score\"\n  ) %&gt;%\n  mutate(Subject = recode(Subject,\n                          AvgMathPV = \"Mathematics\",\n                          AvgReadPV = \"Reading\",\n                          AvgSciePV = \"Science\"))\n\n# Calculate averages for each group\ngroup_averages &lt;- long_format %&gt;%\n  group_by(Gender, Subject) %&gt;%\n  summarize(AvgScore = mean(Score, na.rm = TRUE), .groups = 'drop')\n\n# Create the boxplot with gender colors and move the facet labels to the top\nboxplot &lt;- ggplot(long_format, aes(x = Gender, y = Score, fill = Gender)) +\n  geom_boxplot() +\n  geom_point(data = group_averages, aes(x = Gender, y = AvgScore, group = Gender), \n             color = \"red\", size = 2, show.legend = FALSE) +  # Change dot color to red\n  geom_text(data = group_averages, aes(x = Gender, y = AvgScore, label = paste(\"Avg=\", round(AvgScore, 1))), \n            nudge_y = 10, color = \"black\", size = 2.5, show.legend = FALSE, vjust = -1) +  # Remove fontface argument\n  facet_wrap(~Subject, strip.position = \"top\", labeller = labeller(Subject = c(Mathematics = \"Mathematics\", Reading = \"Reading\", Science = \"Science\"))) +\n  labs(\n    title = \"PV Score Distribution by Gender and Subject\",\n    x = \"\",\n    y = \"Average Plausible Values\"\n  ) +\n  theme_ipsum(base_size = 16, base_family = \"\") +  # Set base font size to 16\n  theme(\n    legend.title = element_blank(),\n    legend.position = \"bottom\",\n    strip.text = element_text(size = 11, hjust = 0.5),  # Center facet labels and increase size\n    axis.text.x = element_blank(),  # Remove x-axis labels\n    axis.ticks.x = element_blank(),  # Remove x-axis ticks\n    plot.title = element_text(size = 18, hjust = 0.5),  # Center plot title\n    axis.text.y = element_text(size = 11, hjust = 0.5),  # Center y-axis text\n    axis.title.y = element_text(size = 14, hjust = 0.5),  # Center y-axis title\n    panel.grid.major.x = element_blank(),  # Remove vertical gridlines\n    panel.grid.minor.x = element_blank()  # Remove vertical gridlines\n  ) +\n  scale_y_continuous(limits = c(0, NA), expand = expansion(mult = c(0, 0.05))) +  # Start y-axis at 0\n  scale_fill_manual(values = c(\"Female\" = \"#FF69B4\", \"Male\" = \"#1E90FF\"))\n\n# Print the boxplot\nprint(boxplot)\n\n\n\n\nThe box plots illustrate the median scores (indicated by the line within each box), the interquartile range (the span of the box), and the range of the data (the “whiskers” extending from the boxes), which includes outliers (represented by the dots).\nThe red dots represent the mean scores and we can see that in Mathematics, male students have a slightly higher average score (579.5) compared to female students (568.2). The Reading scores show a more pronounced difference, with female students having a higher average score (552.9) than male students (532.4). In Science, the average scores are closer, with male students averaging 563.9 and female students averaging 558."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#relationship-between-hisei-and-average-pv-scores",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#relationship-between-hisei-and-average-pv-scores",
    "title": "Take-home Exercise 1",
    "section": "3.4 Relationship between HISEI and Average PV Scores",
    "text": "3.4 Relationship between HISEI and Average PV Scores\n\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(hrbrthemes)  # Load hrbrthemes for theme_ipsum\n\n# Assuming 'df_hisei' is your data frame and it has been loaded correctly\n\n# Reshaping the data\nlong_df_hisei &lt;- df_hisei %&gt;%\n  pivot_longer(\n    cols = c(\"AvgMathPV\", \"AvgReadPV\", \"AvgSciePV\"),\n    names_to = \"Subject\",\n    values_to = \"AveragePV\"\n  ) %&gt;%\n  mutate(Subject = recode(Subject,\n                          \"AvgMathPV\" = \"Math\",\n                          \"AvgReadPV\" = \"Reading\",\n                          \"AvgSciePV\" = \"Science\"))\n\n# Creating a scatter plot with ggplot2\nggplot(long_df_hisei, aes(x = HISEI, y = AveragePV, color = Subject)) +\n  geom_point(size = 0.4, alpha = 0.5) +\n  geom_smooth(method = \"lm\", se = FALSE, aes(group = Subject), size = 0.8) +  # Adjust the size for trend lines\n  scale_color_manual(values = c(\"Math\" = \"darkblue\", \"Reading\" = \"orange\", \"Science\" = \"darkgreen\")) +\n  labs(title = 'Relationship between HISEI and Average PV Scores',\n       x = 'HISEI',\n       y = 'Average PV Score') +\n  theme_ipsum() +\n  theme(\n    legend.title = element_blank(),\n    legend.text = element_text(size = 12),  # Increase legend font size to 11\n    legend.position = \"bottom\",  # Adjust legend position\n    axis.title.x = element_text(size = 12, hjust = 0.5),  # Increase x-axis title font size and center\n    axis.title.y = element_text(size = 12, hjust = 0.5),  # Increase y-axis title font size and center\n    plot.title = element_text(size = 20, hjust = 0.5),  # Center main title and set font size to 20\n    panel.grid.minor = element_blank()  # Remove minor gridlines\n  ) +\n  scale_x_continuous(limits = c(0, NA)) +  # Start x-axis at 0\n  scale_y_continuous(limits = c(0, NA))  # Start y-axis at 0\n\n\n\n\nThe trend lines for each subject indicate a positive correlation between HISEI and the average PV scores, suggesting that as HISEI increases, so does the average score in these subjects. In other words, students with higher socio-economic backgrounds, as measured by their parents’ occupational status, tend to score higher average PV scores.\nHowever, the spread of the data points suggests there is variability that is not solely explained by HISEI. This indicates that while there is a trend, there are other factors at play influencing student performance in these subjects. The wide dispersion of scores at similar HISEI levels suggests that other factors may influence educational outcomes."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#relationship-between-escs-and-average-pv-scores",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#relationship-between-escs-and-average-pv-scores",
    "title": "Take-home Exercise 1",
    "section": "3.5 Relationship between ESCS and Average PV Scores",
    "text": "3.5 Relationship between ESCS and Average PV Scores\n\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(hrbrthemes)  # Load hrbrthemes for theme_ipsum\n\n# Assuming 'df_escs' is your data frame and it has been loaded correctly\n\n# Reshaping the data\nlong_df_escs &lt;- df_escs %&gt;%\n  pivot_longer(\n    cols = c(\"AvgMathPV\", \"AvgReadPV\", \"AvgSciePV\"),\n    names_to = \"Subject\",\n    values_to = \"AveragePV\"\n  ) %&gt;%\n  mutate(Subject = recode(Subject,\n                          \"AvgMathPV\" = \"Math\",\n                          \"AvgReadPV\" = \"Reading\",\n                          \"AvgSciePV\" = \"Science\"))\n\n# Creating a scatter plot with ggplot2\nggplot(long_df_escs, aes(x = ESCS, y = AveragePV, color = Subject)) +\n  geom_point(size = 0.4, alpha = 0.5) +\n  geom_smooth(method = \"lm\", se = FALSE, aes(group = Subject), size = 0.8) +  # Adjust the size for trend lines\n  scale_color_manual(values = c(\"Math\" = \"darkblue\", \"Reading\" = \"orange\", \"Science\" = \"darkgreen\")) +\n  labs(title = 'Relationship between ESCS and Average PV Scores',\n       x = 'ESCS',\n       y = 'Average PV Score') +\n  theme_ipsum() +\n  theme(\n    legend.title = element_blank(),\n    legend.text = element_text(size = 12),  # Increase legend font size to 12\n    legend.position = \"bottom\",  # Adjust legend position\n    axis.title.x = element_text(size = 12, hjust = 0.5),  # Increase x-axis title font size to 14 and center\n    axis.title.y = element_text(size = 12, hjust = 0.5),  # Increase y-axis title font size to 14 and center\n    plot.title = element_text(size = 20, hjust = 0.5),  # Center main title and set font size to 18\n    panel.grid.minor = element_blank()  # Remove minor gridlines\n  ) +\n  scale_x_continuous(limits = c(0, NA)) +  # Start x-axis at 0\n  scale_y_continuous(limits = c(0, NA))  # Start y-axis at 0\n\n\n\n\nAll three subjects show a positive correlation between the ESCS and the average PV scores, as indicated by the upward trend of the lines fitted to the data points in each subject area. This suggests that students whose parents have higher index of economic, social and cultural status tend to achieve better average scores. The trend lines for each subject are quite close to one another, indicating that the relationship between ESCS and average PV scores is similar across all three subjects.\nThe scatter plot indicates a more concentrated distribution of data points around the trend line for each subject area when assessing the relationship between ESCS and average PV scores. This tighter clustering suggests that ESCS may have a more consistent association with student performance in Mathematics, Reading, and Science, compared to the broader spread observed with HISEI.\nWhile the trend lines still point to a positive correlation—higher ESCS often correlates with higher PV scores—the reduced spread implies that ESCS could be a more reliable indicator of average scores. Nevertheless, the presence of scores outside the immediate vicinity of the trend lines does indicate that factors beyond ESCS also play a role in educational performance."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "In this Take-home Exercise 2, I have chosen one of my classmates’ Take-home Exercise 1 submissions and analyzed the charts in terms of clarity and aesthetics. My task involves critically assessing the design and visual presentation of the chosen submission. Using the data visualization design principles and best practices learned in Lessons 1 and 2, I will create a sketch for an alternative design. Subsequently, I will remake the original design using the ggplot2, ggplot2 extensions, and tidyverse packages to enhance its visual effectiveness and clarity."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#installing-r-packages",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#installing-r-packages",
    "title": "Take-home Exercise 2",
    "section": "1.1 Installing R packages",
    "text": "1.1 Installing R packages\npacman::p_load() function from the pacman package is used in the following code chunk to install and call the libraries of multiple R packages:\n\npacman::p_load(tidyverse, haven, ggrepel, patchwork, \n               ggthemes, hrbrthemes)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-dataset",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-dataset",
    "title": "Take-home Exercise 2",
    "section": "1.2 Importing Dataset",
    "text": "1.2 Importing Dataset\n“Student questionnaire data file” from the PISA 2022 database is provided for the task.\nThe code chunk below uses read_sas() of haven to import PISA data into R environment.\n\nstu_qqq &lt;- read_sas(\"../../data/STU_QQQ_SAS/cy08msp_stu_qqq.sas7bdat\")\n\n\nstu_qqq_SG &lt;- stu_qqq %&gt;%\n  filter(CNT == \"SGP\")\n\n\nwrite_rds(stu_qqq_SG,\n          \"../../data/STU_QQQ_SAS/stu_qqq_SG.rds\")\n\nWe upload the file as stu_qqq_Sg.\n\nstu_qqq_Sg &lt;-\n  read_rds(\"../../data/STU_QQQ_SAS/stu_qqq_SG.rds\")\n\nThe makeover is designed to refine the original visualization while staying true to the dataset’s range, as selected by my classmate. Therefore, I will be focusing on the same variables: student performance in mathematics, reading, and science, along with school identification, gender, and parental education levels.\n\nRelated_math_read_scie_data &lt;- stu_qqq_SG %&gt;%\n  select(contains(c(\"ID\",\"ST004D01T\",\"math\", \"read\", \"scie\",\"ST259Q01JA\",\"ST259Q02JA\",\"ST005Q01JA\",\"ST007Q01JA\")))\n\n\nwrite_rds(Related_math_read_scie_data,\n          \"../../data/Related_math_read_scie_data.rds\")\n\n\nRelated_math_read_scie_data &lt;- \nread_rds(\"../../data/Related_math_read_scie_data.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#original-design",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#original-design",
    "title": "Take-home Exercise 2",
    "section": "2.1 Original Design",
    "text": "2.1 Original Design\nThe original design is shown below. \nThe use of histograms with median lines, is a good start for visualizing the distribution of plausible values (PV) across different subjects. However, there are several improvements that could be made."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#enhancements-for-clarity",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#enhancements-for-clarity",
    "title": "Take-home Exercise 2",
    "section": "2.2 Enhancements for Clarity",
    "text": "2.2 Enhancements for Clarity"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#a-main-graph-title-refinement",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#a-main-graph-title-refinement",
    "title": "Take-home Exercise 2",
    "section": "(a) Main Graph Title Refinement",
    "text": "(a) Main Graph Title Refinement\nThe initial graph title ‘Distributions of Maths/Reading/Science with Median Lines’ lacked descriptive power. A revised title, ‘Distribution of Average Plausible Values in Among Students in Singapore,’ provides a more detailed and informative overview of the data presented."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#b-x-axis-labeling",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#b-x-axis-labeling",
    "title": "Take-home Exercise 2",
    "section": "(b) X-axis Labeling",
    "text": "(b) X-axis Labeling\nThe use of column names such as ‘avg_pvMATH’, ‘avg_pvREAD’, and ‘avg_pvSCIE’ as x-axis labels could lead to confusion due to their technical nature. A more accessible approach is to apply a unified label, ‘Average Plausible Values,’ which directly communicates the essence of the data to the reader."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#c-y-axis-scale-uniformity",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#c-y-axis-scale-uniformity",
    "title": "Take-home Exercise 2",
    "section": "(c) Y-axis Scale Uniformity",
    "text": "(c) Y-axis Scale Uniformity\nIt is imperative to synchronize the y-axis scales for all histograms to enable a fair and accurate comparative analysis. The current graphs exhibit varying y-axis scales, which could skew the interpretation of the data. By standardizing these scales, we establish a consistent metric for evaluating the distributions of student performance in the various subjects."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#d-y-axis-label-simplification",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#d-y-axis-label-simplification",
    "title": "Take-home Exercise 2",
    "section": "(d) Y-axis Label Simplification",
    "text": "(d) Y-axis Label Simplification\nWith the y-axis scales aligned, we can enhance the graphs’ neatness by eliminating the ‘Count’ labels and the associated numerical values on the y-axis for the second and third histograms. This declutters the visual space and directs focus to the data itself."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#e-titles-for-individual-graphs",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#e-titles-for-individual-graphs",
    "title": "Take-home Exercise 2",
    "section": "(e) Titles for Individual Graphs",
    "text": "(e) Titles for Individual Graphs\nThe generic ‘I’, ‘II’, and ‘III’ designations for individual graph titles are less informative. These should be replaced with the subject names ‘Mathematics’, ‘Reading’, and ‘Science’ to convey the content of each graph to the viewer."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#f-median-annotation-clarity",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#f-median-annotation-clarity",
    "title": "Take-home Exercise 2",
    "section": "(f) Median Annotation Clarity",
    "text": "(f) Median Annotation Clarity\nThe current placement of the median value at the bottom intersects with the x-axis, which hampers legibility. Moving this annotation on top of the bars ensures it is unobstructed and easily readable."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#aesthetic-improvements",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#aesthetic-improvements",
    "title": "Take-home Exercise 2",
    "section": "2.3 Aesthetic Improvements",
    "text": "2.3 Aesthetic Improvements"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#a-centering-the-main-graph-title",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#a-centering-the-main-graph-title",
    "title": "Take-home Exercise 2",
    "section": "(a) Centering the Main Graph Title",
    "text": "(a) Centering the Main Graph Title\nA central alignment for the main graph title is aesthetically pleasing and anchors the viewer’s attention, compared to the original left-aligned positioning."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#b-gridline-and-background-differentiation",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#b-gridline-and-background-differentiation",
    "title": "Take-home Exercise 2",
    "section": "(b) Gridline and Background Differentiation",
    "text": "(b) Gridline and Background Differentiation\nThe grey bars against a grey background, intersected by white gridlines, result in a low-contrast visual that can be difficult to interpret. By removing the grey background and recoloring the gridlines to grey, we create a stark contrast that allows the data bars to stand out sharply, enhancing the graph’s readability."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#sketch-of-proposed-design",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#sketch-of-proposed-design",
    "title": "Take-home Exercise 2",
    "section": "2.4 Sketch of Proposed Design",
    "text": "2.4 Sketch of Proposed Design"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-wrangling",
    "title": "Take-home Exercise 2",
    "section": "2.5 Data Wrangling",
    "text": "2.5 Data Wrangling\nCalculate the mean of Plausible Values 1 through 10 for Mathematics, Reading and Science respectively.\n\nRelated_math_read_scie_data &lt;- Related_math_read_scie_data %&gt;%\n  mutate(avg_pvMATH = rowMeans(select(., ends_with(\"Math\")), na.rm = TRUE))\n\nRelated_math_read_scie_data &lt;- Related_math_read_scie_data %&gt;%\n  mutate(avg_pvREAD = rowMeans(select(., ends_with(\"READ\")), na.rm = TRUE))\n\nRelated_math_read_scie_data &lt;- Related_math_read_scie_data %&gt;%\n  mutate(avg_pvSCIE = rowMeans(select(., ends_with(\"SCIE\")), na.rm = TRUE))\n\nRelated_math_read_scie_data %&gt;%\n  select(CNTSCHID, CNTSTUID,avg_pvMATH, avg_pvREAD, avg_pvSCIE) %&gt;%\n  head(5)\n\n# A tibble: 5 × 5\n  CNTSCHID CNTSTUID avg_pvMATH avg_pvREAD avg_pvSCIE\n     &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 70200052 70200001       605.       667.       640.\n2 70200134 70200002       690.       628.       672.\n3 70200112 70200003       677.       583.       660.\n4 70200004 70200004       401.       361.       344.\n5 70200152 70200005       436.       476.       479."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#final-design",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#final-design",
    "title": "Take-home Exercise 2",
    "section": "2.6 Final Design",
    "text": "2.6 Final Design\nAfter performing the necessary modifications, the final code and design are as follows.\n\ncreate_histogram &lt;- function(data, subject_column, subject_name, max_y_value, show_labels = TRUE) {\n  median_value &lt;- median(data[[subject_column]])\n  \n  p &lt;- ggplot(data, aes_string(x = subject_column)) +\n    geom_histogram(bins = 10, \n                   boundary = 100,\n                   color = \"black\", \n                   fill=\"grey\") +\n    geom_vline(xintercept = median_value, color = \"red\", linetype = \"dashed\") +\n    annotate(\"text\", x = median_value, y = max_y_value * 0.9, \n             label = paste(\"Median = \", round(median_value, 2)), \n             vjust = 0, color = \"red\", size = 3) + # Adjusted placement for annotation\n    theme_minimal() +\n    theme(\n      panel.grid.major = element_line(color = \"grey\", size = 0.1),\n      panel.grid.minor = element_blank(),\n      panel.background = element_blank(),\n      axis.text.y = element_text(color = \"black\"),\n      axis.text.x = element_text(color = \"black\"),\n      axis.title.x = element_blank(), # Remove x-axis title\n      plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5)\n    ) +\n    coord_cartesian(ylim = c(0, max_y_value)) # Set y-axis limits\n  \n  if (!show_labels) {\n    p &lt;- p + theme(\n      axis.title.y = element_blank(),\n      axis.text.y = element_blank(),\n      axis.ticks.y = element_blank()\n    )\n  } else {\n    p &lt;- p + labs(y = \"Count\")\n  }\n  \n  p &lt;- p + labs(title = subject_name)\n  \n  return(p)\n}\n\n# Calculate the maximum y-value to use as the y-axis limit\nmax_y_value &lt;- max(\n  max(table(cut(Related_math_read_scie_data$avg_pvMATH, breaks = 10))),\n  max(table(cut(Related_math_read_scie_data$avg_pvREAD, breaks = 10))),\n  max(table(cut(Related_math_read_scie_data$avg_pvSCIE, breaks = 10)))\n) * 1.3 # Extend y-axis to fit annotation\n\n# Create histograms with consistent y-axis limits\np1 &lt;- create_histogram(Related_math_read_scie_data, \"avg_pvMATH\", \"Mathematics\", max_y_value, TRUE)\np2 &lt;- create_histogram(Related_math_read_scie_data, \"avg_pvREAD\", \"Reading\", max_y_value, FALSE)\np3 &lt;- create_histogram(Related_math_read_scie_data, \"avg_pvSCIE\", \"Science\", max_y_value, FALSE)\n\n# Create an empty plot with just the x-axis label\nx_axis_label &lt;- ggplot() + \n  theme_void() + \n  labs(x = \"Average Plausible Values\") +\n  theme(\n    plot.margin = margin(t = 0, b = -1, l = 0, r = 0, unit = \"cm\"), # negative bottom margin to move up the x-axis title\n    axis.title.x = element_text(hjust = 0.5),\n    axis.ticks.length = unit(-2, \"mm\"), # negative tick length to move up the x-axis title\n    axis.text.x = element_text(margin = margin(t = -10, b = -15)) # negative margins to move up the x-axis values\n  ) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.05))) # reducing the expansion\n\n# Combine the plots with the x-axis label plot\ncombined_plot &lt;- (p1 | p2 | p3) / \n  x_axis_label +\n  plot_layout(\n    guides = 'collect',\n    heights = c(1, 0.1) # Adjust these values as needed to control the space\n  ) +\n  plot_annotation(\n    title = 'Distribution of Average PV Among Students in Singapore'\n  ) &\n  theme(\n    plot.title = element_text(face = \"bold\", hjust = 0.5) # Center the title\n  )\n\n# Display the combined plot\ncombined_plot"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#original-design-1",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#original-design-1",
    "title": "Take-home Exercise 2",
    "section": "3.1 Original Design",
    "text": "3.1 Original Design\nThe original design is shown below."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#enhancements-for-clarity-1",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#enhancements-for-clarity-1",
    "title": "Take-home Exercise 2",
    "section": "3.2 Enhancements for Clarity",
    "text": "3.2 Enhancements for Clarity"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#a-alternative-chart-type-for-better-analysis",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#a-alternative-chart-type-for-better-analysis",
    "title": "Take-home Exercise 2",
    "section": "(a) Alternative chart type for better analysis",
    "text": "(a) Alternative chart type for better analysis\nOur primary objective is to analyze and compare the score distributions across genders. Given this focus, box plots or violin plots would serve as highly effective visual tools. These types of plots portrays distribution patterns, effectively revealing disparities in median scores and the extent of variation within each gender category. In contrast, histograms, while useful for depicting frequency distributions, fall short in offering a comprehensive view of the data’s spread and central tendencies, such as medians and quartiles. This limitation makes histograms less suitable for our purpose of detailed comparison. Therefore, to achieve a more nuanced and comparative analysis, I recommend transitioning from histograms to violin plots, as they not only highlight the central tendencies but also elegantly encapsulate the full distribution of scores across genders."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#sketch-of-proposed-design-1",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#sketch-of-proposed-design-1",
    "title": "Take-home Exercise 2",
    "section": "3.3 Sketch of Proposed Design",
    "text": "3.3 Sketch of Proposed Design"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#final-design-1",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#final-design-1",
    "title": "Take-home Exercise 2",
    "section": "3.4 Final Design",
    "text": "3.4 Final Design\nAfter performing the necessary modifications, the final code and design are as follows.\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\n\n# Prepare the data with gender and average scores\ngender_scores &lt;- Related_math_read_scie_data %&gt;%\n  mutate(\n    Gender = ifelse(ST004D01T == 1, \"Female\", \"Male\"),\n    AvgMathPV = avg_pvMATH,\n    AvgReadPV = avg_pvREAD,\n    AvgSciePV = avg_pvSCIE\n  )\n\n# Reshape the data to long format\nlong_format &lt;- gender_scores %&gt;%\n  select(Gender, AvgMathPV, AvgReadPV, AvgSciePV) %&gt;%\n  pivot_longer(\n    cols = c(AvgMathPV, AvgReadPV, AvgSciePV),\n    names_to = \"Subject\",\n    values_to = \"Score\"\n  ) %&gt;%\n  mutate(Subject = recode(Subject,\n                          AvgMathPV = \"Mathematics\",\n                          AvgReadPV = \"Reading\",\n                          AvgSciePV = \"Science\"))\n\n# Calculate the average scores for each Subject and Gender\navg_scores &lt;- long_format %&gt;%\n  group_by(Subject, Gender) %&gt;%\n  summarize(AvgScore = mean(Score, na.rm = TRUE), .groups = 'keep')\n\n# Create the boxplots with specified colors and apply a minimalistic theme\nboxplot &lt;- ggplot(long_format, aes(x = Gender, y = Score, fill = Gender)) +\n  geom_boxplot(position = position_dodge(width = 0.75)) + \n  geom_point(data = avg_scores, aes(x = Gender, y = AvgScore, group = Gender), \n             position = position_dodge(width = 0.75), color = \"red\", size = 3, show.legend = FALSE) +\n  geom_text(data = avg_scores, aes(x = Gender, y = AvgScore, label = paste(\"Avg =\", round(AvgScore, 1))),\n            position = position_dodge(width = 0.75), vjust = -2, color = \"black\", size = 2.5, fontface = \"bold\", show.legend = FALSE) +\n  scale_fill_manual(values = c(\"Female\" = \"coral\", \"Male\" = \"skyblue\")) +  # Added the missing `+` here\n  labs(fill = \"\") +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.05)), limits = c(0, NA)) +\n  labs(\n    title = \"Distribution of Average PV by Gender\",\n    x = \"\",\n    y = \"Average Plausible Values\"\n  ) +\n  facet_wrap(~Subject, strip.position = \"top\") +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    legend.title = element_text(size = 11),\n    legend.text = element_text(size = 11),\n    strip.text = element_text(size = 14, hjust = 0.5, face = \"bold\"),\n    plot.title = element_text(size = 13, hjust = 0.5, face = \"bold\"),\n    axis.text.x = element_blank(),  # Remove x-axis text labels\n    axis.text.y = element_text(size = 11),\n    axis.title.y = element_text(size = 11),\n    panel.grid.major.x = element_blank(),\n    panel.grid.minor.x = element_blank(),\n    strip.background = element_blank()\n  )\n\n# Print the boxplot\nprint(boxplot)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#original-design-2",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#original-design-2",
    "title": "Take-home Exercise 2",
    "section": "4.1 Original Design",
    "text": "4.1 Original Design\nThe original design is shown below."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#enhancements-for-clarity-2",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#enhancements-for-clarity-2",
    "title": "Take-home Exercise 2",
    "section": "4.2 Enhancements for Clarity",
    "text": "4.2 Enhancements for Clarity"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#a-main-graph-title-refinement-1",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#a-main-graph-title-refinement-1",
    "title": "Take-home Exercise 2",
    "section": "(a) Main Graph Title Refinement",
    "text": "(a) Main Graph Title Refinement\nThe initial graph title ‘The Relationship between School and Performances’ lacked descriptive power. A more precise title, ‘School Influence on Student Performance Across Subjects,’ provides a comprehensive and informative overview of the data presented."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#b-x-axis-labeling-efficiency",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#b-x-axis-labeling-efficiency",
    "title": "Take-home Exercise 2",
    "section": "(b) X-axis Labeling Efficiency",
    "text": "(b) X-axis Labeling Efficiency\nThe repetition of ‘School ID’ on the x-axis is unnecessary. We will consolidate this label for a cleaner look and enhanced readability. Additionally, to prevent the overlapping of school IDs, we will extend the x-axis from one end of the chart to the other, utilizing the full width of the graph for a more spaced and legible display."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#c-y-axis-scale-and-representation-adjustment",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#c-y-axis-scale-and-representation-adjustment",
    "title": "Take-home Exercise 2",
    "section": "(c) Y-axis Scale and Representation Adjustment",
    "text": "(c) Y-axis Scale and Representation Adjustment\nThe y-axis currently does not start from zero, which may lead to a misinterpretation of the performance variances. To address this, we will standardize the y-axis across all scatterplots. By combining all subjects into one scatterplot, we’ll differentiate them not with individual titles but with a coded color scheme for the dots and lines. The y-axis labels will be unified to ‘Average Plausible Values,’ simplifying the comparison across subjects."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#aesthetic-improvements-1",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#aesthetic-improvements-1",
    "title": "Take-home Exercise 2",
    "section": "4.3 Aesthetic Improvements",
    "text": "4.3 Aesthetic Improvements"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#a-centralized-main-graph-title",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#a-centralized-main-graph-title",
    "title": "Take-home Exercise 2",
    "section": "(a) Centralized Main Graph Title",
    "text": "(a) Centralized Main Graph Title\nWe will shift the main graph title to a central position, enhancing the visual symmetry and appeal of the chart, thus drawing the viewer’s attention more effectively."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#b-enhanced-legend-and-color-differentiation",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#b-enhanced-legend-and-color-differentiation",
    "title": "Take-home Exercise 2",
    "section": "(b) Enhanced Legend and Color Differentiation",
    "text": "(b) Enhanced Legend and Color Differentiation\nTo aid interpretation, we will introduce a legend that clearly links the color scheme to the respective subjects being displayed. This is not only visually appealing but also support the viewer in decoding the information."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#c-background-and-gridline-adjustment",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#c-background-and-gridline-adjustment",
    "title": "Take-home Exercise 2",
    "section": "(c) Background and Gridline Adjustment",
    "text": "(c) Background and Gridline Adjustment\nTo accommodate the various colors present in the graph and enhance visual clarity, we will remove the grey background. This simplification will reduce visual clutter and focus attention on the data points. Additionally, to maintain gridline visibility while ensuring they are not visually intrusive, we will change their color to a subtle grey. This adjustment will create a cleaner and more visually pleasing graph that is easier on the eyes."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#sketch-of-proposed-design-2",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#sketch-of-proposed-design-2",
    "title": "Take-home Exercise 2",
    "section": "4.4 Sketch of Proposed Design",
    "text": "4.4 Sketch of Proposed Design"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#final-design-2",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#final-design-2",
    "title": "Take-home Exercise 2",
    "section": "4.5 Final Design",
    "text": "4.5 Final Design\nAfter performing the necessary modifications, the final code and design are as follows.\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\n\n# Calculate the school-wise average scores for each subject\nRelated_math_read_scie_data &lt;- Related_math_read_scie_data %&gt;%\n  group_by(CNTSCHID) %&gt;%\n  mutate(\n    avg_pvMATH_school = mean(avg_pvMATH, na.rm = TRUE),\n    avg_pvREAD_school = mean(avg_pvREAD, na.rm = TRUE),\n    avg_pvSCIE_school = mean(avg_pvSCIE, na.rm = TRUE)\n  ) %&gt;%\n  ungroup()\n\n# Reshape the data to long format for plotting\nlong_format &lt;- Related_math_read_scie_data %&gt;%\n  select(CNTSCHID, avg_pvMATH_school, avg_pvREAD_school, avg_pvSCIE_school) %&gt;%\n  pivot_longer(\n    cols = starts_with(\"avg_pv\"),\n    names_to = \"Subject\",\n    values_to = \"Score\"\n  ) %&gt;%\n  mutate(Subject = recode(Subject,\n                          \"avg_pvMATH_school\" = \"Mathematics\",\n                          \"avg_pvREAD_school\" = \"Reading\",\n                          \"avg_pvSCIE_school\" = \"Science\"))\n\n# Create the combined scatterplot\np_combined &lt;- ggplot(data = long_format, aes(x = CNTSCHID, y = Score, color = Subject)) +\n  geom_point() +\n  geom_smooth(aes(group = Subject), method = lm, se = FALSE) +\n  scale_color_discrete() +  # Use default color scheme\n  labs(\n    title = \"School Influence on Student Performance Across Subjects\",\n    x = \"School ID\",\n    y = \"Average Plausible Values\"\n  ) +\n  scale_x_continuous(expand = expansion(mult = c(0.01, 0.01))) +  # Adjust x-axis limits\n  scale_y_continuous(expand = expansion(mult = c(0.01, 0.01)), limits = c(0, NA)) +  # Start y-axis at 0, adjust if needed\n  theme_minimal() +\n  theme(\n  plot.title = element_text(hjust = 0.5, face = \"bold\", size = 14),\n  axis.title.x = element_text(size = 11),\n  axis.title.y = element_text(size = 11),\n  axis.text.x = element_text(hjust = 1, angle = 0),  # Horizontal x-axis text\n  axis.text.y = element_text(size = 11),\n  panel.grid.major.x = element_line(color = \"grey90\"),  # Add vertical gridlines\n  panel.grid.minor.x = element_blank(),  # Remove minor vertical gridlines\n  panel.grid.major.y = element_line(color = \"grey90\"),  # Add major horizontal gridlines\n  panel.grid.minor.y = element_blank(),  # Remove minor horizontal gridlines\n  legend.position = \"bottom\",\n  legend.title = element_blank(),\n  legend.text = element_text(size = 12)\n) +\nguides(color = guide_legend(title = \"Subject\", override.aes = list(size = 4))) # Ensure legend is shown correctly\n\n# Print the scatterplot\nprint(p_combined)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#original-design-3",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#original-design-3",
    "title": "Take-home Exercise 2",
    "section": "5.1 Original Design",
    "text": "5.1 Original Design\nThe original design is shown below."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#enhancements-for-clarity-3",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#enhancements-for-clarity-3",
    "title": "Take-home Exercise 2",
    "section": "5.2 Enhancements for Clarity",
    "text": "5.2 Enhancements for Clarity"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#a-x-axis-and-main-title-labeling-correction",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#a-x-axis-and-main-title-labeling-correction",
    "title": "Take-home Exercise 2",
    "section": "(a) X-axis and Main Title Labeling Correction",
    "text": "(a) X-axis and Main Title Labeling Correction\nThe current x-axis title ‘Socioeconomic Status (Lower values indicate higher status)’ does not accurately reflect the data, which is based on the ‘Parent_Edu_level’ derived from our data wrangling process. We will update the x-axis label to ‘Parental Education Level’ to accurately describe the underlying data dimension. As well as the main title of the graph."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#b-legend-labeling-refinement",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#b-legend-labeling-refinement",
    "title": "Take-home Exercise 2",
    "section": "(b) Legend Labeling Refinement",
    "text": "(b) Legend Labeling Refinement\nThe term ‘colour’ in the legend is superfluous and can lead to confusion. Additionally, to ensure grammatical correctness and consistency, ‘Read’ will be updated to ‘Reading’, and ‘Maths’ will be expanded to ‘Mathematics’."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#c-axis-scale-adjustment",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#c-axis-scale-adjustment",
    "title": "Take-home Exercise 2",
    "section": "(c) Axis Scale Adjustment",
    "text": "(c) Axis Scale Adjustment\nCurrently, the axes do not begin at zero, which can potentially misrepresent the data. We will adjust the axis scales to start at zero to provide a true-to-scale representation of the data points."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#aesthetic-improvements-2",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#aesthetic-improvements-2",
    "title": "Take-home Exercise 2",
    "section": "5.3 Aesthetic Improvements",
    "text": "5.3 Aesthetic Improvements"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#a-harmonizing-color-palette",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#a-harmonizing-color-palette",
    "title": "Take-home Exercise 2",
    "section": "(a) Harmonizing Color Palette",
    "text": "(a) Harmonizing Color Palette\nWe will adopt a palette of soft, natural colors for the primary data display, reserving more vivid or darker shades for elements that require emphasis or immediate attention from the viewer."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#sketch-of-proposed-design-3",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#sketch-of-proposed-design-3",
    "title": "Take-home Exercise 2",
    "section": "5.4 Sketch of Proposed Design",
    "text": "5.4 Sketch of Proposed Design"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#final-design-3",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#final-design-3",
    "title": "Take-home Exercise 2",
    "section": "5.5 Final Design",
    "text": "5.5 Final Design\nAfter performing the necessary modifications, the final code and design are as follows.\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Create a new column 'Parent_Edu_level'\nRelated_math_read_scie_data &lt;- Related_math_read_scie_data %&gt;%\n  mutate(Parent_Edu_level = ST005Q01JA + ST007Q01JA)\n\n# Create a dataframe for plotting\ndf &lt;- Related_math_read_scie_data\n\n# Plot the relationship between performance and socioeconomic status\np_combined &lt;- ggplot(df, aes(x = Parent_Edu_level)) +\n  geom_point(aes(y = avg_pvMATH, color = \"Mathematics\"), alpha = 1, size = 1.5, na.rm = TRUE) +\n  geom_smooth(aes(y = avg_pvMATH, color = \"Mathematics\"), method = \"lm\", se = FALSE, na.rm = TRUE) +\n  geom_point(aes(y = avg_pvREAD, color = \"Reading\"), alpha = 1, size = 1.5, na.rm = TRUE) +\n  geom_smooth(aes(y = avg_pvREAD, color = \"Reading\"), method = \"lm\", se = FALSE, na.rm = TRUE) +\n  geom_point(aes(y = avg_pvSCIE, color = \"Science\"), alpha = 1, size = 1.5, na.rm = TRUE) +\n  geom_smooth(aes(y = avg_pvSCIE, color = \"Science\"), method = \"lm\", se = FALSE, na.rm = TRUE) +\n  labs(\n    title = \"Relationship between Parental Education Level and Student Performance\",\n    x = \"Parental Education Level (Lower values indicate higher education levels)\",\n    y = \"Average Plausible Values\",\n    \n  ) +\n  scale_color_discrete() +  # Use default color scheme\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\", hjust = 0.5, size = 12),\n    axis.title = element_text(size = 11),\n    axis.text.x = element_text(angle = 0, vjust = 0.5, size = 9),\n    axis.text.y = element_text(angle = 0, vjust = 0.5, size = 9),\n    legend.position = \"bottom\",\n    legend.title = element_blank(),\n    plot.margin = margin(t = 10, r = 10, b = 10, l = 10),\n    legend.text = element_text(size = 11),\n    panel.grid.minor.y = element_blank()\n  ) +\n  expand_limits(y = 0)  # Ensure the y-axis starts at zero\n\n# Print the plot\nprint(p_combined)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#learning-points",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#learning-points",
    "title": "Take-home Exercise 2",
    "section": "6. Learning Points",
    "text": "6. Learning Points\nThe Take Home Exercise 2 was instrumental in deepening my understanding of the importance of selecting appropriate visualizations and tailoring charts to the audience’s perspective. It was an enlightening experience to learn about efficient coding practices from my peers’ work. This exercise also afforded me the opportunity to delve deeper into ggplot, enhancing my ability to add layers and craft more insightful charts. It was a valuable exercise in not just honing technical skills but also in appreciating the nuances of effective data visualization."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "title": "In-class Exercise 1: Now you see it!",
    "section": "",
    "text": "In this hands-on exercise, two R packages will be used. They are:\n\ntidyverse, and\nhaven\n\nThe code chunk used is as follows:\n\npacman::p_load(tidyverse, haven)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-r-packages",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-r-packages",
    "title": "In-class Exercise 1: Now you see it!",
    "section": "",
    "text": "In this hands-on exercise, two R packages will be used. They are:\n\ntidyverse, and\nhaven\n\nThe code chunk used is as follows:\n\npacman::p_load(tidyverse, haven)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#importing-pisa-data",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#importing-pisa-data",
    "title": "In-class Exercise 1: Now you see it!",
    "section": "Importing PISA data",
    "text": "Importing PISA data\nThe code chunk below uses read_sas() of haven to import PISA data into R environment.\n\nstu_qqq &lt;- read_sas(\"../../data/STU_QQQ_SAS/cy08msp_stu_qqq.sas7bdat\")\n\n\nstu_qqq_SG &lt;- stu_qqq %&gt;%\n  filter(CNT == \"SGP\")\n\n\nwrite_rds(stu_qqq_SG,\n          \"../../data/STU_QQQ_SAS/stu_qqq_SG.rds\")\n\n\nstu_qqq_Sg &lt;-\n  read_rds(\"../../data/STU_QQQ_SAS/stu_qqq_SG.rds\")"
  }
]